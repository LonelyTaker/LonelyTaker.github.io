[{"title":"ES6模块与CommonJS模块的区别","url":"/2022/01/29/ES6%E6%A8%A1%E5%9D%97%E4%B8%8ECommonJS%E6%A8%A1%E5%9D%97%E7%9A%84%E5%8C%BA%E5%88%AB/","content":"1.写法不同最直观的，两者对于模块的导入导出写法不同\n\nES6\n\n/* 导出 */export let a = 10export let b = 20export default &#123;...&#125;/* 导入 */import &#123;a, b&#125; from &#x27;./test.js&#x27;import c from &#x27;./test.js&#x27;\n\n\nCommonJS\n\n/* 导出 */module.exports = &#123; a: 10, b: 20 &#125;;/* 导入 */let test = require(&quot;./test.js&quot;);console.log(test.a, test.b); // 输出 10 20\n\n\n注意：上述 CommonJS 导出写法会改变原本指向的内存，使其与 exports 指向不同内存空间，语法非本篇重点，可看这篇博客\nhttps://www.cnblogs.com/fightjianxian/p/12151010.html\n\n\n\n2.加载阶段不同\nCommonJS 模块加载的是对象（即module.exports属性），它只有在脚本运行完才会生成，所以是运行时加载\n而 ES6 模块不是对象，它的对外接口是一种静态定义，在代码静态解析阶段就会生成，所以是编译时输出接口\n\n\n\n3.输出内容不同\n刚刚说了 CommonJS 模块输出的是一个对象，所以是一个值的拷贝（浅拷贝）\n\n请看下面这个例子，模块内有一个变量 a 和一个自增函数\n/* 模块test.js */let a = 1;function add() &#123;  a++;&#125;module.exports = &#123;  a: a,  add: add,&#125;;/* 需要引入模块的文件main.js */let mod = require(&quot;./test.js&quot;);console.log(mod.a); // 1mod.add();console.log(mod.a); // 1\n\n上述代码说明，test.js模块加载以后，它内部的变化影响不到已经输出的mod.a了，因为 a 会被缓存（a 是一个简单数据类型，导出时直接拷贝值）。除非写成一个函数，才能获得内部变动后的值\n/* 模块test.js */let a = 1;function add() &#123;  a++;&#125;module.exports = &#123;  get a() &#123;    return a;  &#125;,  add: add,&#125;;/* 需要引入模块的文件main.js */let mod = require(&quot;./test.js&quot;);console.log(mod.a); // 1mod.add();console.log(mod.a); // 2\n\n上面代码中，输出的a实际上是一个取值器函数。如果想输出后的a发生改变，可以这样修改\n/* 模块test.js */let a = 1;function add() &#123;  this.a++;&#125;module.exports = &#123;  a: a,  add: add,&#125;;/* 需要引入模块的文件main.js */let mod = require(&quot;./test.js&quot;);console.log(mod.a); // 1mod.add();console.log(mod.a); // 2\n\n这样改变的是输出的对象的a属性，模块内部并未受影响\n/* 模块test.js */let a = 1;function add() &#123;  this.a++;  console.log(a); // 1&#125;module.exports = &#123;  a: a,  add: add,&#125;;/* 需要引入模块的文件main.js */let mod = require(&quot;./test.js&quot;);mod.add();console.log(mod.a); // 2\n\n这或许对你理解CommonJS模块输出的是一个对象有所帮助\n\n而 ES6 模块输出的是值的引用\n\nES6 模块的运行机制与 CommonJS 不一样。JS 引擎对脚本静态分析的时候，遇到模块加载命令import，就会生成一个只读引用。等到脚本真正执行时，再根据这个只读引用，到被加载的那个模块里面去取值。同样的代码\n/* 模块test.js */export let a = 1;export function add() &#123;  a++;&#125;/* 需要引入模块的文件main.js */import &#123; a, add &#125; from &quot;./test.js&quot;;console.log(a); // 3add();console.log(a); // 4\n\n上述代码说明 ES6 模块输出的变量a完全反应其在所在模块内部的变化\n\n\n4.加载方式不同\nCommonJS 模块的require()是同步加载模块\nES6 模块的import命令是异步加载，有一个独立的模块依赖的解析阶段\n\n\n\n\n参考自阮一峰老师的博客\nhttps://es6.ruanyifeng.com/#docs/module-loader#ES6-%E6%A8%A1%E5%9D%97%E4%B8%8E-CommonJS-%E6%A8%A1%E5%9D%97%E7%9A%84%E5%B7%AE%E5%BC%82\n\n","categories":["前端"],"tags":["JavaScript"]},{"title":"IO多路复用","url":"/2024/10/09/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","content":"多路复用要解决的问题在多路复用之前，并发多客户端连接，最简单和典型的方案是：同步阻塞网络IO模型。\n这种模式的特点就是用一个进程来处理一个网络连接（一个网络请求）。\n优点是这种方式容易理解，但缺点是性能差，每个用户请求都需要占用一个进程来处理。\n而进程在Linux上是个不小的开销，不说创建，光是上下文切换也需要耗费资源。所以为了高效地对海量用户提供服务，必须要让一个进程能同时处理多个TCP连接。\n那么进程如何发现是哪个连接可读了或者可写了？循环遍历这种方式显然太低级。Linux操作系统其实已经帮我们做好了，那就是多路复用机制。\n这里的复用是指对进程的复用。\n\n这里的进程也可以理解为线程层次，个人理解为1个worker对应多个socket。\n\n\n\nRedis的IO多路复用Redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，依次放到文件事件分派器，事件分派器 将事件分发给 事件处理器。\n\nRedis是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以IO操作在一般情况下往往不能直接返回，这会导致某一文件的IO阻塞导致整个进程无法对其他客户提供服务，而IO多路复用就是为了解决这个问题而出现的。\n所谓IO多路复用机制，就是说通过一种机制可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），就能够通知程序进行相应的读写操作。这种机制的使用需要select、poll、epoll来配合。多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象上等待，无需阻塞等待所有连接。当某条连接有新数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。\n\n\nRedis服务采用Reactor的方式来实现文件事件处理器（每一个网络连接都对应一个文件描述符）。\nReactor模式，是指通过一个或多个输入同时传递给服务处理器的服务请求的事件驱动处理模式。服务端程序处理传入多路请求，并将它们同步分派给请求对应的处理线程，Reator模式又叫Dispatcher模式。即IO多路复用统一监听事件，收到事件后分发，是编写高性能网络服务器的必备技术。\n\nRedis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器。它由四部分组成：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。\n因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。\n\n\n补充：从Redis6开始，将网络数据读写、请求协议解析通过多个IO线程来处理，解决网络IO问题。\n\n\n\n\n\nIO中的阻塞、非阻塞、同步、异步举一个生活中的案例：\n你去餐厅点餐，服务员拿到你的订单后，把订单交给厨师，然后等待厨师把餐做完，而不去关注其他食客，这种情况就叫做阻塞。\n如果服务员把订单交给厨师后，继续去服务其他食客，这种情况就叫做非阻塞。\n服务员把订单交给厨师后，不断主动向厨师询问菜好了没有，这就是同步（主动获取）。\n如果厨师把菜做完后，告知服务员菜已经好了，这就是异步（被动通知）。\n总结：阻塞&#x2F;非阻塞关注的是线程在等待消息时候的状态，同步&#x2F;异步关注的是消息通知的方式\n由此引申出来四种组合，我们还是继续通过上面的例子来说明：\n\n同步阻塞\n服务员拿到订单，交给厨师后，等待厨师出餐，并不断询问出餐状态，直到出餐完成\n\n异步阻塞\n服务员拿到订单，交给厨师后，等待厨师出餐，厨师出餐完成后通知服务员\n\n通过这个例子可以看出，消息已经被动通知了，线程完全没有必要阻塞等待，所以异步阻塞IO实际上是不存在的\n\n\n同步非阻塞\n服务员拿到订单，交给厨师后，继续服务其他食客，期间不断向厨师询问出餐状态\n\n异步非阻塞\n服务员拿到订单，交给厨师后，继续服务其他食客，厨师出餐完成后通知服务员\n\n\n\n\nUnix网络编程中的五种IO模型\n阻塞IO\n非阻塞IO\nIO多路复用\n信号驱动IO\n异步IO\n\n\nhttps://www.cnblogs.com/flashsun/p/14591563.html\n\n\n\nIO多路复用的实现方式IO多路复用就是我们说的select，poll，epoll，有些书籍也将这种IO方式称为事件驱动IO。就是通过一种机制，一个进程可以监控多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。可以基于一个阻塞对象并同时在多个描述符上等待就绪，而不是使用多个线程（每个文件描述符一个线程），这样就可以大大节省系统资源。\n所以，IO多路复用的特点是通过一种机制一个进程能够同时等待多个文件描述符，而文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select、poll、epoll等函数就可以返回。\n\n\n\nselect\nselect 是操作系统提供的系统调用函数，通过它，我们可以把一个文件描述符的数组发给操作系统， 让操作系统去遍历，确定哪个文件描述符可以读写。\nint select(    int nfds,    fd_set *readfds,    fd_set *writefds,    fd_set *exceptfds,    struct timeval *timeout);// nfds:监控的文件描述符集里最大文件描述符加1// readfds：监控有读数据到达文件描述符集合，传入传出参数// writefds：监控写数据到达文件描述符集合，传入传出参数// exceptfds：监控异常发生达文件描述符集合, 传入传出参数// timeout：定时阻塞监控时间，3种情况//  1.NULL，永远等下去//  2.设置timeval，等待固定时间//  3.设置timeval里时间均为0，检查描述字后立即返回，轮询\n\nselect函数监视的文件描述符分3类，分别是readfds、writefds和exceptfds，将用户传入的数组拷贝到内核空间。\n调用后select函数会阻塞，直到有描述符就绪（有数据可读、可写或有except）或超时，函数返回。\n当select函数返回时，可以通过遍历fdset，来找到就绪的描述符。\nwhile(1) &#123;  nready = select(list);  // 用户层依然要遍历，只不过少了很多无效的系统调用  for(fd &lt;-- fdlist) &#123;    if(fd != -1) &#123;      // 只读已就绪的文件描述符      read(fd, buf);      // 总共只有 nready 个已就绪描述符，不用过多遍历      if(--nready == 0) break;    &#125;  &#125;&#125;\n\n细节：\n\nselect 调用需要传入 fd 数组，需要拷贝一份到内核，高并发场景下这样的拷贝消耗的资源是惊人的。（可优化为不复制）\n\nselect 在内核层仍然是通过遍历的方式检查文件描述符的就绪状态，是个同步过程，只不过无系统调用切换上下文的开销。（内核层可优化为异步事件通知）\n\nselect 仅仅返回可读文件描述符的个数，具体哪个可读还是要用户自己遍历。（可优化为只返回给用户就绪的文件描述符，无需用户做无效的遍历）\n\n\n可以看到，这种方式，既做到了一个线程处理多个客户端连接（文件描述符），又减少了系统调用的开销（多个文件描述符只有一次 select 的系统调用 + n 次就绪状态的文件描述符的 read 系统调用）。\n\npoll\npoll 也是操作系统提供的系统调用函数。\nint poll(struct pollfd *fds, nfds_tnfds, int timeout);struct pollfd &#123;  intfd; /*文件描述符*/  shortevents; /*监控的事件*/  shortrevents; /*监控事件中满足条件返回的事件*/&#125;;\n\n它和 select 的主要区别就是，去掉了 select 只能监听 1024 个文件描述符的限制。\n\n这是因为select函数底层使用了bitmap，bitmap默认大小为1024\n\n\nepoll\nepoll 解决了 select 和 poll 的一些问题。\n它主要针对上面 select 细节当中的三点进行了改进：\n\n内核中保存一份文件描述符集合，无需用户每次都重新传入，只需告诉内核修改的部分即可。\n\n内核不再通过轮询的方式找到就绪的文件描述符，而是通过异步 IO 事件唤醒。\n\n内核仅会将有 IO 事件的文件描述符返回给用户，用户也无需遍历整个文件描述符集合。\n\n\n具体，操作系统提供了这三个函数：\n第一步，创建一个 epoll 句柄int epoll_create(int size);第二步，向内核添加、修改或删除要监控的文件描述符。int epoll_ctl(  int epfd, int op, int fd, struct epoll_event *event);第三步，类似发起了 select() 调用int epoll_wait(  int epfd, struct epoll_event *events, int max events, int timeout);\n\n","categories":["后端"],"tags":["Redis"]},{"title":"MoreKey和BigKey","url":"/2024/10/08/MoreKey%E5%92%8CBigKey/","content":"MoreKey问题keys *指令有致命的弊端，在实际生产环境中是禁用的。\n\n这个指令没有offset、limit参数，是要一次性返回所有满足条件的key，由于redis是单线程的，其所有操作都是原子的，而keys算法是遍历算法，复杂度是O(n)，如果实例中有千万级以上的key，这个指令就会导致Redis服务卡顿，所有读写Redis的其他的指令都会被延后甚至会超时报错，可能会引起缓存雪崩甚至数据库宕机。\n\n\n\n规避生产上如何限制keys */flushdb/flushall等危险命令以防止误删误用？\n修改配置文件：\n########## SECURITY ##########rename-command keys &quot;&quot;rename-command flushdb &quot;&quot;rename-command flushall &quot;&quot;\n\n\n\n如何正确查询scan与scan相关的指令有sscan/hscan/zscan\n\nscan命令用于迭代当前数据库中的数据库键\n\nsscan命令用于迭代集合键中的元素\n\nhscan命令用于迭代哈希键中的键值对\n\nzscan命令用于迭代有序集合中的元素（包括元素成员和元素分值）\n\n\n\n\nSCAN cursor [MATCH pattern] [COUNT count]\n\n\ncursor：游标\npattern：匹配的模式\ncount：指定从数据集里返回多少元素，默认10\n\nSCAN返回一个包含两个元素的数组\n\n第一个元素是用于下一次迭代的新游标\n第二个元素则是一个数组，这个数组中包含了所有被迭代的元素\n如果新游标返回0表示迭代已结束\n\n\nhttps://redis.com.cn/commands/scan.html\n\n\n\nBigKeybigkey是指key对应的value所占的内存空间比较大。\nstring类型控制在10kb以内，hash、list、set、zset元素个数不要超过5000，否则可以称之为bigkey。\n\n\n问题\n内存空间不均（不平衡），集群迁移困难\n超时触发删除操作，由于Redis单线程，不仅耗时并且会占用资源，也就意味着Redis阻塞的可能性会增大\n网络流量阻塞\n\n\n\n如何发现\nredis-cli --bigkeys\n在连接Redis时加入--bigkeys参数。\n可以找到Redis实例中5种基本数据类型的最大key。\n\nMEMORY USAGE key\n\nhttps://redis.com.cn/commands/memory-usage.html\n\n\n\n\n\n如何删除非字符串的bigkey，不要使用del删除，使用sscan、hscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题（过期触发del操作会造成阻塞）\n\nstring：一般使用del，如果过于庞大使用unlink\nhash：使用hscan每次获取少量field-value，再使用hdel删除每个field\nlist：使用ltrim渐进式逐步删除，直到全部删除\nset：使用sscan每次获取部分元素，再使用srem命令删除每个元素\nlset：使用zscan每次获取部分元素，再使用zremrangebyrank命令删除每个元素\n\n\n\nLAZY FREEING阻塞和非阻塞删除Redis有两种方式删除键，一种是DEL，是对象的阻塞删除。这意味着服务器停止处理新命令，以便以同步方式回收和对象关联的所有内存。如果删除的键与一个小对象关联，该执行时间非常短。但是如果键与包含数百万个元素的集合值相关联，则服务器可能会阻塞很长时间才能完成操作。\n基于上述原因，Redis还提供了非阻塞删除，例如UNLINK（非阻塞DEL）以及FLUSHALL和FLUSHDB命令的ASYNC选项，以便在后台回收内存。这些命令在恒定时间内执行，另一个线程将尽可能地逐步释放后台中的对象。\n\n\n配置由于其他操作的副作用，Redis服务器有时不得不删除键或刷新整个数据库，在某些场景下独立于用户调用删除对象，而默认的删除方式是阻塞式的，可以通过配置修改：\nlazyfree-lazy-eviction nolazyfree-lazy-expire no# 下方几个配置可以改为yes，使用非阻塞方式lazyfree-lazy-server-del noreplica-lazy-flush nolazyfree-lazy-user-del no\n\n","categories":["后端"],"tags":["Redis"]},{"title":"MySQL架构","url":"/2024/09/29/MySQL%E6%9E%B6%E6%9E%84/","content":"逻辑架构逻辑架构剖析\n基础服务组件\n连接池\nSQL接口\n解析器\n优化器\n查询缓存\n插件式存储引擎\n文件系统\n日志文件\n\n\n连接层\n建立TCP连接\n身份认证、权限获取\n\nMySQL服务器有专门的TCP连接池限制连接数，采用长连接模式复用TCP连接。\n连接接收到请求后，必须分配一个线程专门与这个客户端交互，所以还有一个线程池。\n这些内容都归纳到MySQL的连接管理组件中。\n服务层服务层主要完成大多数的核心服务功能，如SQL接口，并完成缓存的查询，SQL的分析和优化以及部分内置函数的执行。所有跨存储引擎的功能也再这一层实现，如过程、函数等。\n\nSQL Interface: SQL接口\nParser: 解析器\nOptimizer: 查询优化器\nCaches &amp; Buffers: 查询缓存组件\n\n引擎层真正负责了MySQL中数据的存储和提取，对物理服务器级别的维护的底层数据执行操作。\nSQL执行流程\n\n查询缓存（因为查询缓存往往效率不高，在MySQL8.0之后就抛弃了该功能）\n大多数情况查询缓存就是个鸡肋，原因如下：\n\n查询缓存不是缓存查询计划，而是缓存查询结果。只有相同的查询才会命中缓存。\n如果查询请求中包含某些系统函数、用户自定义变量和函数、一些系统表，那这个请求就不会缓存。\n既然是缓存，那就有它缓存失效的时候。MySQL的缓存系统会监测涉及到的每张表，只要该表的结构或者数据被修改，那使用该表的缓存查询都会失效。对于更新压力大的数据库来说，查询缓存的命中率会非常低。\n\n\n解析器\n\n词法分析\n语法分析\n\n如果SQL语句正确，则会生产一个语法树。\n\n优化器\n一条查询可以有很多种执行方式，最后都返回相同的结果。优化器的作用就是找到其中最好的执行计划。\n优化可以分为两个部分：逻辑查询优化和物理查询优化\n\n执行器\n拿到优化器的执行计划后开始执行。\n在执行前需要判断用户是否具备权限。如果没有，则返回权限错误；如果有，则执行SQL查询并返回结果。在MySQL8.0以下的版本，如果设置了查询缓存，这时会将查询结果进行缓存。\n打开表的时候，执行器会根据表的引擎定义，调用存储引擎API对表进行读写。存储引擎API只是抽象接口，下面还有个存储引擎层，具体实现要看表选择的存储引擎。\n\n\n总结：SQL的执行流程：SQL语句-&gt;查询缓存-&gt;解析器-&gt;优化器-&gt;执行器\n存储引擎存储引擎原称表处理器，它的功能就是接收上层传下来的指令，对表中的数据进行提取或写入操作\n查看存储引擎show engines;# 查看默认的存储引擎show variables like &#x27;%storage_engine&#x27;;\n\n\n\n修改存储引擎# 修改默认的存储引擎SET DEFAULT_STORAGE_ENGINE=MyISAM;\n\n或者修改my.cnf文件：\ndefault-storage-engine=MyISAM\n\n\n\n设置表的存储引擎CREATE TABLE 表名( ...) ENGINE = 存储引擎名;\n\nALTER TABLE 表名 ENGINE = InnoDB;\n\n\n\n存储引擎类型InnoDB引擎：具有外键支持功能的事务存储引擎\nInnoDB是MySQL的默认事务型引擎，它被设计用来处理大量的短期事务。可以确保事务的完整提交（commit）和回滚（rollback）\n\n除了增加和查询外，还需要更新、删除操作，应优先选择InnoDB存储引擎\n\n除非有非常特别的原因需要使用其他的存储引擎，否则应该优先考虑InnoDB引擎\n\n数据文件结构：\n表名.frm 存储表结构（MySQL8.0合并到表名.ibd中）\n表名.ibd 存储数据和索引\n\nInnoDB是为处理巨大数据量的最大性能设计\n\n对比MyISAM的存储引擎，InnoDB写的处理效率差一些，并且会占用更多的磁盘空间以保存数据和索引\n\nMyISAM只缓存索引，不缓存真实数据；InnoDB不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性影响\n\n\nMyISAM引擎：主要的非事务处理存储引擎\nMyISAM不支持事务、行级锁、外键，有一个毫无疑问的缺陷就是崩溃后无法安全恢复\n\nMySQL5.5之前默认的存储引擎\n\n优势是访问的速度快\n\n针对数据统计有额外的常数存储。故而count(*)的查询效率很高\n\n数据文件结构：\n表名.frm 存储表结构\n表名.MYD 存储数据\n表名.MYI 存储索引\n\n应用场景：只读应用或者以读为主的业务\n\n\n\n\n\n对比\nMyISAM\nInnoDB\n\n\n\n外键\n不支持\n支持\n\n\n事务\n不支持\n支持\n\n\n行表锁\n表锁，即使操作一条记录也会锁住整个表，不适合高并发的操作\n行锁，操作时只锁一行，不对其他行有影响，适合高并发的操作\n\n\n缓存\n只缓存索引，不缓存真实数据\n不仅缓存索引，还要缓存真实数据，对内存要求较高\n\n\n自带系统表使用\nY\nN\n\n\n关注点\n性能：节省资源、消耗少、简单业务\n事务：并发写、事务、更大资源\n\n\n默认安装\nY\nY\n\n\n默认使用\nN\nY\n\n\nInnoDB存储引擎架构逻辑存储结构\n表空间\n段\n区\n页\n行\n\n内存结构\n缓冲池（Buffer Pool）\n\n更改缓冲区（Change Buffer）\n针对于非唯一二级索引页，在执行DML语句时，如果这些数据页没有在缓冲池中，不会直接操作磁盘，而是将数据变更存在更改缓冲区中，在未来数据被读取时，再将数据合并恢复到缓冲池中，再将合并后的数据刷新到磁盘中\n\nChange Buffer的意义是什么？\n与聚簇索引不同，二级索引通常是非唯一的，并且以相对随机的顺序插入二级索引。同样，删除和更改可能会影响索引树种不相邻的二级索引页，如果每次都操作磁盘，会造成大量的磁盘IO。有了Change Buffer，我们可以在缓冲池中进行合并处理，减少磁盘IO。\n\n\n自适应Hash索引\n用于优化对缓冲池数据的查询。InnoDB存储引擎会监控对表上各索引页的查询，如果观察到hash索引可以提高速度，则建立hash索引，称之为自适应hash索引。\n自适应哈希索引，无需人工干预，是系统根据情况自动完成。\n\n日志缓冲区（Log Buffer）\n用来保存要写入磁盘中的log日志数据（redo log、undo log），默认大小为16MB，日志缓冲区的日志会定期刷新到磁盘中。如果需要更新、插入或删除多行的事务，增加日志缓冲区的大小可以节省磁盘I&#x2F;O。\n\n\n磁盘结构\n系统表空间\n系统表空间是更改缓冲区的存储区域。如果表是在系统表空间而不是每个表文件或通用表空间中创建的，它也可能包含表和索引数据。\n文件：ibdata1\n\n独立表空间\n每个表的文件表空间包含单个InnoDB表的数据和索引，并存储在文件系统上的单个数据文件中。\n文件：xxx.ibd\n\n通用表空间\n需要通过CREATE TABLESPACE语法创建通用表空间，在创建表时，可以指定该表空间。\n文件：xxx.ibd\n\n撤销表空间\nMySQL实例在初始化时会自动创建两个默认的undo表空间（初始大小16M），用于存储undo log日志。\n文件：undo_001、undo_002\n\n临时表空间\nInnoDB使用会话临时表空间和全局临时表空间。存储用户创建的临时表等数据。\n文件：xxx.ibt\n\n双写缓冲区\nInnoDB引擎将数据页从Buffer Pool刷新到磁盘前，先将数据页写入双写缓冲区文件中，便于系统异常时恢复数据。\n文件：xxx.dblwr\n\n重做日志\n用来实现事务的持久性。该日志由两部分组成：重做日志缓存（redo log buffer）以及重做日志文件（redo log），前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志中，用于在刷新脏页到磁盘时发生错误，进行数据恢复使用。\n文件：ib_logfile0、ib_logfile1\n\n\n后台线程\nMaster Thread\n核心后台线程，负责调度其他线程，还负责将缓冲池中的数据异步刷新到磁盘中，保持数据的一致性，包括脏页的刷新、合并插入缓存、undo页的回收。\n\nIO Thread\n在InnoDB存储引擎中大量使用了AIO来处理IO请求，这样可以极大提高数据库性能，而IO Thread主要负责这些IO请求的回调。\n\n\n\n线程类型\n默认个数\n功能\n\n\n\nRead Thread\n4\n负责读操作\n\n\nWrite Thread\n4\n负责写操作\n\n\nLog Thread\n1\n负责将日志缓冲区刷新到磁盘\n\n\nInsert Buffer Thread\n1\n负责将写缓冲区刷新到磁盘\n\n\n\nPurge Thread\n主要用于回收事务已经提交了的undo log，在事务提交之后，undo log可能不用了，就用它来回收。\n\nPage Cleaner Thread\n协助 Master Thread 刷新脏页到磁盘的线程，它可以减轻 Master Thread 的工作压力，减少阻塞。\n\n\n缓冲池（buffer pool）InnoDB存储引擎是以页为单位来管理存储空间的，我们进行的增删改查操作其实本质上都是在访问页面（包括读页面、写页面、创建新页面等操作）。而磁盘 I&#x2F;O 需要消耗的时间很多，而在内存中进行操作，效率则会高很多，为了能让数据表或者索引中的数据随时被我们所用，DBMS 会申请占用内存来作为数据缓冲池，在真正访问页面之前，需要把在磁盘上的页缓存到内存中的Buffer Pool之后才可以访问。\n这样做的好处是可以让磁盘活动最小化，从而减少与磁盘直接进行 I/O 的时间。要知道，这种策略对提升 SQL 语句的查询性能来说至关重要。如果索引的数据在缓冲池里，那么访问的成本就会降低很多。\n缓冲池vs查询缓存缓冲池和查询缓存不是一个东西\n\n缓冲池\n缓冲池包括了数据页、索引页、插入缓冲、锁信息、自适应索引哈希、数据字典信息等\n\n缓冲池的重要性：节省磁盘IO的开销\n\n缓存原则：位置 * 频次\n位置决定效率，提供缓冲池就是为了在内存中可以直接访问数据。\n频次决定优先级顺序，因为缓冲池的大小有限，会优先对使用频次高的热数据进行加载。\n\n缓冲池的预读特性：\n缓冲池的作用就是提升I&#x2F;О效率，而我们进行读取数据的时候存在一个“局部性原理”，也就是说我们使用了一些数据，大概率还会使用它周围的一些数据，因此采用“预读”的机制提前加载，可以减少未来可能的磁盘I&#x2F;О操作。\n\n\n\n查询缓存\n查询缓存是提前将查询结果缓存起来，以key:value形式缓存。而缓冲池是缓存物理磁盘上的数据\n\n\n缓冲池如何读取数据缓冲池管理器会尽量将经常使用的数据保存起来，在数据库进行页面读操作的时候，首先会判断该页面是否在缓冲池中，如果存在就直接读取，如果不存在，就会通过内存或磁盘将页面存放到缓冲池中再进行读取。\n\n如果我们执行SQL语句的时候更新了缓冲池中的数据，那么这些数据会马上同步到磁盘上吗？\n实际上，当我们对数据库中的记录进行修改的时候，首先会修改缓冲池中页里面的记录信息，然后数据库会以一定的频率刷新到磁盘上。注意不是每次发生更新操作，都会立刻进行磁盘回写。缓冲池会采用一种叫做check point机制回写，这样做的好处就是提升了数据库的整体性能。\n比如，当缓冲池不够用时，需要释放掉一些不常用的页，此时就可以强行采用check point方式，将不常用的脏页写到磁盘上，然后将这些页从缓冲池中释放掉。这里的脏页（dirty page）是指缓冲池中被修改过的页。\n\n查看&#x2F;设置缓冲池的大小如果是MyISAM存储引擎，它只缓存索引，不缓存数据，参数为key_buffer_size；\n如果是InnoDB存储引擎，可以通过innodb_buffer_pool_size变量来查看缓冲池大小\n# 查看缓冲池大小show variables like &#x27;innodb_buffer_pool_size&#x27;;# 设置缓冲池大小set global innodb_buffer_pool_size=268435456; # 单位字节，这里设置为256MB\n\n\n\n多个缓冲池实例缓冲池本质上是InnoDB向操作系统申请的一块连续的内存空间。在多线程环境下，访问缓冲池中的数据需要加锁处理。所以在缓冲池特别大而且并发访问特别高的情况下，单一的缓冲池可能会影响请求的处理速度，我们可以把它们拆成若干个小的缓冲池，每个缓冲池都称为一个实例。\n[server]innodb_buffer_pool_instances=2\n\n查看缓冲池个数\nshow variables like &#x27;innodb_buffer_pool_instances&#x27;;\n\ninnodb_buffer_pool_size是总共的缓冲池大小，每个实例的占用空间计算公式如下：\ninnodb_buffer_pool_size/innodb_buffer_pool_instances\n不过并不是说缓冲池越多越好，管理缓冲池也需要性能开销。InnoDB规定：\ninnodb_buffer_pool_size小于1G时，设置多个实例是无效的\n","categories":["后端"],"tags":["MySQL"]},{"title":"MySQL基础","url":"/2024/09/29/MySQL%E5%9F%BA%E7%A1%80/","content":"DDL数据库\n创建数据库\nCREATE DATABASE IF NOT EXISTS dbtest CHARACTER SET &#x27;utf8&#x27;# 显示创建数据库时的语句SHOW CREATE DATABASE dbtest\n\n删除数据库\nDROP DATABASE dbtest\n\n表\n创建表\nCREATE TABLE 表名 IF NOT EXISTS ( 字段信息)# 显示创建表时的语句SHOW CREATE TABLE 表名# 展示表结构DESC 表名# 计算列(MySQL8特性)CREATE TABLE test ( a INT, b INT, c INT GENERATED ALWAYS AS (a+b) VIRTUAL)\n\n删除表\nDROP TABLE 表名\n\n修改表\nALTER TABLE 表名    ADD 字段\t# 添加字段    MODIFY 字段 # 修改字段\tDROP COLUMN 字段 # 删除字段\n\n清除表数据\nTRUNCATE 表名\n\n\nDROP、DELETE、TRUNCATE三者的区别？\n\nDROP和TRUNCATE属于DDL定于语言，执行后无法回滚，DELETE属于DML操作语言，会走事务，执行时会触发触发器，可被回滚\nDELETE不会立刻释放磁盘空间，DROP和TRUNCATE会\nDROP用于删除库和表，包括表结构，DELETE、TRUNCATE用于清除表数据\n从执行速度上来说，DROP &gt; TRUNCATE &gt; DELETE\n\nhttps://zhuanlan.zhihu.com/p/270331768\n\nDML增INSERT INTO 表名(字段信息)VALUES(数据1),(数据2);# 从查询中获取数据插入INSERT INTO 表名(字段1,字段2)SELECT 字段1,字段2 # 查询的字段一定要和添加到表的字段一一对应FROM 表\n\n删DELETE FROM 表名 WHERE ...# 联表删除DELETE m,u FROM employees m JOIN users u ON m.userid = u.userid WHERE m.userid = &#x27;Bbiri&#x27;\n\n改UPDATE 表名 SET ...,... WHERE ...UPDATE empl SET salary = salary * 1.2, hire_date = CURDATE()WHERE `name` LIKE &#x27;%a%&#x27;\n\n\n\n\nDML操作默认情况下，执行完都会自动提交数据如果希望执行完后不自动提交，则需要使用 SET autocommit &#x3D; FALSE\n\n数据类型数值类型整数类型\nTINYINT 1字节 （一般用于枚举数据，比如系统设定取值范围很小且固定场景）\nSMALLINT 2字节 （用于较小范围的统计数据，如工厂的固定资产库存等）\nMEDIUMINT 3字节 （用于较大整数计算，如车站客流量）\nINT 4字节 （取值范围足够大，一般不用考虑超限问题，如商品编号）（使用最多）\nBIGINT 8字节 （处理巨大整数才会用到。如大型门户网站的点击量等）\n\n可选属性：\n\nM: 宽度（MySQL8.0后不推荐）\nCREATE TABLE test( f1 INT, f2 INT(5), f3 INT(5) ZEROFILL  # 显示宽度5，当insert的值不足5位时，拿0填充； # 当使用 ZEROFILL 时，会自动添加 UNSIGNED)\n\nUNSIGNED: 无符号（正数）\n\n\n浮点类型\nFLOAT 4字节\nDOUBLE 8字节\n\nMySQL允许使用非标准语法 ：FLOAT(M,D) M-精度 D-标度 M&#x3D;整数位+小数位 D&#x3D;小数位 D&lt;&#x3D;M&lt;&#x3D;255 0&lt;&#x3D;D&lt;&#x3D;30\n浮点类型也可以加 UNSIGNED ，但是不会改变数据范围，无符号取值范围相当于有符号取值范围的一半。这是因为MySQL存储浮点格式为：符号、尾数、阶码。无论有没有符号，浮点数都会存储表示符号的部分。因此无符号取值范围相当于有符号取值范围大于0的部分\n如果不指定精度，则按照实际精度（由操作系统决定）显示\n如果小数位长度超过，则会四舍五入；如果整数位长度超过，则会报错\n定点数类型\nDECIMAL(M,D) M+2字节\n\n在存储同样范围的值时，DECIMAL通常使用更多的空间，float使用4个字节存储，double使用8个字节，而DECIMAL依赖于M和D的值\n位类型\nBIT(M) 1&lt;&#x3D;M&lt;&#x3D;64 占用约为(M+7)&#x2F;8字节\n\n使用SELECT查询位字段时，可以用BIN()或者HEX()函数查看\nBIN() # 2进制HEX() # 16进制\n\n\n\n日期与时间类型YEAR类型以4位字符串或数字格式表示YEAR类型，格式YYYY，最小值1901，最大值2155\n以2位字符串或数字表示（不推荐）\nDATE类型日期，不包括时间，需要3个字节存储空间\n格式：YYYY-MM-DD\nCURRENT_DATE()CURDATE()\n\n以下都可以写入\n&#x27;2020-10-01&#x27; &#x27;20201001&#x27; 20201001\n\nTIME类型时间，需要3个字节存储空间\n格式：HH:MM:SS\n\n可以插入天数 如&#39;D HH:MM:SS&#39;，D会转化为小时，计算格式为D*24+HH\n\n如果带冒号的【字符串】表示时间，如&#39;12:10&#39;，表示&#39;12:10:00&#39;\n\n如果不带冒号的【字符串或数字】表示时间，如1210，MySQL会将右边两位解析成秒，表示&#39;00:12:10&#39;\n\n如果插入一个不合法的字符串或数字，会自动转为&#39;00:00:00&#39;存储\n\n\nCURRENT_TIME()CURTIME()\n\nDATETIME类型日期+时间的组合，需要8个字节存储空间\n格式：YYYY-MM-DD HH:MM:SS \n\n以YYYY-MM-DD HH:MM:SS格式或者YYYYMMDDHHMMSS格式【字符串】插入时，最小值&#39;1000-01-01 00:00:00&#39;，最大值&#39;9999-12-03 23:59:59&#39;\n\n以YYYYMMDDHHMMSS格式【数字】插入时，会被转为YYYY-MM-DD HH:MM:SS格式\n\n\nTIMESTAMP类型时间戳，格式与DATETIME类型相同，只需要4字节存储，但时间范围小，只能存储 ‘1970-01-01 00:00:01 UTC’ 到 ‘2038-01-19 03:14:07 UTC’ 之间\n使用TIMESTAMP存储的同一个时间，在不同时区查询会显示不同时间\n\nTIMESTAMP与DATETIME区别：\n\nTIMESTAMP存储空间小，表示范围也比较小\n底层存储方式不同，TIMESTAMP存储的是毫秒值\n在计算日期或者比较大小时，TIMESTAMP更方便、更快\nTIMESTAMP与时区相关。TIMESTAMP会根据用户的时区不同显示不同的结果。而DATETIME只能反映插入时当地时区，其他时区的人查看数据会有误差\n\n\n\n开发经验：\nDATETIME使用最多，但是存储注册时间、商品发布时间等，推荐使用TIMESTAMP，更便于计算\n\n文本字符串类型CHAR&#x2F;VARCHAR类型\n\n\n类型\n特点\n长度\n长度范围\n占用空间\n\n\n\nCHAR(M)\n固定长度\nM\n0&lt;&#x3D;M&lt;&#x3D;255\nM个字节\n\n\nVARCHAR(M)\n可变长度\nM\n0&lt;&#x3D;M&lt;&#x3D;65535\n实际长度+1个字节\n\n\n\nVARCHAR最大有效长度由最大行大小和使用的字符集确定（65535并不准确）\n如果保存时数据实际长度比CHAR类型声明长度小，则会在右侧填充空格以达到指定长度。当MySQL检索CHAR类型数据时，会去除尾部空格\n检索VARCHAR类型数据时，会保留尾部空格\n\n\n\n\n类型\n空间\n时间\n适用场景\n\n\n\nCHAR(M)\n浪费存储空间\n效率高\n存储不大，速度要求高\n\n\nVARCHAR(M)\n节省存储空间\n效率低\n非CHAR的情况\n\n\n情况1：存储较短的信息，使用CHAR\n情况2：存储固定长度信息，使用CHAR\n情况3：频繁修改的字段，使用CHAR\n情况4：不同存储引擎中的情况：\n\nMyISAM存储引擎建议使用CHAR类型\nMEMORY存储引擎建议使用CHAR类型\nInnoDB存储引擎建议使用VARCHAR类型\n\nTEXT类型\n\n\n类型\n长度\n长度范围\n占空空间\n特点\n\n\n\nTINYTEXT\nL\n0&lt;&#x3D;L&lt;&#x3D;255\nL+2个字节\n可变长度，小文本\n\n\nTEXT\nL\n0&lt;&#x3D;L&lt;&#x3D;65535\nL+2个字节\n可变长度，文本\n\n\nMEDIUMTEXT\nL\n0&lt;&#x3D;L&lt;&#x3D;16777215\nL+3个字节\n可变长度，中等文本\n\n\nLONGTEXT\nL\n0&lt;&#x3D;L&lt;&#x3D;4294967295\nL+4个字节\n可变长度，长文本\n\n\n\n由于实际存储长度不确定，MySQL不允许TEXT类型作为主键\n\n实际开发中，如果存入内容不是特别大，建议使用CHAR，VARCHAR\n\nTEXT类型和BLOB类型删除后容易导致“空洞”，使得文件碎片比较多，所以频繁使用的表不建议包含TEXT类型，建议单独分出去\n\n\nENUM类型\n\n\n类型\n长度\n长度范围\n占空空间\n\n\n\nENUM\nL\n0&lt;&#x3D;L&lt;&#x3D;65535\n1或2个字节\n\n\n\n当ENUM类型包含1~255个成员时，需要1个字节存储\n当ENUM类型包含256~65535个成员时，需要2个字节存储\n\nCREATE TABLE test( season ENUM(&#x27;春&#x27;,&#x27;夏&#x27;,&#x27;秋&#x27;,&#x27;冬&#x27;，&#x27;unknow&#x27;))INSERT INTO test(season)VALUES(&#x27;春&#x27;),(&#x27;UNKNOW&#x27;), # 忽略大小写(1), # 可以使用索引(&#x27;1&#x27;);\n\nSET类型\n\n\n类型\n长度\n长度范围\n占空空间\n\n\n\nSET\nL\n0&lt;&#x3D;L&lt;&#x3D;64\n1&lt;&#x3D;L&lt;&#x3D;8 1个字节9&lt;&#x3D;L&lt;&#x3D;16 2个字节17&lt;&#x3D;L&lt;&#x3D;24 3个字节25&lt;&#x3D;L&lt;&#x3D;32 4个字节33&lt;&#x3D;L&lt;&#x3D;64 8个字节\n\n\nCREATE TABLE test( s ENUM(&#x27;A&#x27;,&#x27;B&#x27;,&#x27;C&#x27;))INSERT INTO test(s)VALUES(&#x27;A&#x27;),(&#x27;A,B&#x27;),(&#x27;A,B,C,A&#x27;), # 插入重复的SET类型成员时，会自动去重(&#x27;A,B,C,D&#x27;); # 插入不在SET内元素时会报错\n\n\n\n二进制类型BINARY&#x2F;VARBINARY类型类型CHAR和VARCHAR，只是他们存储的是二进制字符串\n\n\n\n类型\n特点\n长度范围\n占用空间\n\n\n\nBINARY(M)\n固定长度\n0&lt;&#x3D;M&lt;&#x3D;255\nM个字节\n\n\nVARBINARY(M)\n可变长度\n0&lt;&#x3D;M&lt;&#x3D;65535\n实际长度+1个字节\n\n\nBLOB类型可以存储一个二进制的大对象，比如图片、音频、视频等\n\n\n\n类型\n长度\n长度范围\n占空空间\n\n\n\nTINYBLOB\nL\n0&lt;&#x3D;L&lt;&#x3D;255\nL+1个字节\n\n\nBLOB\nL\n0&lt;&#x3D;L&lt;&#x3D;65535（相当于64KB）\nL+2个字节\n\n\nMEDIUMBLOB\nL\n0&lt;&#x3D;L&lt;&#x3D;16777215（相当于16MB）\nL+3个字节\n\n\nLONGBLOB\nL\n0&lt;&#x3D;L&lt;&#x3D;4294967295（相当于4GB）\nL+4个字节\n\n\n需要注意的是，实际开发中往往不会在数据库中存储大对象数据\n在使用TEXT和BLOB时需要注意以下几点\n\nBLOB和TEXT在执行了大量的删除和更新操作时，会在数据表中留下很多“空洞”。为了提高性能，建议定期使用OPTIMIZE TABLE功能对表进行碎片整理\n如果需要对大文本字段进行模糊查询，MySQL提供了前缀索引\n建议把BLOB或TEXT列分离到单独的表中\n\nJSON类型在MySQL 8.x版本中，JSON类型提供了可以进行自动验证的JSON文档和优化的存储结构，使得在MySQL中存储和读取JSON类型的数据更加方便高效\nCREATE TABLE test( js JSON);INSERT INTO test(js)VALUES (&#x27;&#123;&quot;name&quot;:&quot;xiaoming&quot;&#125;&#x27;)\n\n当需要检索JSON类型的字段中某个具体值时，可以使用-&gt;和-&gt;&gt;符号\nSELECT js -&gt; &#x27;$.name&#x27; AS j_name, js -&gt; &#x27;$.age&#x27; AS j_age, js -&gt; &#x27;$.address.province&#x27; AS j_provinceFROM test\n\n\n\n约束# 查看表中约束SELECT * FROM information_schema.table_constraintsWHERE table_name = &#x27;表名&#x27;;\n\n约束类型：\n\n列级约束\n主键约束、外键约束、唯一约束、检查约束、默认约束、非空约束、自增列约束\n\n表级约束\n主键约束、外键约束、唯一约束、检查约束\n\n\n非空约束关键字：NOT NULL\n# 在建表的时候添加约束CREATE TABLE test1( id INT NOT NULL, last_name VARCHAR(15) NOT NULL, email VARCHAR(25), salary DECIMAL(10,2));# 在修改时添加约束ALTER TABLE test1MODIFY email VARCHAR(25) NOT NULL;# 在修改时删除约束ALTER TABLE test1MODIFY email VARCHAR(25) NULL;\n\n\n\n唯一性约束关键字：UNIQUE\n特点：\n\n同一个表可以有多个唯一约束\n唯一约束可以是某一个列值唯一，也可以多个列组合值唯一\n唯一性约束允许列值为空，并且允许多个为空值\n在创建唯一约束时如果不命名，默认和列名相同\nMySQL会给唯一约束的列默认创建一个唯一索引\n\n# 在建表的时候添加约束CREATE TABLE test2( id INT UNIQUE, # 列级约束 last_name VARCHAR(15), email VARCHAR(25), salary DECIMAL(10,2),     # 表级约束 CONSTRAINT uk_test2_email UNIQUE(email));# 在修改时添加约束# 方式1ALTER TABLE test2MODIFY email VARCHAR(25) UNIQUE;# 方式2ALTER TABLE test2ADD CONSTRAINT uk_test2_sal UNIQUE(salary);# 复合的唯一性约束CREATE TABLE user( id INT, `name` VARCHAR(15), `password` VARCHAR(25), CONSTRAINT uk_user_name_pwd UNIQUE(`name`,`password`) # UNIQUE(`name`,`password`));# 删除唯一性约束-- 添加唯一性约束的列上也会自动创建唯一索引-- 删除唯一约束只能通过删除唯一索引的方式删除-- 删除时需要指定唯一索引名，唯一索引名和唯一约束名一致-- 如果创建唯一约束时未指定名字，如果是单列，默认和列名相同；如果是组合列，默认和()中排在第一个的列名相同ALTER TABLE userDROP INDEX uk_user_name_pwd;\n\n\n\n主键约束关键字：PRIMARY KEY\n特点： \n\n相当于唯一约束+非空约束的组合\n一个表最多一个主键约束\n主键约束对应表中的一列或多列（复合主键）\n如果是多列组合的复合主键约束，这些列都不允许为空值，且组合的值不允许重复\nMySQL的主键约束名总是PRIMARY，无法自定义\n创建主键约束时，系统会自动创建对应的主键索引。如果删除主键约束，对应索引也会自动删除\n不要修改主键字段值。如果修改了主键的值，有可能会破坏数据完整性\n\n# 在建表的时候添加约束CREATE TABLE test3( id INT PRIMARY KEY, # 列级约束 last_name VARCHAR(15), email VARCHAR(25), salary DECIMAL(10,2),  # 表级约束 # CONSTRAINT uk_test3_id PRIMARY KEY(id) # 自定义约束名无效，仍然为PRIMARY # PRIMARY KEY(last_name,email));# 在修改时添加约束ALTER TABLE test3ADD PRIMARY KEY(id);# 删除主键约束ALTER TABLE test3DROP PRIMARY KEY;\n\n\n\n自增列关键字：AUTO_INCREMENT\n特点：\n\n一个表最多一个自增长列\n当需要产生唯一标识符或顺序值时，可设置自增长\n自增长列约束的列必须是键列（主键列，唯一键列）\n自增约束的列数据类型必须是整数类型\n如果自增列指定了0和null，会在当前最大值的基础上自增；如果自增列手动指定了具体值，直接赋值为具体值\n\n# 在建表的时候添加约束CREATE TABLE test4( id INT PRIMARY KEY AUTO_INCREMENT, last_name VARCHAR(15), email VARCHAR(25), salary DECIMAL(10,2),);# 在修改时添加约束ALTER TABLE test3MODIFY id INT AUTO_INCREMENT;# 在修改时删除约束ALTER TABLE test3MODIFY id INT;\n\nMySQL 8.0将自增主键的计数器持久化到重做日志中。数据库重启自增变量不会变；\n此前版本放在内存中，数据库重启后自增变量会变\n外键约束关键字：FOREIGN KEY\n特点：\n\n从表的外键列，必须引用主表的主键或唯一约束列\n在创建外键约束时，如果不给外键约束命名，默认名不是列名，而是自动产生一个外键名\n创建表时就指定外键约束的话，先创建主表，再创建从表\n删表时，先删从表（或先删外键约束），再删主表\n当主表的记录被从表参照时，主编记录不允许被删除，需要先删除从表中依赖该记录的数据，才能删除主表中的数据\n一个表可以建立多个外键约束\n从表外键列 和 主表被参照列 名字可以不同，但数据类型必须一样，逻辑意义一致\n当创建外键约束时，系统默认会在所在的列上建立对应的普通索引。但是索引名是列名，不是外键约束名\n删除外键约束后，必须手动删除对应的索引\n\n# 在建表的时候添加约束# 建立主表CREATE TABLE dept1(    dept_id INT PRIMARY KEY AUTO_INCREMENT,    dept_name VARCHAR(15));# 建立从表CREATE TABLE emp1(    emp_id INT PRIMARY KEY AUTO_INCREMENT,    emp_name VARCHAR(15),    dept_id INT        CONSTRAINT fk_emp1_dept_id FOREIGN KEY(dept_id) REFERENCES dept1(dept_id));# 添加约束ALTER TABLE emp1ADD CONSTRAINT fk_emp1_dept_id FOREIGN KEY(dept_id) REFERENCES dept1(dept_id)# 删除约束# 1.先删除外键约束ALTER TABLE 从表名DROP FOREIGN KEY 外键约束名# 2.再删除索引ALTER TABLE 从表名DROP INDEX 索引名\n\n\n\n检查约束关键字：CHECK\n特点：\n\nMySQL 8.0中可以使用。5.7不支持，虽然可以添加，但无任何作用\n\nCREATE TABLE test( id INT PRIMARY KEY AUTO_INCREMENT, age INT CHECK(age &gt; 20), sex CHAR(2) CHECK(sex in (&#x27;男&#x27;,&#x27;女&#x27;)));# 删除约束ALTER TABLE testDROP CHECK 检查约束名;\n\n\n\n默认值约束关键字：DEFAULT\n# 在建表的时候添加约束CREATE TABLE test( id INT PRIMARY KEY AUTO_INCREMENT, age INT DEFAULT 20);# 在修改时添加约束ALTER TABLE testMODIFY age INT DEFAULT 20;# 删除约束ALTER TABLE testMODIFY age INT;\n\n\n\n\n非空约束、默认值约束、自增列约束可以在ALTER TABLE中用MODIFY修改（添加&#x2F;删除）\n其余约束需要注意修改方式，MODIFY&#x2F;ADD&#x2F;DROP\n\n视图\n视图是一种虚拟表，本身不具有数据\n视图建立在已有的表上，视图赖以建立的表称为基表\n视图的创建和删除只影响视图本身，不影响基表。但是对视图中的数据进行增删改时，基表数据也会相应变化，反之亦然\n向视图提供数据内容的语句为SELECT语句，可以将视图理解为存储起来的SELECT语句\n\n创建视图# 创建视图CREATE VIEW 视图名ASSELECT ...# 确定视图中字段名的方式1CREATE VIEW 视图名ASSELECT 字段1 AS 别名1, 字段2 AS 别名2, 字段3 AS 别名3FROM ...# 确定视图中字段名的方式2CREATE VIEW 视图名(别名1, 别名2, 别名3)\t# 字段个数需对应ASSELECT 字段1, 字段2, 字段3FROM ...\n\n\n\n查看视图# 查看数据库的表对象、视图对象SHOW TABLES;# 查看视图结构DESC 视图名;# 查看视图的属性信息SHOW TABLE STATUS LIKE &#x27;视图名&#x27;;# 查看视图的定义信息SHOW CREATE VIEW 视图名;\n\n\n\n修改视图数据修改\n\n视图数据修改同表操作\n要使视图可更新，视图中的行和基表中的行必须存在一对一的关系。以下情况都不支持更新：\n定义视图的时候指定了ALGORITHM = TEMPTABLE，视图将不支持INSERT和DELETE操作\n视图中不包含基表中所有被定义为非空又未指定默认值的列，视图将不支持INSERT操作\n在定义视图的SELECT语句中使用了JOIN联合查询，视图将不支持INSERT和DELETE操作\n在定义视图的SELECT语句后的字段列表中使用了数学表达式或子查询，视图将不支持INSERT，也不支持UPDATE使用了数学表达式、子查询的字段\n在定义视图的SELECT语句后的字段列表中使用了DISTINCT、聚合函数、GROUP BY、HAVING、UNION等，视图将不支持INSERT、UPDATE、DELETE\n在定义视图的SELECT语句中包含了子查询，而子查询中引用了FROM后面的表，视图将不支持INSERT、UPDATE、DELETE\n视图定义基于一个不可更新视图\n常量视图\n\n\n\n\n总的来说，视图作为虚拟表，主要用于方便查询，不建议更新数据\n\n视图修改\n# 方式1CREATE OR REPLACE VIEW 视图名ASSELECT ...# 方式2ALTER VIEW 视图名ASSELECT ...\n\n\n\n删除视图DROP VIEW IF EXISTS 视图名;\n\n\n基于视图A、B创建了视图C，如果将A或者B删除，会导致C的查询失败。这样的视图C需要手动删除或修改，否则影响使用\n\n总结优点：\n\n简化查询，操作简单\n减少数据冗余\n数据安全\n适应灵活多变的需求\n能够分解复杂的查询逻辑\n\n缺点：\n\n如果视图过多，会导致数据库维护成本的问题：\n基表数据变更，我们需要及时对相关视图进行维护。特别是基于嵌套的视图，维护会变得比较复杂，可读性差，容易变成系统的潜在隐患。因为创建视图的SQL查询可能会对字段重命名，也可能包含复杂的逻辑，这些都会增加维护的成本\n\n\n字符集SHOW VARIABLES LIKE &#x27;%character%&#x27;;# character_set_server: 服务器级别的字符集# character_set_database: 当前数据库的字符集# character_set_client: 服务器解码请求时使用的字符集# character_set_connection: 服务器处理请求时会把请求字符串从character_set_client转为character_set_connection# character_set_results: 服务器向客户端返回数据时使用的字符集# 修改数据库的字符集ALTER DATABASE 数据库名 CHARACTER SET &#x27;utf8&#x27;;# 修改表的字符集ALTER TABLE 表名 CONVERT TO CHARACTER SET &#x27;utf8&#x27;;# 查看MySQL支持的字符集SHOW CHARSET;SHOW CHARACTER SET;\n\n\n\n字符集级别\n服务器级别\n通过修改MySQL配置文件修改\n\n数据库级别\nCREATE DATABASE 数据库名[CHARACTER SET 字符集][COLLATE 比较规则];\n\n表级别\nCREATE TABLE 表名[CHARACTER SET 字符集][COLLATE 比较规则];\n\n列级别\nCREATE TABLE 表名 (  列名 类型 [CHARACTER SET 字符集] [COLLATE 比较规则],  ...);\n\nutf8与utf8mb4utf8字符集表示一个字符需要14个字节存储，但我们常用的一些字符使用13个字节就可以了。所以MySQL有两种utf8的字符集：\n\nutf8mb3：阉割的utf8字符集，只使用1~3个字节表示字符\nutf8mb4：标准的utf8字符集，使用1~4个字节表示字符\n\nutf8是utf8mb3的别名\n比较规则指的是对字符进行比较、排序的规则\n# 查看比较规则SHOW COLLATION LIKE &#x27;utf8%&#x27;# 一般使用utf8mb4_general_ci\n\n\nhttps://zhuanlan.zhihu.com/p/166682278\n\n请求到响应过程中字符集的变化\n我们知道客户端发给服务端的SQL语句，本质上就是一个字符串\n服务端在收到客户端的SQL语句后，会先使用系统变量character_set_client所指定的字符集对其进行解码，然后再使用系统变量character_set_connection所指定的字符集对其进行编码\n如果 系统变量character_set_connection所指定的字符集 与 SQL语句所指向的某列(字段)的字符集 不一致，则SQL语句还需要再次进行解码-编码操作\n最后，将查询结果先使用 具体的列(字段)使用的字符集 进行解码，再使用系统变量character_set_results所指定的字符集进行编码，并返回给客户端\n\n\n\n疑问：character_set_connection是否有必要？\n字符集的转换在请求过程中有两步，character_set_client-&gt;character_set_connection-&gt;列使用字符集\n而在响应过程中就一步，列使用字符集-&gt;character_set_results\n由此引发为什么不跳过character_set_connection这个问题的讨论，翻阅了一些资料，也没有找到一个能说服我的结论。\n有解释为 虽然字符串与列进行比较会使用列的字符集，但数据库操作并非都与表有关。\n如果是这样的解释的话，为什么不直接使用character_set_client指定的字符集？\n\n大小写规范\nWindows下不区分大小写\nLinux下：\n数据库名、表名、表别名、变量名严格区分大小写\n关键字、函数名称在SQL中不区分大小写\n列名与列的别名在所有情况下都忽略大小写\n\n\n\n\n建议：\n\n关键字和函数名全部大写\n\n数据库名、表名、表别名、字段名、字段别名等全部小写\n\nSQL语句必须以分号结尾\n\n\n\nsql_mode\n宽松模式\n严格模式\n\nselect @@session.sql_mode;select @@global.sql_mode;# 或者show variables like &#x27;sql_mode&#x27;;# 临时设置设置sql_mode（永久修改sql_mode需更改配置文件）SET GLOBAL sql_mode = &#x27;&#x27;;SET SESSION sql_mode = &#x27;&#x27;; # 多个模式用,分割\n\n\n\n用户与权限管理用户管理MySQL用户可以分为普通用户和root用户\n# 登录mysql -h hostname|hostIP -P port -u username -p DatabaseName -e &quot;sql语句&quot;\n\n\n-h后面接主机名或主机IP\n-P后面接端口号，默认端口3306，不使用该参数会自动连接到3306端口\n-u后面接用户名\n-p会提示输入密码\nDatabaseName指明登录到哪个数据库\n-e后面可以加SQL语句。登录后立刻执行该语句，然后退出MySQL服务器\n\n创建用户# 查看当前用户use mysql;select host,user from user;CREATE USER 用户名 [IDENTIFIED BY 密码];\n\n用户名由用户@host构成，host默认是%\nCREATE USER &#x27;zhangsan&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123456&#x27;;\n\n修改用户UPDATE mysql.user SET USER=&#x27;li4&#x27; WHERE USER=&#x27;zhangsan&#x27;;FLUSH PRIVILEGES;\n\n删除用户DROP USER 用户名[,用户名]; # 默认删除%下的用户，也可指定hostDROP USER &#x27;zhangsan&#x27;@&#x27;localhost&#x27;;\n\n设置密码\n修改自己的密码\n推荐写法：\nALTER USER USER() IDENTIFIED BY &#x27;新密码&#x27;;# 或者SET PASSWORD=&#x27;新密码&#x27;;\n\n修改其他用户的密码\nALTER USER 用户名 IDENTIFIED BY &#x27;新密码&#x27;;# 或者SET PASSWORD FOR 用户名=&#x27;新密码&#x27;;\n\n密码管理\n密码过期：要求定期修改密码\n密码重用限制：不允许使用旧密码\n密码强度评估：要求使用高强度密码\n\n权限管理权限列表SHOW PRIVILEGES;\n\n原则\n只授予能满足需要的最小权限\n创建用户时限制用户的登录主机\n为每个用户设置满足密码复杂度的密码\n定期清理不需要的用户，回收权限或删除用户\n\n授予权限授权的方式有两种，分别是通过角色赋予用户给用户权限和直接给用户授权\nGRANT 权限1,权限2... ON 数据库名称.表名称 TO 用户名 [IDENTIFIED BY &#x27;密码&#x27;];# 该操作如果没有该用户，会直接新建个用户# 授予通过网络登录的joe用户，对所有表的全部权限，密码设为123。注意这里唯独不包括GRANT的权限GRANT ALL PRIVILEGES ON *.* TO &#x27;joe&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123&#x27;;# 如果需要赋予包括GRANT的权限，添加参数 WITH GRANT OPTION 即可# 可以使用GRANT重复给用户添加权限，权限会叠加，而非覆盖\n\n查看权限# 查看当前用户权限SHOW GRANTS;SHOW GRANTS FOR CURRENT_USER;SHOW GRANTS FOR CURRENT_USER();# 查看其他用户的权限SHOW GRANTS FOR 用户名;\n\n回收权限REVOKE 权限1,权限2... ON 数据库名称.表名称 FROM 用户名;# 收回全部权限REVOKE ALL PRIVILEGES ON *.* FROM &#x27;joe&#x27;@&#x27;%&#x27;;\n\n\n\n权限表MySQL通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库中。这些权限表中最重要的是user表、db表，除此之外，还有table_priv表、column_priv表、procs_priv表。在MySQL启动时，这些数据库表中权限信息会读入内存。\n\n\n\n表名\n描述\n\n\n\nuser\n用户账户及权限信息\n\n\ndb\n数据库层级的权限\n\n\ntable_priv\n表层级的权限\n\n\ncolumn_priv\n列层级的权限\n\n\nprocs_priv\n存储的过程和函数权限\n\n\n访问控制当MySQL允许一个用户执行各种操作时，它首先核实用户向MySQL服务器发送的连接请求，然后确认用户的操作请求是否被允许。这个过程称为MySQL中的访问控制过程。MySQL的访问控制分为两个阶段：\n\n连接核实阶段\n当用户试图连接MySQL服务器时，服务器基于用户的身份以及用户是否提供正确的密码验证身份来确定接受或拒绝连接。即客户端用户会在连接请求中提供用户名、主机地址、用户密码，MySQL服务器接收到用户请求后，会使用user表中的host、user和authentication_string这三个字段匹配客户端提供信息。\n如果连接核实没有通过，服务器就完全拒绝访问；否则，服务器接收连接，然后进入等待用户请求阶段。\n\n请求核实阶段\n在建立连接后，对此连接上进来的每个请求，服务器检查该请求要执行什么操作、是否有足够的权限来执行它，这正是需要授权表中的权限列发挥作用的地方。这些权限可以来自user、db、table_priv和column_priv表。\n确认权限时，MySQL首先检查user表，如果指定的权限没有在user表中授予，就会继续检查db表，db表是下一安全层级，其中的权限限定于数据库层级，该层级的SELECT权限允许用户查看指定数据库的所有表中数据；如果在该层级没有找到限定的权限，则继续检查tables_priv表以及columns_priv表，如果所有权限表都检查完毕，但还没有找到允许的权限操作，MySQL将返回错误信息\n\n\n\n提示：MySQL通过向下层级的顺序检查权限表，但并不是所有的权限都要执行该过程。\n\n角色管理创建角色CREATE ROLE &#x27;role_name&#x27;[@&#x27;host_name&#x27;]\n\n角色名称的命名规则和用户名类似。如果host_name省略，默认是%，role_name不可省略\n分配角色权限GRANT ALL PRIVILEGES ON *.* TO 角色名;\n\n查看角色权限SHOW GRANTS FOR 角色名;# 查询当前角色SELECT CURRENT_ROLE(); # 如果角色未激活，结果将显示NONE\n\n回收角色权限REVOKE ALL PRIVILEGES ON *.* FROM 角色名;\n\n删除角色DROP ROLE 角色名;\n\n给用户分配角色GRANT 角色名 TO 用户名;\n\nMySQL创建角色后，默认都是没有激活的，也就是不能用，必须要手动激活\n激活角色# 方式1SET DEFAULT ROLE ALL TO 用户名; # 用户需要重新登录# 方式2SET GLOBAL activate_all_roles_on_login=&#x27;ON&#x27;; # 对所有角色永久激活\n\n回收用户的角色REVOKE 角色名 FROM 用户名;\n\n设置强制角色强制角色是给每个创建账户的默认角色，不需要手动设置。强制角色无法被回收或删除\nMySQL结构目录主要目录结构find / -name mysql\n\n\n数据库文件存放路径：/var/lib/mysql/\n数据目录对应着一个系统变量datadir\nshow variables like &#x27;datadir&#x27;;\n\n相关命令目录：/usr/bin和/usr/sbin\n\n配置文件目录：/usr/share/mysql和/etc/mysql\n\n\n数据库和文件系统的关系1.默认数据库\nmysql\nMySQL系统自带的核心数据库，存储了MySQL的用户信息和权限信息，一些存储过程、事件的定义信息，一些运行过程中产生的日志信息，一些帮助信息以及时区信息等\n\ninformation_schema\nMySQL系统自带的数据库，这个数据库保存着MySQL服务器维护的所有其他数据库的信息，比如有哪些表、哪些视图、哪些触发器、哪些列、哪些索引。这些信息并不是真实的用户数据，而是一些描述性信息，有时候也被称为元数据。在该数据库中提供了一些以innodb_sys开头的表，用于表示内部系统表\n\nperformance_schema\nMySQL系统自带的数据库，这个数据库主要保存MySQL服务器运行过程中的一些状态信息，可以用来监控MySQL服务的各类性能指标。包括统计最近执行了哪些语句，在执行过程的每个阶段都花费了多长时间，内存的使用情况等信息\n\nsys\nMySQL系统自带的数据库，这个数据库主要通过视图的形式把information_schema和performance_schema结合起来，帮助系统管理员和开发人员监控MySQL的技术性能\n\n\n2.数据库在文件系统中的表示每当创建一个数据库，MySQL会帮我们做两件事：\n\n在数据目录下创建一个和数据库名同名的子目录\n在该子目录下创建一个db.opt的文件（仅限MySQL5.7及之前版本），这个文件中包含了该数据库的各种属性，比如字符集和比较规则\n\n3.表在文件系统中的表示InnoDB存储引擎模式\n系统表空间\n默认情况下，InnoDB会在数据目录下创建一个ibdata1文件，大小为12M。这个文件就是系统表空间在文件系统上的表示。\n这是个自扩展文件，当不够用时会自己增加文件大小。\n从MySQL5.5.7到MySQL5.6.6之间的各个版本，表中的数据都会默认存储到系统表空间。\n\n独立表空间\n在MySQL5.6.6之后的版本，InnoDB会为每个表建立一个独立表空间，对应文件为数据库子目录下的.idb文件。\n\n5.7版本数据库文件夹下每个表会有.frm和.ibd两个文件，.frm用于存放表结构，.ibd用于存放表数据和索引。\n8.0版本每个表仅.ibd一个文件。\n\n\n\nMyISAM存储引擎模式数据与索引分开存储\n8.0版本中数据库文件夹下每个表会有.sdi、.MYD、.MYI三个文件\n\n.MYD存放表数据\n.MYI存放索引\n.sdi存放表结构（5.7版本中为.frm）\n\n","categories":["后端"],"tags":["MySQL"]},{"title":"Redis的单线程","url":"/2024/10/08/Redis%E7%9A%84%E5%8D%95%E7%BA%BF%E7%A8%8B/","content":"Redis是单线程还是多线程？Redis的网络IO和键值对读写是由一个线程来完成的，Redis在处理客户端的请求时，包括获取（socket读）、解析、执行、内容返回（socket写）等都由一个顺序串行的主线程处理，这就是所谓的“单线程”。这也是Redis对外提供键值存储服务的主要流程。\n但Redis的其他功能，比如持久化RDB、AOF、异步删除、集群数据同步等等，其实是由额外的线程执行的。\nRedis命令工作线程是单线程的，但是，对整个Redis来说，是多线程的。\n\n\n单线程为什么这么快？在Redis3.x单线程时代但性能依旧很快的主要原因：\n\n基于内存操作：所有数据存在内存中，因此所有的计算都是内存级别的，所以性能较高\n\n数据结构简单：Redis的数据结构是专门设计的，这些简单的数据结构的查找和操作的大部分复杂度都是O(1)，因此性能比较高\n\n多路复用和非阻塞IO：Redis使用IO多路复用功能来监听多个socket连接客户端，这样可以使用一个线程来处理多个请求，减少线程切换带来的开销，同时避免了IO阻塞\n\n避免上下文切换：因为是单线程模型，因此避免了不必要的上下文切换和多线程竞争，这就省去了多线程切换带来的时间和性能开销\n\n\n但是在Redis4.0中开始支持多线程了\n\n\n为什么引入多线程？既然单线程有这些优势，那么为什么引入多线程？\nRedis性能影响的因素有CPU、内存、网络IO，对于Redis主要的性能瓶颈在内存或者网络带宽而非CPU，特别是网络IO。\nRedis在处理网络数据时，调用epoll的过程是阻塞的，也就是说这个过程会阻塞线程，如果并发量很高，达到几万的QPS，此处可能会成为瓶颈。开启多线程除了可以减少由于网络I&#x2F;O等待造成的影响，还可以充分利用CPU的多核优势。\n从Redis6开始，将网络数据读写、请求协议解析通过多个IO线程来处理，解决网络IO问题。这点可以是“Redis单线程为什么那么快？”问题的补充。\n\n","categories":["后端"],"tags":["Redis"]},{"title":"Redis分布式锁","url":"/2024/10/09/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","content":"CAP分布式系统有三个指标：\n\nConsistency（一致性） \nAvailability（可用性） \nPartition tolerance （分区容错性）\n\n在一个分布式系统（指互相连接并共享数据的节点的集合）中，当涉及读写操作时，只能保证一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三者中的两个，另外一个必须被牺牲。 \n\nhttps://cloud.tencent.com/developer/article/2355483\n\n\n\n分布式锁分布式锁的刚需\n独占性\n任何时刻只能有且只有一个线程持有\n\n高可用\n\n集群环境下，不能因为一个节点宕机而出现获取锁和释放锁失败的情况\n高并发情况下，性能依旧良好\n\n\n防死锁\n必须有超时控制机制或者撤销操作，有个兜底终止跳出方案\n\n不乱抢\n不能私自释放其他线程获取的锁\n\n重入性\n同一个节点的同一个线程如果获取锁之后，它也可以再次获取这个锁\n\n\n\n\n简单实现# 获取锁SETNX lock thread1# 释放锁DEL lock\n\n问题：客户端宕机会导致锁一直未被释放，造成死锁。\n优化：\n# 获取锁SETNX lock thread1# 添加锁的过期时间，避免服务宕机引起的死锁EXPIRE lock 10# 释放锁DEL lock\n\n问题：由于SETNX和EXPIRE并非原子操作，可能存在刚SETNX完就宕机的情况，一样会导致死锁。\n优化：\n# 获取锁SET lock thread1 EX 10 NX# 释放锁DEL lock\n\n\n\n防止误删上方锁的简易实现中，还存在一定问题：\n一般情况下，我们设置的超时时间需要大于业务代码的执行时间，但如果业务代码中出现了异常情况，导致执行完成时间大于锁的超时时间，这就会导致锁过期后被删除，其他线程抢占到锁，如果此时代码执行完了，要去释放锁，就会把其他线程占用的锁给释放了。\n修改：\n\n在获取锁时存入线程标识（可以用UUID）\n在释放锁时先获取锁种的线程标识，判断是否与当前线程一致：\n如果一致则释放\n如果不一致则不释放\n\n\n\n# 获取锁SET lock thread1 EX 10 NX# 查询锁的线程标识GET lock# 如果当前线程为thread1，释放锁DEL lock\n\n\n上方为示例解释，线程标识判断需在业务代码中完成\n\n\n\n原子性问题上方防止误删的优化代码仍有一些问题：\n由于 判断线程标识一致性 和 释放锁 的操作不是原子性的，如果在判断线程标识一致性之后，发生了阻塞，此时锁过期被删除，另一个线程抢占到锁，当前线程阻塞结束再去释放锁，又会出现误删除问题。\n修改：\n\n使用Lua脚本解决多条命令原子性问题\nif redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then\treturn redis.call(&quot;del&quot;,KEYS[1])else\treturn 0end\n\n\n\n前置知识：\nLua中调用Redis的方式\nredis.call(&#x27;命令名称&#x27;, &#x27;key&#x27;, &#x27;其他参数&#x27;, ...)redis.call(&#x27;set&#x27;, &#x27;name&#x27;, &#x27;jack&#x27;)\n\nRedis中调用脚本的方式\nEVAL script numkeys key [key ...] arg [arg ...]EVAL &quot;return redis.call(&#x27;set&#x27;, &#x27;name&#x27;, &#x27;jack&#x27;)&quot; 0\n\n\n后面的0是脚本需要的key类型的参数个数。\n作用是区分key数组和arg数组，例如a b c d ，假设numkeys是2，说明前2个参数a和b是key，后2个参数c和d是arg。\n\nRedis调用脚本传参：\nEVAL &quot;return redis.call(&#x27;set&#x27;, KEYS[1], ARGV[1])&quot; 1 name jack\n\n\n\n分布式锁的简单实现（Python）\n def acquire_lock_with_timeout(conn, lock_name, acquire_timeout=3, lock_timeout=2):    &quot;&quot;&quot;    基于 Redis 实现的分布式锁    :param conn: Redis 连接    :param lock_name: 锁的名称    :param acquire_timeout: 获取锁的超时时间，默认 3 秒    :param lock_timeout: 锁的超时时间，默认 2 秒    :return:    &quot;&quot;&quot;    identifier = str(uuid.uuid4())    lockname = f&#x27;lock:&#123;lock_name&#125;&#x27;    lock_timeout = int(math.ceil(lock_timeout))    end = time.time() + acquire_timeout    while time.time() &lt; end:        # 如果不存在这个锁则加锁并设置过期时间，避免死锁        if conn.set(lockname, identifier, ex=lock_timeout, nx=True):            return identifier        time.sleep(0.001)    return Falsedef release_lock(conn, lock_name, identifier):    &quot;&quot;&quot;    释放锁    :param conn: Redis 连接    :param lockname: 锁的名称    :param identifier: 锁的标识    :return:    &quot;&quot;&quot;    unlock_script = &quot;&quot;&quot;    if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then        return redis.call(&quot;del&quot;,KEYS[1])    else        return 0    end    &quot;&quot;&quot;    lockname = f&#x27;lock:&#123;lock_name&#125;&#x27;    unlock = conn.register_script(unlock_script)    result = unlock(keys=[lockname], args=[identifier])    if result:        return True    else:        return False\n\n\n\n其他问题基于SETNX实现的分布式锁还存在其他一些问题：\n\n不可重入\n同一个线程无法多次获取同一把锁\n\n超时释放\n锁超时释放虽然可以避免死锁，但如果业务执行耗时较长，也会导致锁释放，存在安全隐患\n\n主从一致性\n如果Redis提供了主从集群，主从同步存在延迟，当主机宕机时，如果从机来不及复制，新上位的主机没有锁数据，就有可能有多个线程获取到锁\n\n\n现有的成熟工具集合：Redisson\n\npython可以使用python-redis-lock包，其内部也实现了锁的自动续约\n\n","categories":["后端"],"tags":["Redis"]},{"title":"RabbitMQ","url":"/2024/09/30/RabbitMQ/","content":"基本介绍不同消息队列选择\n\n\n\nRabbitMQ\nActiveMQ\nRocketMQ\nKafka\n\n\n\n公司&#x2F;社区\nRabbit\nApache\n阿里\nApache\n\n\n开发语言\nErlang\nJava\nJava\nScala &amp; Java\n\n\n协议支持\nAMQPXMPPSTOMPSMTP\nAMQPXMPPSTOMPOpenWireREST\n自定义协议\n自定义协议\n\n\n支持语言\n几乎支持所有\nJavaC&#x2F;C++PythonPHPPerl.NET等\nJava\n官方支持Java社区产出多种API，如PHP、Python等\n\n\n单机吞吐量\n每秒十万左右级别\n每秒数万级\n每秒十万+级\n每秒百万级\n\n\n消息延迟\n微秒级\n毫秒级\n毫秒级\n毫秒以内\n\n\n消息可靠性\n高完整的消息确认机制\n一般\n高内置消息表，消息保存到数据库实现持久化\n一般\n\n\nRabbitMQ核心概念\npublisher：消息发送者\nconsumer：消息消费者\nqueue：队列，存储消息\nexchange：交换机，负责路由消息\nvirtual-host：虚拟主机，起到数据隔离作用\nBroker：接收和分发消息的应用，RabbitMQ Server就是Message Broker\nChannel：如果每一次访问RabbitMQ都建立一个Connection，在消息量大的时候建立Connection的开销是巨大的，效率也较低。Channel是Connection内部建立的逻辑连接，如果应用程序支持多线程，通常每个线程创建单独的Channel进行通讯，AMQP method 包含了 Channel ID 帮助客户端和 Message Broker 识别Channel，所以Channel之间完全隔离。Channel作为轻量级的Connection极大减少了建立TCP连接的开销\n\nWork Queues\n多个消费者绑定到一个队列，可以加快消息处理速度\n同一条消息只会被一个消费者处理\n\n默认情况下，RabbitMQ会将消息依次轮询投递给绑定在队列上的每个消费者。但这并未考虑到消费者是否已经处理完消息，可能出现消息堆积。\n解决方案：设置不公平分发\n\n设置预取值\n开启手动应答\n\n\n预取值：\nhttps://blog.csdn.net/qq_43856972/article/details/130835883\nhttps://zhuanlan.zhihu.com/p/582836002\n\nFanout交换机Fanout交换机会将接收到的消息广播到每一个绑定的Queue，所以也叫广播模式\nDirect交换机Direct交换机会将接收到的消息根据规则路由到指定的Queue，因此称为定向路由\n\n每一个Queue都与交换机设置一个BindingKey\n发布者发送消息时，指定消息的RoutingKey\n交换机将消息路由到BindingKey与消息RoutingKey一致的Queue\n\nTopic交换机Topic交换机与Direct交换机类似，区别在于RoutingKey可以是多个单词的列表，并以.分割\nQueue与Exchange指定BindingKey时可以使用通配符：\n\n#：代指0个或多个单词\n*：代指一个单词\n\n例如：china.#、#.news\n可靠性生产者可靠性生产者重连配置重连相关设置，包括连接超时时长、重连间隔、最大重连次数等\n生产者确认RabbitMQ有Publisher Confirm和Publisher Return两种确认机制。开启确认机制后，在MQ成功收到消息后会返回确认消息给生产者。返回结果有以下情况：\n\n消息投递到了MQ，但是路由失败。此时会通过Publisher Return返回路由异常原因，然后返回ACK，告知消息投递成功\n临时消息投递到了MQ，并且入队成功，返回ACK，告知投递成功\n持久消息投递到了MQ，并且入队完成持久化，返回ACK，告知投递成功\n其他情况都会返回NACK，告知投递失败\n\n消息从 producer 到 exchange 则会返回一个 confirmCallback\n消息从 exchange 到 queue 投递失败则会返回一个 returnCallback\n\n如何处理生产者的确认消息？\n\n生产者确认需要额外的网络和系统资源开销，尽量不要使用\n如果一定要使用，无需开启Publisher Return机制，因为一般路由失败是自己业务问题\n对于nack消息可以有限次数重试，依旧失败则记录异常消息\n\n\nMQ可靠性在默认情况下，RabbitMQ会将接收到的信息保存在内存中以降低消息收发的延迟。这样会导致两个问题：\n\n一旦MQ宕机，内存中的消息会丢失\n内存空间有限，当消费者故障或处理过慢时，会导致消息积压，引发MQ阻塞\n\n数据持久化RabbitMQ实现数据持久化包括三个方面：\n\n交换机持久化\n创建时配置Durability为Durable，Transient为临时的\n\n队列持久化\n同上\n\n消息持久化\n配置delivery mode，1为临时的，2为持久化的\n\n\n\n补充：\n即使队列和消息都是持久化的，也不能完全保证消息的 100% 不丢失。例如：在消息尚未被刷写到磁盘时，RabbitMQ 服务器突然崩溃，这种情况下的消息仍然可能会丢失。此外，RabbitMQ 不保证消息的立即持久化，而是尽可能快地将消息保存到磁盘。\n如果需要强有力的持久化策略，需要结合生产者的确认模式。\n\nLazy Queue惰性队列，它有以下特征：\n\n接收到消息后直接存入磁盘而非内存（内存中只保留最近的消息，默认2048条）\n消费者要消费消息时才会从磁盘中读取并加载到内存\n支持数百万条的消息存储\n\n在3.12版本后，所有队列都是Lazy Queue模式，无法更改\n消费者可靠性自动应答消息发送成功后立刻被认为已经传送成功，这种模式需要在高吞吐量和数据传输安全性方面做权衡。\n这种模式仅适用在消费者可以高效并以某种速率能够处理这些消息的情况下使用。\n手动应答为了确认消费者是否成功处理消息，RabbitMQ提供了消费者确认机制（Consumer Acknowledgement）。当消费者处理消息结束后，应该向RabbitMQ发送一个回执，告知RabbitMQ自己消息处理状态。回执有三种可选值：\n\nack：成功处理消息，RabbitMQ从队列中删除该消息\nnack：消息处理失败，RabbitMQ需要再次投递消息\nreject：消息处理失败并拒绝该消息，RabbitMQ从队列中删除该消息\n\n消费失败处理当消费者出现异常时，消息会不断重新入队（requeue）到队列，再重新发送给消费者，如果一直异常，就会无限循环导致MQ的消息处理飙升，带来不必要的压力。\n当出现异常时，客户端尽量本地重试，而不是无限制重新入队。业务控制失败的处理情况，最终返回ack或者reject。\n延迟消息什么是延迟消息？延迟消息：生产者发送消息时指定一个时间，消费者不会立刻收到消息，而是在指定时间之后才收到消息。\n延迟任务：设置在一定时间之后才执行的任务\n死信交换机当一个队列中的消息满足下列情况之一时，将会称为死信（dead letter）：\n\n消费者reject或nack声明消费失败，并且消息的requeue参数设置为false\n\n消息是一个过期消息（达到了队列或消息本身设置的过期时间），超时无人消费\n\n队列设置x-message-ttl（简称TTL）属性，即可设置该队列中消息的过期时间，单位ms\n\n\n要投递的队列消息堆积满了，最早的消息可能成为死信\n\n\n如果队列通过x-dead-letter-exchange属性指定了一个交换机，那么该队列中的死信就会投递到这个交换机中。该交换机被称为死信交换机（Dead Letter Exchange，简称DLX），x-dead-letter-routing-key属性（简称DLK）可以将死信消息投递到指定交换机指定路由键的队列中去\n延迟队列延迟队列最重要的特性体现在延迟属性上，延迟队列中的元素是希望在指定时间到了以后取出和处理，简单来说，延迟队列就是用来存放需要指定时间被处理的消息的队列，即存放延迟消息的队列。\nRabbitMQ中的延迟队列可以看做死信队列的一种，即消息过期的情况，利用DLX+TTL实现。\n延迟队列优化单纯依靠DLX+TTL实现延迟队列会引发一个问题，队列中所有消息的过期时间是固定的，如果需求不同消息有不同的过期时间，这种方式就无法实现。\n优化方式：为每一条消息设置过期时间\n引发问题：有些情况下，即使消息过期，也无法立刻从队列中删除，这是因为每条消息是否过期是在即将投递到消费者之前判定的，如果第一条消息过期时间很长，即使后面的消息过期时间很短，也需要等到第一条消息执行完再处理后面的消息\n解决方案：延迟队列插件rabbitmq_delayed_message_exchange\n其他优先级队列队列设置参数x-max-priority可设置为优先级队列，参数值表示消息可以选取的优先级范围，如10代表消息可以选择0-10之间的优先级\n","categories":["后端"],"tags":["消息队列"]},{"title":"MySQL进阶","url":"/2024/09/29/MySQL%E8%BF%9B%E9%98%B6/","content":"索引的数据结构\nhttps://www.bilibili.com/video/BV1iq4y1u7vj?p=115\n\n索引设计原则哪些情况下适合创建索引\n字段的数值有唯一性限制 —— 唯一索引或主键索引\n\n频繁作为WHERE查询条件的字段\n\n经常GROUP BY和ORDER BY的列\n\nUPDATE、DELETE的WHERE条件列\n\nDISTINCT字段需要创建索引\n\n多表JOIN连接操作时，创建索引注意事项\n\n连接表数量不要超过3张\n对WHERE条件创建索引\n对连接的字段创建索引\n\n\n使用列的类型小的创建索引\n这里的类型大小指该类型表示的数据范围大小\n以整型为例，如果我们想要对某个整数列建立索引，在表示的整数范围允许的情况下，尽量让索引列使用较小的类型，比如能使用INT就不使用BIGINT，能使用MEDIUMINT就不使用INT，这是因为：\n\n数据类型越小，在查询时的比较操作越快\n数据类型越小，索引占用的存储空间就越小，一个数据页就可以存放更多记录，从而减少磁盘IO\n\n这个建议对表的主键来说更适用\n\n使用字符串前缀创建索引\nALTER TABLE shop ADD INDEX(address(12));\n\n在VARCHAR字段上建立索引，没必要对全字段建立索引，根据实际文本区分度决定索引长度\nCOUNT(DISTINCT LEFT(列名,索引长度))/COUNT(*) # 计算区分度\n\n引申问题：使用索引列前缀的方式无法支持使用索引排序\n\n区分度高（散列性高）的列适合作为索引\n列的基数指的是某一列当中不重复数据的个数\n在记录行数一定的情况下，列的基数越大，该列中的值越分散；列的基数越小，该列中的值越集中。最好为列的基数大的列创立索引，为基数太小的列创建索引效果可能不好。\nCOUNT(DISTINCT 列名)/COUNT(*)\n\n使用最频繁的列放在联合索引的左侧\n\n在多个字段都要创建索引的情况下，联合索引优于单值索引\n\n\n限制索引的数目建议单表索引数量不超过6个\n\n每个索引都需要占用磁盘空间\n索引会影响INSERT、UPDATE、DELETE等语句的性能\n优化器在优化查询时会对每个可以用到的索引进行评估，过多的索引会增加优化器生成执行计划的时间，降低查询性能\n\n哪些情况下不适合创建索引\n在WHERE使用不到的字段，不要设置索引\n数据量小的表最好不要使用索引\n有大量重复数据的列上不要创建索引\n避免对经常更新的表创建过多的索引\n不建议用无序的值作为索引\n删除不再使用或很少使用的索引\n不要定义冗余或重复的索引\n\n性能分析工具查看系统性能参数SHOW STATUS LIKE &#x27;参数&#x27;;\n\n一些常用性能参数：\n\nConnections: 连接MySQL服务器的次数\nUptime: MySQL服务器的上线时间\nSlow_queries: 慢查询的次数\nInnodb_rows_read: Select查询返回的行数\nInnodb_rows_inserted: 执行INSERT操作插入的行数\nInnodb_rows_updated: 执行UPDATE操作更新的行数\nInnodb_rows_deleted: 执行DELETE操作删除的行数\nCom_select: 查询操作的次数\nCom_insert: 插入操作的次数（批量插入只累加一次）\nCom_update: 更新操作的次数\nCom_delete: 删除操作的次数\n\n统计SQL的查询成本: last_query_coatSHOW STATUS LIKE &#x27;last_query_coat&#x27;;\n\n这个查询成本对应的就是SQL语句需要读取的页的数量\n\nSQL查询是个动态的过程\n\n位置决定效率：缓冲池&gt;内存&gt;磁盘\n批量决定效率：顺序IO&gt;随机IO\n\n\n慢查询日志默认情况下，MySQL数据库没有开启慢查询日志。如果不是调优需要，一般不建议开启该参数\n开启慢查询日志参数SHOW VARIABLES LIKE &#x27;%slow_query_log%&#x27;; # 查看慢查询日志是否开启SHOW VARIABLES LIKE &#x27;%long_query_time%&#x27;; # 查看时间阈值SET GLOBAL slow_query_log=&#x27;ON&#x27;;SET GLOBAL long_query_time=1; # 仅修改GLOBAL对当前session失效SET long_query_time=1; # 所以当前session也需要修改\n\n通过配置文件修改\n[mysqld]slow_query_log=ONlong_query_time=1\n\n定位慢查询的SQL通过mysqldumpslow（在服务器内执行，非MySQL）\nmysqldumpslow -a -s t -t 5 /var/lib/mysql/慢查询日志\n\n删除慢查询日志手动删除慢查询日志即可\nrm -rf 慢查询日志\n\n使用mysqladmin flush-logs重新生成查询日志文件，slow指定重新生成慢查询日志文件\nmysqladmin -uroot -p flush-logs slow\n\n\n慢查询日志都是使用该命令来删除重建的。但是要注意，一旦执行了这个命令，慢查询日志都只存在新的日志文件中，如果需要旧的查询日志，就必须事先备份。\n\n查看SQL执行成本SHOW VARIABLES LIKE &#x27;profiling&#x27;;SET profiling=&#x27;ON&#x27;; # 开启Show Profile\n\nSHOW PROFILES;SHOW PROFILE; # 针对最近一次查询SHOW PROFILE ALL FOR QUERY 2 # 指定Query ID\n\nshow profile常用查询参数：\n\nALL: 显示所有的开销信息\nBLOCK IO: 显示块IO开销\nCONTEXT SWITCHES: 上下文切换开销\nCPU: 显示CPU开销信息\nIPC: 显示发送和接收开销信息\nMEMORY: 显示内存开销信息\nPAGE FAULTS: 显示页面错误开销信息\nSOURCE: 显示和Source_function，Source_file，Source_line相关的开销信息\nSWAPS: 显示交换次数开销信息\n\n需要注意的结论：\n\nconverting HEAP to MyISAM：查询结果太大，内存不够，数据往磁盘上搬了\nCreating tmp table：创建临时表。先拷贝数据到临时表，用完再删除临时表\nCopying to tmp table on disk：把内存中临时表复制到磁盘上\nlocked\n\n如果在show profile诊断结果中出现了以上情况，则SQL语句需要优化\n\n注意：show profile命令将被弃用，我们可以从 information_schema 中的 profiling 数据表进行查看\n\nEXPLAIN定位到查询慢的SQL后，我们就可以使用EXPLAIN做针对性的分析查询语句。\n注意：使用EXPLAIN并不真正执行语句，只是查看执行计划\nEXPLAIN要语句输出的各列作用如下：\n\n\n\n列名\n描述\n\n\n\nid\n每个SELECT关键字都对应一个唯一的id\n\n\nselect_type\nSELECT关键字对应的那个查询的类型\n\n\ntable\n表名，每一行记录都对应着一个单表\n\n\npartitions\n匹配的分区信息\n\n\ntype\n针对表单的访问方法\n\n\npossible_keys\n可能用到的索引\n\n\nkey\n实际上使用的索引\n\n\nkey_len\n实际使用到的索引长度\n\n\nref\n当使用索引列等值查询时，与索引列进行等值匹配的对象信息\n\n\nrows\n预估的需要读取的记录条数\n\n\nfiltered\n某个表经过搜索条件过滤后剩余记录条数的百分比\n\n\nExtra\n一些额外信息\n\n\ntypeMySQL对某个表执行查询时的访问方法，又称”访问类型“\n\nconst\n对主键或者唯一索引进行等值查询，对单表的访问方法就是const\n\nsystem\n在const基础上，当表中只有一条记录，那么对该表的访问方法就是system，性能高于const，属于const的一种特殊情况\n前提条件：存储引擎对数据统计是精确的，由于Innodb不确定表正好有一行，所以在innodb中不会出现system\n\neq_ref\n联表查询中，关联条件是 主键或者唯一非空索引，则对该被驱动表的访问方式就是eq_ref\n\nref\n当通过普通的二级索引列与常量进行等值匹配时，对该表的访问方式就可能是ref\n\nref_or_null\n当通过普通的二级索引列与常量进行等值匹配时，如果该列的值也可以为NULL时，对该表的访问方式就可能是ref_or_null\n\nindex_merge\n单表访问时在某些场景下可以使用索引合并的方式来执行查询\n\nunique_subquery\n\nindex_subquery\nMySQL服务层会对SQL进行优化，上面两种type不会在存储引擎层出现\n\nrange\n任意索引的范围查询，包括BETWEENT、LIKE、IN、&gt;、&lt;等，都是range访问方法\n\nindex\n\nALL\n上面两种type都是全表扫描，区别在于index只需要查询索引树就可以拿到结果，而ALL需要遍历所有行\n\n\nExtra一些额外信息\n常见信息：\n\nusing index\n索引覆盖，想查找的数据都在索引树中，不需要回表再去查询聚簇索引\n\nusing index condition\n索引下推，如果搜索时需要大量回表，在回表之前，会先处理“下推”到存储引擎的过滤逻辑，过滤整理后才发到Server层进行处理\n\nusing where\n与using index condition相对，所有过滤处理都在Server层处理\n\nusing MRR\n对二级索引范围查询时，会先对二级索引的查询结果缓存并进行排序，然后统一去聚簇索引中回表查询，这样就可以把随机IO优化成顺序IO，提升效率\n\nusing join buffer（BNL、BKA）\n如果AB两表关联查询，A关联列上有索引而B没有，就会发生BNL优化，从A表中取10行数据放到Join Buffer内存空间中，再全表扫描B表和Join Buffer中这10行进行关联，然后循环这一步，直到A表所有数据都关联完\nBKA在BNL基础上，如果B表有索引，则配合MRR，将Join Buffer中的行进行排序后，去B表对应索引中查询，无需全表扫描\n\nusing union（indexs）\n如果多个查询条件都是索引，就会对索引进行合并，会出现using union，一般伴随type index_merge\n\nusing temporary\n表示语句执行过程中出现了临时表\n\nusing filesort\n通常出现在order by中，在查询之后需要额外单独进行一次排序，就会出现using filesort，可以通过将条件和排序字段组成联合索引进行优化\n\n\n查看重写后的SQL在使用EXPLAIN语句查看了某个查询的执行计划手，可以使用SHOW WARNINGS语句查看与这个查询的执行计划有关的扩展信息\nSHOW WARNINGS;\n\n\n\n索引优化与查询优化MySQL中提高性能的一个最有效方式就是对数据库设计合理的索引\n索引失效索引失效的几种情况：\n\n索引列参与运算、使用了函数、进行了类型转换（参数类型和字段类型不一致），会导致全表扫描，索引失效\n\n模糊查询时（LIKE语句），%位于条件首部，会导致索引失效\n\n不等于比较索引失效\n\n两列数据做比较，即便两列都创建了索引，索引也会失效\n\n查询条件使用or关键字，其中一个字段没有创建索引，则会导致整个查询语句索引失效；\nor两边为“&gt;”和“&lt;”范围查询时，索引失效\n\n查询条件使用is null时正常走索引，使用is not null时，不走索引\n\n查询条件使用not in时，如果是主键则走索引，如果是普通索引，则索引失效；\n查询条件使用not exists时，索引失效\n\n联合索引不满足最左匹配原则\n\n范围查询导致联合索引右侧列索引失效\n\n\n关联查询优化\n外连接\n给关联条件字段加上索引\n\n内连接\n对于内连接来说，查询优化器可以决定 驱动表 与 被驱动表\n\n如果关联条件字段只在一个表中有索引，那么该表将作为 被驱动表\n\n如果关联条件字段在两个表中都有索引，会选择数据量小的表作为 驱动表（小表驱动大表）\n\n\n\n\nJOIN语句原理JOIN本质上是各个表之间数据的循环匹配\n简单嵌套循环连接（Simple Nested-Loop Join）假设表A数据100条，表B数据1000条，则循环100*1000次，开销如下：\n\n\n\n开销统计\nSNLJ\n\n\n\n外表扫描次数\n1\n\n\n内表扫描次数\nA\n\n\n读取记录数\nA+B*A\n\n\nJOIN比较次数\nA*B\n\n\n回表读取记录次数\n0\n\n\n索引嵌套循环连接（Index Nested-Loop Join）INLJ的优化思路主要是为了减少内层表数据的匹配次数，要求被驱动表上有索引\n\n\n\n开销统计\nINLJ\n\n\n\n外表扫描次数\n1\n\n\n内表扫描次数\n0\n\n\n读取记录数\nA+B(match)\n\n\nJOIN比较次数\nA*Index(Height)\n\n\n回表读取记录次数\nB(match)（if possible）\n\n\n\nINLJ每次JOIN的比较，其实就是一次索引查找，这里的Index(Height)个人理解为树的高度*二分查找的成本\n\n块嵌套循环连接（Block Nested-Loop Join）扫描一个表的过程其实是先把这个表从磁盘上加载到内存中，然后从内存中比较匹配条件是否满足。但内存里可能并不能完全存放的下表中所有的记录，所以在扫描表前边记录的时候后边的记录可能还在磁盘上，等扫描到后边记录的时候可能内存不足，所以需要把前边的记录从内存中释放掉。我们前边又说过，采用Simple Nested-Loop Join算法的两表联接过程中，被驱动表可是要被访问好多次的，如果这个被驱动表中的数据特别多而且不能使用索引进行访问，那就相当于要从磁盘上读好几次这个表，这个I&#x2F;O代价就非常大了，所以我们得想办法：尽量减少访问被驱动表的次数。\n当被驱动表中的数据非常多时，每次访问被驱动表，被驱动表的记录会被加载到内存中，在内存中的每一条记录只会和驱动表结果集的一条记录做匹配，之后就会被从内存中清除掉。然后再从驱动表结果集中拿出另一条记录，再一次把被驱动表的记录加载到内存中一遍，周而复始，驱动表结果集中有多少条记录，就得把被驱动表从磁盘上加载到内存中多少次。所以我们可不可以在把被驱动表的记录加载到内存的时候，一次性和多条驱动表中的记录做匹配，这样就可以大大减少重复从磁盘上加载被驱动表的代价了。这也就是Block Nested-Loop Join算法的思想。\n\n\n\n开销统计\nBNLJ\n\n\n\n外表扫描次数\n1\n\n\n内表扫描次数\nA*used_column_size&#x2F;join_buffer_size+1\n\n\n读取记录数\nA+B*(A*used_column_size&#x2F;join_buffer_size)\n\n\nJOIN比较次数\nA*B\n\n\n回表读取记录次数\n0\n\n\n\nA*used_column_size&#x2F;join_buffer_size是join buffer分批加载表A记录的批次数\n也可以写成 A&#x2F;(join_buffer_size&#x2F;used_column_size)，方便理解\n\n总结\n整体效率：INLJ &gt; BNLJ &gt; SNLJ\n永远用小结果集驱动大结果集（本质是减少外层循环的数据数量）\n为被驱动表匹配的条件添加索引（减少内层表的循环匹配次数）\n适当增加join buffer的大小（一次缓存的数据越多，内表的扫描次数就越少）\n减少驱动表不必要的字段查询（字段越少，join buffer缓存的数据就越多）\n\n注意：从MySQL的8.0.20版本版本开始将废弃BNLJ，因为从MySQL8.0.18版本开始加入了hash join，默认都会使用hash join\n子查询优化子查询可以一次性完成很多逻辑上需要多个步骤才能完成的SQL操作。但是子查询的执行效率不高：\n\n执行子查询时，MySQL需要为内层查询语句的查询结果建立临时表，然后外层查询语句从临时表中查询记录。查询完成后再撤销这些临时表。这样就会消耗过多的CPU和IO资源，产生大量的慢查询\n子查询结果集存储的临时表，不会存在索引，所以查询性能会受到一定影响\n对于返回结果集比较大的子查询，其对查询性能得意影响也就越大\n\n优化方式：使用连接查询来代替子查询\n排序优化在MySQL中支持两种排序方式，分别是FileSort和Index排序\n\nIndex排序中，索引可以保证数据的有序性，不需要再排序，效率更高\nFileSort排序一般在内存中尽显，占用CPU较多。如果待排结果较大，会产生临时文件IO到磁盘进行排序的情况，效率较低\n\n优化建议：\n\n可以在WHERE子句和ORDER BY子句中使用索引，目的是在WHERE子句中避免全表扫描，在ORDER BY子句中避免使用FileSort排序\n尽量使用Index完成ORDER BY排序。如果WHERE和ORDER BY后面是相同列就使用单索引；如果不同就使用联合索引\n无法使用Index时，需要对FileSort方式进行调优\n\n索引情况使用order by时，以下情况会导致索引失效：\n\n无过滤条件（没有WHERE或者LIMIT）\n对不同的索引列使用order by\n不满足最左匹配原则\n排序方式不同，多个字段要么同时升序，要么同时降序\n\nFileSort算法：双路排序和单路排序\n双路排序（慢）\nMySQL4.1之前使用双路排序，字面意思是两次扫描磁盘，最终得到数据\n\n读取行指针和order by列，对他们进行排序\n然后根据排好序的列表，重新读取对应数据输出\n\n\n单路排序（快）\n从磁盘读取查询需要的所有列，按照order by列进行排序，然后扫描排序后的列表进行输出。它的效率更快一些，避免了二次读取数据，并且把随机IO变成了顺序IO，但是会使用更多的空间\n\n\n引申问题：\n总体而言，单路排序优于双路排序，但是单路可能存在以下问题：\n\n单路比多路占用更多空间，有可能取出数据总大小超过了sort_buffer的容量，导致每次只能取sort_buffer容量大小的数据进行排序（创建tmp文件，多路合并），排完再取sort_buffer容量大小数据…从而多次IO\n单路本来想省一次IO操作，反而导致了大量的IO操作，得不偿失\n\n优化：\n\n尝试提高sort_buffer_size\n尝试提高max_length_for_sort_data\norder by时select具体字段，避免使用select *\n\nGROUP BY优化\ngroup by使用索引的原则几乎和order by一样，group by即使没有过滤条件用到索引，也可以直接使用索引\ngroup by 先排序再分组，遵照索引的最佳左前缀原则\n当无法使用索引列，增大max_length_for_sort_data和sort_buffer_size参数的设置\nwhere效率高于having，能写在where的条件就不要写在having中\n减少使用order by。order by、group by、distinct这些语句较为耗费CPU，数据的CPU资源是极其宝贵的\n包含了order by、group by、distinct这些查询的语句，where条件过滤出来的结果集请保持在1000行以内，否则SQL会很慢\n\n分页查询优化一般分页查询时，通过创建覆盖索引能够比较好地提高性能。\n当遇到如LIMIT 2000000,10这种情况，优化思路：在索引上完成排序分页，最后根据主键关联回原表查询所需要的其他列内容\nSELECT * FROM student t,(SELECT id FROM student ORDER BY id LIMIT 2000000,10) a WHERE t.id=a.id;\n\n\n\n覆盖索引定义：一个索引包含了满足查询结果的数据就叫覆盖索引\n优点：\n\n避免回表\n避免了对主键的二次查询，减少了IO操作\n\n可以把随机IO变成顺序IO加快查询效率\n由于覆盖索引是按键值的顺序存储的，对于IO密集型的范围查找来说，对比随机从磁盘读取每一行的数据IO要少得多，因此利用覆盖索引在访问时也可以把磁盘的随机读取IO转变为索引查找的顺序IO\n\n\n缺点：\n\n维护成本\n\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段\n索引下推Index Condition Pushdown（ICP）是MySQL5.6中新特性，是一种存储引擎层使用索引过滤数据的优化方式。\n为了理解ICP是如何工作的，我们先了解下没有使用ICP的情况下，MySQL是如何查询的：\n\n存储引擎读取索引记录；\n根据索引中的主键值，定位并读取完整的行记录；\n存储引擎把记录交给Server层去检测该记录是否满足WHERE条件。\n\n使用ICP的情况下，查询过程如下：\n\n读取索引记录（不是完整的行记录）；\n判断WHERE条件部分能否用索引中的列来做检查，条件不满足，则处理下一行索引记录；\n条件满足，使用索引中的主键去定位并读取完整的行记录（就是所谓的回表）；\n存储引擎把记录交给Server层，Server层检测该记录是否满足WHERE条件的其余部分。\n\n本质上ICP是以降低回表和访问存储引擎的次数，提高查询效率。\n使用条件：\n\n只能用于range、 ref、 eq_ref、ref_or_null访问方法；\n\n只能用于InnoDB和 MyISAM存储引擎及其分区表；\n\n对InnoDB存储引擎来说，索引下推只适用于二级索引（也叫辅助索引）;\n\n索引下推的目的是为了减少回表次数，也就是要减少IO操作。对于InnoDB的聚簇索引来说，完整的行记录已经加载到缓存区了，索引下推也就没什么意义了。\n\n\n引用了子查询的条件不能下推；\n\n引用了存储函数的条件不能下推，因为存储引擎无法调用存储函数。\n\n\n其他优化EXISTS和IN的区分SELECT * FROM A WHERE cc IN (SELECT cc FROM B)SELECT * FROM A WHERE cc EXISTS (SELECT cc FROM B WHERE B.cc=A.cc)\n\n选择标准可以理解为小表驱动大表。\n当A小于B时，用EXISTS；当B小于A时，用IN。\nCOUNT(*)、COUNT(1)、COUNT(具体字段)效率前提：不存在空数据（因为count(具体字段)会忽视空数据，其余两种不会，因为场景不同，所以存在空数据的情况下，比较效率是没有意义的） \n\nCOUNT(*)和COUNT(1)没有本质上的区别\n\n如果是MyISAM存储引擎，时间复杂度为O(1)，因为MyISAM的每张表都有一个meta信息存储了row_count值\n如果是InnoDB存储引擎，时间复杂度为O(n)，因为InnoDB支持事务，采用行级锁和MVCC机制，无法像MyISAM一样维护一个row_count变量，因此需要全表扫描\n\n在InnoDB中，如果使用COUNT(具体字段)来统计数据行，尽量采用二级索引。因为主键采用的聚簇索引包含信息更多，占用资源也更多。对于COUNT(*)和COUNT(1)，它们不需要查找具体行，只是统计行数，系统会自动采用占用空间更小的二级索引进行统计（判断依据为key_len），当没有二级索引时才会采用主键索引进行统计\n\n\nSELECT *尽量避免使用select *，原因如下：\n\nMySQL在解析的过程中，会通过查询数据字典将*转换为所有列名，增加了资源耗费\n无法使用覆盖索引\n对表关联等使用到了buffer的操作会产生影响\n\nLIMIT 1针对的是全表扫描的SQL语句，如果确定结果集只有一条，加上LIMIT 1，当找到一条结果就不会再继续扫描了，加快查询结果\n但如果数据表已经对字段建立了唯一索引，就可以通过索引进行查询，不会进行全表扫描，那么就不需要加LIMIT 1\n范式在关系型数据库中，关于数据表设计的基本原则、规则就称为范式\n目前关系型数据库有六种常见范式，按照范式级别，从低到高分别是：第一范式、第二范式、第三范式、巴斯-科德范式、第四范式和第五范式\n键\n超键：能唯一标识元组的属性集叫做超键\n候选键：如果超键不包括多余的属性，那么这个超键就是候选键\n主键：用户可以从候选键中选择一个作为超键\n外键：如果数据表R1中的某个属性集不是R1的主键，而是另一个表R2的主键，那么这个属性集就是表R1的外键\n主属性：包含在任一候选键中的属性称为主属性\n非主属性：与主属性相对，不包含在任何一个候选键中的属性\n\n第一范式第一范式主要确保数据表中每个字段的值必须具有原子性，也就是说数据表中的每个字段的值都是不可再次拆分的最小数据单元。\n第二范式在满足第一范式的基础上，还要满足数据表里的每一条记录，都是可唯一标识的，而且所有非主键字段，都必须完全依赖主键，不能只依赖主键的一部分。\n举例：\n比赛表包含 球员编号、姓名、年龄、比赛编号、比赛时间和比赛场地等信息，这里的主键为（球员编号，比赛编号），可以通过主键决定如下关系：\n（球员编号，比赛编号）-&gt; （姓名，年龄，比赛编号，比赛时间，比赛场地）\n\n但它不满足第二范式，因为表中字段之间还存在如下关系：\n（球员编号）-&gt; （姓名，年龄）（比赛编号）-&gt; （比赛时间，比赛场地）\n\n\n\n第三范式在满足第二范式的基础上，确保数据表中的每一个非主键字段与主键字段直接相关，也就是说，要求数据表中的所有非主键字段不能依赖于其他非主键字段。非主键属性之间不能有依赖关系，必须相互独立。\n举例：\n部门信息表包含 部门编号、部门名称、部门简介等信息\n员工信息表包含 员工编号、姓名、部门编号。列出部门编号后就不能再将部门名称等信息再加入到员工表中。\n小结\n第一范式，确保每列保持原子性\n第二范式，确保每列和主键完全依赖\n第三范式，确保每列和主键直接相关\n\n范式优点：\n\n数据的标准化有助于消除数据库中的数据冗余，第三范式通常被认为再性能、扩展性和数据完整性方面达到了最好的平衡\n\n范式缺点：\n\n可能降低查询的效率。因为范式等级越高，设计出来的数据表就越多、越精细，数据冗余度越低，进行查询的时候可能就需要关联多表，这不仅代价昂贵，也可能使一些索引策略无效\n\n范式只是提出了设计的标准，实际上设计时未必一定要符合这些标准。在开发中，可能会通过增加少量的冗余来提高数据库的读性能，减少关联查询的次数，实现空间换时间的目的。反范式化也是一种优化思路。\n巴斯-科德范式巴斯-科德范式，又称巴斯范式（BCNF），是对第三范式的改进，所以称为修正的第三范式，或扩充的第三范式，而不能称为第四范式。\n它在第三范式的基础上消除主属性对候选键的部分函数依赖和传递函数依赖。\nBC范式既检查非主属性，又检查主属性。当只检查非主属性时，就成了第三范式。满足BC范式的关系都必然满足第三范式。或者还可以换一种说法：若一个关系达到了第三范式，并且它只有一个候选码，或者它的每个候选码都是单属性，则该关系自然达到BC范式。一般来说，一个数据库设计符合3NF或BCNF就可以了。\n举例：\n学生导师表，字段包含：学生ID，专业，导师，专业GPA\n其中学生ID和专业是联合主键，该表满足第三范式，但是这里存在另一个依赖关系：专业 依赖于 导师，所以该表的部分主键依赖于非主键属性，我们可以拆分成两个表：\n学生专业表（学生ID，专业，专业GPA）\n导师表（导师，专业）\n第四范式第四范式在满足巴斯范式的基础上，消除非平凡且非函数依赖的多值依赖（即把同一表内的多对多关系删除）\n举例：\n职工表（职工编号，职工孩子姓名，职工选修课程）\n在这个表中，同一个职工可能会有多个职工孩子姓名，同样，同一个职工也可能会有多个职工选修课程，即这里存在着多值事实，不符合第四范式\n第五范式在第四范式的基础上，消除不是由候选键所蕴含的连接依赖。如果关系模式R中的每一个连接依赖均由R的候选键所蕴含，则此关系模式符合第五范式\n设计表的设计原则\n数据表的个数越少越好\n\n数据表中的字段个数越少越好\n上述的个数少是相对的，需在数据冗余和检索效率中进行平衡\n\n数据表中联合主键的字段越少越好\n联合主键字段越多，占用索引空间越大\n\n使用主键和外键越多越好\n数据库的设计实际上就是定义各种表，以及各种字段之间的关系。这些关系越多，证明实体之间的冗余度越低，利用度越高\n\n\n“三少一多”原则的核心就是简单可复用\n\n这些原则不是绝对的，有时候我们需要牺牲数据的冗余度来换取数据处理的效率\n\n事务一组逻辑操作单元\nACID特性\n原子性\n事务被视为一个不可分割的最小单位，它要么完全执行，要么完全不执行\n\n一致性\n一致性保证了事务的执行将数据库从一个一致的状态转变到另一个一致的状态\n\n隔离性\n隔离性是指当多个事务同时对数据库进行操作时，每个事务都是独立的，一个事务的操作不会影响到其他事务\n\n持久性\n持久性意味着一旦事务被提交，它对数据库的修改就是永久性的，即使系统发生故障也不会丢失\n\n\n如何使用事务显式事务开启事务\nBEGIN;# 或者START TRANSACTION;\n\nSTART TRANSACTION相较于BEGIN，后面可以跟随几个修饰符：\n\nREAD ONLY：标识当前事务是一个只读事务\n只读事务只是不允许修改其他事务也可以访问的表中数据，对于临时表来说，由于它们只在当前会话中可见，所以只读事务也是可以对临时表进行修改的\n\nREAD WRITE：标识当前事务是一个读写事务\n\nWITH CONSISTENT SNAPSHOT：开启一致性读\n\n\n提交事务&#x2F;中止事务（回滚）\n# 提交事务COMMIT;# 回滚事务ROLLBACK;# 将事务回滚到某个保存点ROLLBACK [TO SAVEPOINT];\n\n# 创建保存点SAVEPOINT 保存点名称;# 删除某个保存点RELEASE SAVEPOINT 保存点名称;\n\n隐式事务默认情况下，如果我们不显式使用BEGIN或START TRANSACTION去开启一个事务，那么每一条语句都算是一个独立的事务，这种特性称之为事务的自动提交\n如何关闭自动提交？\nSET autocommit = FALSE; # 针对于DML操作是有效的，对DDL操作是无效的\n\n或者显式创建一个事务，DML操作就不会自动提交数据\n隐式提交数据的情况\n数据定义语言（DDL）\n\n隐式使用或修改 mysql数据库中的表\n\n事务控制或关于锁定的语句\n\n上一个事务还没有提交或回滚，又开启了另一个事务，会隐式提交上一个事务\n将autocommit从关闭调为开启时，也会隐式提交前边语句所属的事务\n使用LOCK TABLES、UNLOCK TABLES等关于锁定的语句也会隐式提交前边语句所属的事务\n\n\n加载数据的语句\n使用LOAD DATA语句来导入数据时，也会隐式提交前边语句所属的事务\n\n关于MySQL复制的语句\n使用START SLAVE、STOP SLAVE、RESET SLAVE、CHANGE MASTER TO等语句也会隐式提交前边语句所属的事务\n\n其他的一些语句\n\n\ncompletion_typeSET @@completion_type = 1;\n\n\ncompletion_type=0，这是默认情况。当我们执行COMMIT时会提交事务，在执行下一个事务时，还需要使用BEGIN或者START TRANSACTION开启\ncompletion_type=1，这种情况下，当我们提交事务后，相当于执行了COMMIT AND CHAIN，也就是开启一个链式事务，即当我们提交事务后会开启一个相同隔离级别的事务\ncompletion_type=2，这种情况下，当我们提交事务后，相当于执行了COMMIT AND RELEASE，也就是当我们提交后，会自动与服务器断开连接\n\n事务分类\n扁平事务\n带有保存点的扁平事务\n链事务\n嵌套事务\n分布式事务\n\n事务隔离级别数据并发问题\n脏写\n一个事务将另一个事务的更新回滚回最初状态\n\n脏读\n一个事务读取到另一个事务还没有提交的数据\n\n不可重复读\n一个事务先后读取同一条数据，但两次读取的数据不同\n\n幻读\n一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这行数据已经存在（这个数据可能是由另一事务插入的，这些记录被称为幻影记录）\n\n\n严重性：脏写 &gt; 脏读 &gt; 不可重复读 &gt; 幻读\n\n脏写的说法有点太理论。实际上脏写是不允许发生的。\n两个事务同时操作一条数据的情况下，先操作数据的事务会锁定操作的那一行数据，其他事务无法对这条数据进行更新操作的。\n也就是说脏写实际上是不可能发生的。\n\nSQL四种隔离级别\nREAD UNCOMMITTED：读未提交\n所有事务都可以看到其他未提交事务的执行结果\n不能避免脏读、不可重复读、幻读\n\nREAD COMMITTED：读已提交\n一个事务只能看到已经提交事务所做的改变\n可以避免脏读，但不能避免不可重复读、幻读\n\nREPEATABLE READ：可重复读\n事务A读到一条数据后，事务B对该数据进行了修改并提交，那么事务A再次读取该数据，读到的仍然是原本的内容\n可以避免脏读、不可重复读，但不能避免幻读\n这是 MySQL InnoDB引擎 的默认隔离级别\n\nSERIALIZABLE：可串行化\n强制事务排序，所有并发问题都可以避免，但性能十分低下\n可以避免脏读、不可重复读、幻读\n\n\nSET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL 隔离级别;\n\n\n\n锁\n全局锁\n锁定数据库中的所有表\n\n表级锁\n每次操作锁住整张表\n\n行级锁\n每次操作锁住对应的行数据\n\n\n全局锁全局锁就是对整个数据库实例加锁，加锁后整个实例就处于只读状态，后续的DML的写语句，DDL语句，已经更新操作的事务提交语句都将被阻塞。\n典型场景是做全库的逻辑备份，对所有的表进行锁定，从而获取一致性视图，保证数据的完整性。\nflush tables with read lock; # 上锁unlock tables; # 解锁\n\n\nhttps://www.bilibili.com/video/BV1Kr4y1i7ru/?p=123\n\n表级锁每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。应用在MyISAM、InnoDB、BDB等存储引擎中。\n分类：\n\n表锁\n元数据锁（meta data lock，MDL）\n意向锁\n\n表锁表锁，分为两类：\n\n表共享读锁（read lock）\n所有客户端可读不可写\n\n表独占写锁（write lock）\n当前客户端可读可写，其余客户端不可读不可写\n\n\nlock tables 表名 read/write;unlock tables;\n\n\n\n元数据锁MDL加锁过程是系统自动控制的，无需显示使用，在访问一张表的时候会自动加上。MDL锁主要作用是维护表元数据的一致性，在表上有活动事务的时候，不可以对元数据进行写入操作。\n为了避免DML与DDL冲突，保证读写的正确性。\n当对一张表进行增删改查时，加MDL读锁（共享）；当对表结构进行变更操作时，加MDL写锁（排他）\n意向锁为了避免DML在执行时，加的行锁与表锁的冲突，在InnoDB中引入了意向锁，使得表锁不用检查每行数据是否加锁，使用意向锁来减少表锁的检查。\n\n意向共享锁（IS）\n由语句 select … lock in share mode 添加\n与表锁共享锁（read）兼容，与表锁排他锁（write）互斥\n\n意向排他锁（IX）\n由语句 insert、update、delete、select … for update 添加\n与表锁共享锁（read）及排他锁（write）都互斥\n\n\n意向锁之间不会互斥\n行级锁每次操作锁住对应的行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。应用在InnoDB存储引擎中。\nInnoDB的数据是基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的锁。对于行级锁，主要分为以下三类：\n\n行锁（Record Lock）：锁定单行记录的锁，防止其他事务对此进行update和delete。在RC、RR隔离级别下都支持\n间隙锁（Gap Lock）：锁定索引记录间隙（不含该记录），确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。在RR隔离级别下支持\n临建锁（Next-Key Lock）：行锁和间隙锁组合，同时锁住数据及数据前面的间隙。在RR隔离级别下支持\n\n行锁\n共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁\n排他锁（X）：允许获取排他锁的事务执行更新数据，阻止其他事务获取相同数据集的共享锁和排他锁\n\n\n\n\nSQL\n行锁类型\n说明\n\n\n\nINSERT\n排他锁\n自动加锁\n\n\nUPDATE\n排他锁\n自动加锁\n\n\nDELETE\n排他锁\n自动加锁\n\n\nSELECT\n不加任何锁\n\n\n\nSELECT … LOCK IN SHARE MODE\n共享锁\n需要手动在SELECT之后加LOCK IN SHARE MODE\n\n\nSELECT … FOR UPDATE\n排他锁\n需要手动在SELECT之后加FOR UPDATE\n\n\n\nInnoDB的行锁是针对于索引加的锁，不通过索引条件检索数据，那么InnoDB将对表中的所有记录加锁，此时就会升级为表锁。\n\n间隙锁&#x2F;临建锁默认情况下，InnoDB在RR隔离级别运行，使用临建锁进行搜索和索引扫描，以防止幻读。\n\n索引上的等值查询（唯一索引），给已存在的记录加锁时，优化为行锁。\n\n索引上的等值查询（唯一索引），给不存在的记录加锁时，优化为间隙锁。\n\n索引上的等值查询（普通索引），临建锁锁住自身和前面数据（到不满足查询需求的数据）的同时，会额外创建间隙锁，锁住后面的数据（到不满足查询需求的数据）。\n\n索引上的范围查询（唯一索引），会创建临建锁。\n\n\n注意：间隙锁唯一的目的是防止其他事务插入间隙，产生幻读。间隙锁可以共存，一个事务采用的间隙锁不会阻止另一个事务在同一间隙上采用间隙锁。\n事务日志\n事务的隔离性由锁机制实现\n而事务的原子性、一致性和持久性由事务的redo日志和undo日志保证\nREDO LOG被称为重做日志，提供再写入操作，恢复提交事务修改的页操作，用来保证事务的持久性\nUNDO LOG被称为回滚日志，回滚行记录到某个特定版本，用来保证事务的原子性、一致性\n\n\n\nRedo日志InnoDB存储引擎是以页为单位来管理存储空间的。在真正访问页面之前，需要把磁盘上的页缓存到内存中的Buffer Pool之后才可以访问。所有的变更都必须先更新缓冲池中的数据，然后缓冲池中的脏页会以一定频率被刷入磁盘（checkpoint机制），通过缓冲池来优化CPU和磁盘之间的鸿沟，这样就可以保证整体的性能不会下降太快\n为什么需要Redo日志checkpoint并不是每次更新的时候就触发，而是主线程隔一段时间去处理的。所以最坏的情况是事务提交后刚写入缓冲池，数据库宕机了，那么这段数据就是丢失的。这也导致事务失去了持久性特征。\nInnoDB采用了WAL技术（Write-Ahead Logging），这种技术的思想是先写日志，再写磁盘，只有日志写入成功，才算事务提交成功，这里的日志就是redo log\n优点\nredo日志降低了刷盘频率\n\nredo日志占用的空间非常小\n存储表空间ID、页号、偏移量以及需要更新的值，所需的磁盘空间是很小的，刷盘快\n\n\n特点\nredo日志是顺序写入磁盘的\n执行事务的过程中可能产生若干条redo日志，这些日志是按照产生的顺序写入磁盘的，也就是使用顺序IO，效率高于随机IO\n\n事务执行过程中，redo日志不断记录\nredo日志和bin日志的区别，redo日志是存储引擎层产生的，而bin日志是数据库层产生的。假设一个事务，对表不断的操作，这个过程中redo日志不断在记录，而bin日志只有在事务提交后一次性写入\n\n\nRedo日志组成\n重做日志的缓存（redo log buffer），保存在内存中\n在服务器启动时就向操作系统申请了一大片称为redo log buffer的连续内存空间（日志缓冲区）。这片内存空间被划分为若干个连续的redo log block，一个redo log block占用512字节大小\n\n重做日志文件（redo log file），保存在磁盘中\n\n\nRedo日志刷盘策略\nhttps://www.bilibili.com/video/BV1iq4y1u7vj?p=170\n\nUndo日志在事务中更新数据的前置操作其实是先写入一个undo log。\n出现意外情况时，我们需要把数据改回原先的样子，这个过程称之为回滚，这样就可以符合原子性要求。\nMySQL把这些为了回滚而记录的内容称为撤销日志或者回滚日志，即undo log。\n注意，由于查询操作并不会修改任何用户记录，所以在查询操作执行时，并不需要记录相应的undo日志。\n此外，Undo Log也需要进行持久化操作， 所以Undo Log也会产生Redo Log。由于Undo Log的完整性和可靠性需要Redo Log来保证，因此数据库崩溃时需要先做Redo Log数据恢复， 然后做Undo Log回滚。\nUndo日志作用\n回滚数据\n\nMVCC\n当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非阻塞读取\n\n\nUndo日志的类型在InnoDB存储引擎中，undo log分为：\n\ninsert undo log\n记录insert操作中产生的undo log。因为insert操作的记录，只对事务本身可见，对其他事务不可见，故该undo log可以在事务提交后直接删除。\n\nupdate undo log\n记录update和delete操作中产生的undo log。该undo log可能需要提供MVCC机制，因此不能在事务提交时就进行删除。提交时放入undo log链表，等待清除（purge）线程进行最后的删除\n\n\n\n清理线程两个主要作用：清理undo页和清除page里面带有Delete_Bit标识的数据行。\n在InnoDB中，事务中的Delete操作实际上并不是真正的删除掉行数据，而是一种Delete Mark操作，在记录上标识Delete_Bit，而不删除记录，真正的删除工作需要后台清理线程去完成。\n\n\nMVCC基本概念\n\n当前读\n读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。对于我们日常的操作，如：\nselect … lock in share mode（共享锁），select … for update、update、insert、delete（排他锁）都是一种当前读。\n\n快照读\n简单的select（不加锁）就是快照读，读取的是记录数据的可见版本，有可能是历史数据，不加锁，是非阻塞读。\n快照读的前提是隔离级别不是Serializable，Serializable级别下的快照读会退化成当前读。\n\nMVCC\n多版本并发控制。指维护一个数据的多个版本，使得读写操作没有冲突，快照读是MySQL实现MVCC提供了一个非阻塞读功能。MVCC的具体实现，还需要依赖数据库记录中的三个隐式字段、undo log日志、ReadView。\n\n\n实现原理隐藏字段\nDB_TRX_ID\n最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID\n\nDB_ROLL_PTR\n回滚指针，指向这条记录的上一个版本，用于配合undo log\n\nDB_ROW_ID\n隐藏主键， 如果表结构没有指定主键，将会生成该隐藏字段\n\n\nUNDO LOG版本链\n不同事务或相同事务对同一条记录进行修改，会导致该记录的undo log生成一条记录版本链表，链表的头部是最新的数据，链表尾部是最早的数据\nReadView读视图是快照读SQL执行时MVCC提供数据的依据，记录并维护系统当前活跃的事务（未提交的）id。\n\nReadView包含了四个核心字段：\n\n\n\n\n字段\n含义\n\n\n\nm_ids\n当前活跃的事务ID集合\n\n\nmin_trx_id\n最小活跃事务ID\n\n\nmax_trx_id\n预分配事务ID，当前最大事务ID+1（因为事务ID是自增的）\n\n\ncreator_trx_id\nReadView创建者的事务ID\n\n\n\n版本链数据访问规则\ndb_trx_id ：代表当前版本事务ID\n\ndb_trx_id == creator_trx_id\n可以访问该版本\n说明数据是当前这个事务更改的\n\ndb_trx_id &lt; min_trx_id\n可以访问该版本\n说明数据已经提交了\n\ndb_trx_id &gt; max_trx_id\n不可以访问该版本\n说明事务是在ReadView生成后才开启的\n\nmin_trx_id &lt;= db_trx_id &lt;= max_trx_id\n如果db_trx_id 不在m_ids中，可以访问该版本\n说明数据已经提交了\n\n\n\n不同隔离级别，生成ReadView的时机不同：\n\nREAD COMMITTED：在事务中每一次执行快照读时生成ReadView\nREPEATABLE READ：仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView\n\n\n\n\nhttps://www.bilibili.com/video/BV1Kr4y1i7ru?p=145\n\n","categories":["后端"],"tags":["MySQL"]},{"title":"Redis缓存过期、内存淘汰策略","url":"/2024/10/09/Redis%E7%BC%93%E5%AD%98%E8%BF%87%E6%9C%9F%E3%80%81%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/","content":"过期键的删除策略\n立刻删除\n立刻删除能保证内存中数据的最大新鲜度，因为它保证过期键会在过期后马上被删除，其所占用的内存也会随之释放。但是对CPU不友好，因为删除会占用CPU时间，这会产生大量的性能消耗，同时也会影响数据的读取操作。\n\n惰性删除\n数据达到过期时间，不立刻删除，等下次访问时判断是否过期，过期则删除。该方式的缺点是对内存不友好，如果这个过期键一直不被访问，其所占用的内存就不会释放。我们甚至可以将这种情况看作是一种内存泄漏，无用的数据占用了大量内存，而服务器却不会主动去释放。\n\n定期删除\n这种方式是上面两种策略的折中，每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行时长和频率来减少对CPU时间的影响。\n周期性轮询Redis库中的时效性数据，采用随机抽查的策略，利用过期数据占比的方式控制删除额度。\n\n该方式的难点在确定删除操作执行的时长和频率：\n如果删除操作太频繁或执行时间太长，定期删除策略就会退化为立刻删除策略，以至于将CPU时间过多消耗在删除过期键上；\n如果删除操作太少或执行时间太短，定期删除策略又会和惰性删除策略一样，出现浪费内存的情况。\n\n\n\n\n\nRedis内存设置如果不设置Redis的最大内存大小或者设置最大内存大小为0，在64位操作系统下不限制内存大小（默认）\n修改配置：\nmaxmemory &lt;bytes&gt;maxmemory 1048576 # 1MB\n\n一般推荐Redis设置内存为最大物理内存的四分之三\n如果Redis内存达到了使用上限，无法再设置新key，会抛出OOM异常\n\n\n内存淘汰策略如果我们希望Redis内存达到上限后，仍能正常提供服务，那么它就需要使用对应的一些淘汰策略。\nRedis支持的内存淘汰策略如下：\n\nnoeviction（默认）\n该策略对于写请求不再提供服务，会直接返回错误，当然排除del等特殊操作\n\nallkeys-random\n从Redis中随机选取key进行淘汰\n\nallkeys-lru\n使用LRU算法，从Redis中选取使用最少的key进行淘汰\n\nallkeys-lfu\n使用LFU，从Redis中选取某段时间之内使用频次最少的key进行淘汰\n\nvolatile-random\n从Redis中设置了过期时间的key，进行随机淘汰\n\nvolatile-ttl\n从Redis中选取即将过期的key，进行淘汰\n\nvolatile-lru\n使用LRU算法，从Redis设置了过期时间的key中，选取最少使用的key进行淘汰\n\nvolatile-lfu\n使用LFU算法，从Redis设置了过期时间的key中，选取某段时间之内使用频次最小的key进行淘汰\n\n\n\nLRU：Least Recently Used，最近最少使用\n淘汰最长时间未被使用的key，看key被使用到发生调度的时间长度\nLFU：Least Frequently Used，最不经常使用\n淘汰一定时期内被访问次数最少的key，看一段时间内key被使用的频率\n\n\n\n性能优化建议：\n\n避免存储bigkey\n\n开启惰性淘汰\nlazyfree-lazy-eviction yes\n\n","categories":["后端"],"tags":["Redis"]},{"title":"docker-compose","url":"/2024/01/02/docker-compose/","content":"nginxservices:  nginx:    image: nginx:1.24.0-alpine-slim    container_name: nginx    network_mode: bridge    environment:      - TZ=Asia/Shanghai    volumes:      - /data/container/nginx/config:/etc/nginx      - /data/container/nginx/data:/usr/share/nginx/html      - /data/container/nginx/logs:/var/log/nginx    ports:      - 80:80    restart: always\n\n\n\nmysqlversion: &#x27;3&#x27;services:  mysql:    image: mysql:8.0.20    container_name: mysql    volumes:      - /data/container/mysql/config:/etc/mysql      - /data/container/mysql/data:/var/lib/mysql      - /data/container/mysql/logs:/var/log/mysql    environment:      - &quot;MYSQL_ROOT_PASSWORD=xxxxxx&quot;      - &quot;TZ=Asia/Shanghai&quot;    ports:      - 3306:3306    restart: always\n\n\n\nredisservices:  redis:    image: redis:7.4.0    container_name: redis    environment:      - TZ=Asia/Shanghai    volumes:      - /data/container/redis/config:/etc/redis      - /data/container/redis/data:/data    ports:      - 6379:6379    restart: always    command: [&quot;redis-server&quot;,&quot;/etc/redis/redis.conf&quot;]\n\n\n需要提前创建配置文件，配置文件可从官网下载\nhttps://redis.io/docs/latest/operate/oss_and_stack/management/config/\n\n","categories":["其他"]},{"title":"ref和reactive","url":"/2024/10/18/ref%E5%92%8Creactive/","content":"区别\nref可以定义基本数据类型和对象数据类型；reactive可以定义对象数据类型\nref创建的对象必须使用.value\nreactive重新分配一个新对象，会失去响应式（可以使用Object.assign去整体替换）\n\n使用原则：\n\n若需要一个基本类型的响应式数据，必须使用ref\n若需要一个响应式对象，层级不深，ref和reactive都可以\n若需要一个响应式对象，层级较深，推荐使用reactive\n\n\n\n原理reactiveProxy对象，简单描述：\nfunction reactive(obj) &#123;    return new Proxy(obj, &#123;        get(target, key, receiver) &#123;            // 如果是普通对象，会对该对象再包装            if (typeof target[key] === &quot;object&quot;) &#123;                return reactive(target[key]);            &#125;;            // 如果是ref响应式对象，自动解包(.value)            return Reflect.get(target, key, receiver);        &#125;,        set(target, key, value, receiver) &#123;            return Reflect.set(target, key, value, receiver);        &#125;    &#125;);&#125;;\n\n解释问题：\n\n为什么对reactive响应式对象重新赋值会丢失响应式？\nlet test = reactive(&#123; a: 1, b: 2 &#125;)test = &#123; a:3, b:4 &#125; // 会丢失响应式\n\n这是因为test实际上是个Proxy对象，重新赋值变成了一个普通对象。\n那为什么重新赋值一个reactive对象也会丢失响应式呢？\nlet test = reactive(&#123; a: 1, b: 2 &#125;)test = reactive(&#123; a:3, b:4 &#125;) // 丢失响应\n\n这是因为上面的代码只是一个简单描述，实际上reactive函数中做的事情还有很多，重新赋值一个reactive对象，虽然实现了数据上的代理，但是丢失了与视图之间的依赖关系，所以视图无法更新，也就是所谓的失去了响应式。\n\n为什么reactive解构赋值会丢失响应式？\n准确来说，只有普通类型的属性会丢失响应，如果是对象类型的属性，响应式仍有效。\nlet test = reactive(&#123;  a: 1,  b: 2,  c: &#123;    x: 1,    y: 2,  &#125;,&#125;)const &#123; a, b, c &#125; = testconsole.log(a, b, c) // 1 2 Proxy(Object)\n\n这是因为解构赋值等价于：\nconst a = test.aconst b = test.bconst c = test.c\n\n由于c是对象类型，在get函数中被再次包装，所以不会丢失响应式。\n\n为什么reactive响应式对象中的属性赋予一个新对象，该新对象具有响应式？\nlet test = reactive(&#123;  a: 1,  b: 2&#125;)test.c = &#123; x: 1, y: 2 &#125;console.log(test.a, test.b, test.c) // 1 2 Proxy(Object)\n\n原因和上一个问题其实是一样的，因为触发了get方法，在get方法中进行了再次包装\n\nreactive响应式对象中的属性使用ref包裹，为什么不需要再使用.value？\nlet test = reactive(&#123;  a: 1,  b: ref(2),&#125;)console.log(test.a, test.b) // 1 2，b可以直接访问到，而不需要test.b.value\n\n原因是get方法里对ref对象自动解包\n\n\n\n\nref为什么会出现ref响应式对象？因为Proxy只能用来包装对象，无法包装基础类型数据，所以需要自己实现一个包装类：\nimport &#123; reactive &#125; from &quot;./reactive&quot;;import &#123; trackEffects, triggerEffects &#125; from &#x27;./effect&#x27;// 判断是否是对象export const isObject = (value) =&gt; &#123;    return typeof value === &#x27;object&#x27; &amp;&amp; value !== null&#125;// 将对象转为响应式function toReactive(value) &#123;    return isObject(value) ? reactive(value) : value&#125;class RefImpl &#123;    public _value;    public dep = new Set; // 依赖    public __v_isRef = true; // 是ref的标识    constructor(public rawValue, public _shallow) &#123;        // 判断是否是浅ref（shallowRef）：浅ref不需要再次代理        this._value = _shallow ? rawValue : toReactive(rawValue);    &#125;    get value() &#123;        // 收集依赖        trackEffects(this.dep)        return this._value;    &#125;    set value(newVal) &#123;        // set的值不等于初始值        if (newVal !== this.rawValue) &#123;            // 判断是否是浅ref（shallowRef）            this._value = this._shallow ? newVal : toReactive(newVal);            // 将初始值变为本次的值            this.rawValue = newVal            // 触发依赖更新            triggerEffects(this.dep)        &#125;    &#125;&#125;\n\n解释问题：\n\n为什么ref需要用.value访问其中值？\n因为ref是自己包装的一个类，为了使基础数据类型也具有响应式，所以需要.value访问其中值。\n\n为什么ref包裹对象，其value是个Proxy？\nref的底层实现中，如果是对象类型，实际上仍然依靠reactive方法。\n\n为什么对reactive响应式对象重新赋值会丢失响应式，而对ref响应式对象.value重新赋值不会？\nlet test = ref(&#123;  a: 1,  b: 2,&#125;)test.value = &#123; a: 4, b: 5 &#125;console.log(test) // RefImpl，其中的value仍然是Proxy\n\n对reactive响应式对象重新赋值会丢失响应式已经在上文中解释过了，\n而对ref响应式对象.value重新赋值，实际上触发了类中的set方法，如果是对象，再次经过reactive包装，所以依然是个响应式对象。\n\nref响应式对象中的属性使用ref包裹，为什么不需要再使用.value？\nlet test = ref(&#123;  a: 1,  b: ref(2),&#125;)console.log(test.value.a, test.value.b) // 1 2，b可以直接访问到，而不需要test.value.b.value\n\n原因其实和上文中说到的一样，由于ref包裹的是对象，所以test.value实际是靠reactive包装的。\nreactive中的get方法会对ref对象进行自动解包。\n\n\n","categories":["前端"],"tags":["Vue"]},{"title":"Redis","url":"/2024/10/06/Redis/","content":"数据类型字符串（String）set key value [NX|XX] [GET] [EX seconds|PX milliseconds|EXAT unix-time-seconds|PXAT unix-time-milliseconds|KEEPTTL]\n\n\nNX：键不存在的时候设置键值\nXX：键存在的时候设置键值\nGET：返回指定键原本的值，若键不存在时返回nil\nEX seconds：以秒为单位的过期时间\nPX milliseconds：以毫秒为单位的过期时间\nEXAT unix-time-seconds：设置以秒为单位的UNIX时间戳对应的时间为过期时间\nPXAT unix-time-milliseconds：设置以毫秒为单位的UNIX时间戳对应的时间为过期时间\nKEEPTTL：保留设置前指定键的生存时间\n\n\n\n同时设置&#x2F;获取多个键值：\nmset k1 v1 k2 v2 k3 v3mget k1 k2 k3msetnx k1 v1 k4 v4 # 如果其中一项失败，整体失败，k1已存在，所以都不会设置成功\n\n获取指定区间范围内的值：\nset k1 abcd1234getrange k1 0 3 # abcd，类似切片setrange k1 0 xxxx # xxxx1234，从第0位开始，使用后面的字符串覆盖\n\n数值增减（一定要是数字才能进行加减）：\nset k1 100INCR k1 # 递增INCRBY k1 2 # 增加指定整数DECR k1 # 递减DECRBY k1 2 # 减少指定整数\n\n获取字符串长度和内容追加：\nSTRLEN k1 # 获取字符串长度1APPEND k1 xxxx # 追加\n\n其他：\nsetnx k1 v1 # 只有key不存在时设置key的值setex k1 10 v1 # 设置key的同时设置过期时间getset k1 v1 # 先get再set\n\n\n\n列表（List）一个双端链表结构，主要功能有push、pop等，一般用在栈、队列、消息队列等场景\n\nleft、right都可插入添加\n如果键不存在，创建新的链表\n如果键已存在，新增内容\n若果值全移除，对应的键也就消失了\n\n由于底层是个双向链表，对两端的操作性能很高，通过索引下标操作中间节点的性能会较差。\nlpush/rpushlpop/rpoplrange k1 0 -1 # 遍历列表lindex # 按照索引获取元素llen # 获取列表中元素个数lrem key 数字N 给定值v1 # 删除N个值等于v1的元素ltrim key 开始index 结束index # 截取指定范围的值后再赋值给keyrpoplpush 源列表 目标列表lset key index valuelinsert key before/after 已有值 插入的新值\n\n\n\n哈希表（Hash）key-value键值对模式不变，但是value是一个键值对\nMap&lt;String,Map&lt;Object,Object&gt;&gt;\nhset/hget/hmset/hmget/hgetall/hdel# hset user id 11 age25# hset之前只能设置一个值，现在可以设置多个，代替了hmset的功能，hmset已被弃用hlen # 获取某个key内所有字段数量hexists key 具体字段hkeys/hvals key # 罗列key内所有字段/字段值hincrby/hincrbyfloathsetnx\n\n\n\n集合（Set）单值多value，且无重复\nsadd key member [member...] # 添加元素smembers key # 遍历所有元素sismember key member # 判断元素是否在集合中srem key member [member...] # 删除軅scard # 获取集合内元素个数srandmember key [数字N] # 从集合中随机展现N个元素，元素不删除spop key [数字N] # 从集合中随机弹出N个元素，元素删除smove key1 key2 key1中存在的值 # 将key1中某个值赋予key2# 集合运算A:&#123;a,b,c,1,2&#125; B:&#123;1,2,3,a,x&#125;sdiff A B # 差集sunion A B # 并集sinter A B # 交集sintercard numkeys key [key ...] [LIMIT limit] # redis7新命令sintercard 2 A B # 返回给定集合的交集产生的集合的基数\n\n\n\n有序集合（ZSet）在set的基础上，每个val值前加一个score分数值\nzadd key score member [score member...] # 添加元素zrange key start stop [WITHSCORES] # 按照分数从小到大的顺序返回索引从start到stop之间的所有元素zrevrange key start stop [WITHSCORES] # 按照分数从大到小的顺序返回索引从start到stop之间的所有元素zrangebyscore key min max [WITHSCORES] [LIMIT offset count] # 获取指定分数范围的元素，等价于 zrange key min max byscore# zrangebyscore key (min (max# 小括号表示不包含（开区间）zscore key member # 获取元素的分数zcard key # 获取集合中元素数量zrem key member # 删除元素zincrby key increment member # 增加某个元素的分数zcount key min max # 获取指定分数范围内的元素个数zmpop numkeys key [key ...] &lt;MIN | MAX&gt; [COUNT count] # redis7新命令，从键名列表中的第一个非空排序机制弹出一个或多个元素zrank key values # 获取下标值zrevrank key values # 逆序获取下标值\n\n\n\n\n以上为五种基本类型，以下为特殊类型\n\n\n\n地理空间（GEO）geoadd # 将指定的地理空间位置（纬度、经度、名称）添加到指定的key中geopos # 从key里返回所有给定位置元素的位置（经度和纬度）geodist # 返回两个给定位置之间的距离georadius # 以给定的经纬度为中心， 找出某一半径内的元素georadiusbymember # 找出位于指定范围内的元素，中心点是由给定的位置元素决定geohash # 返回一个或多个位置元素的 Geohash 表示\n\n\n\n基数统计（HyperLogLog）主要用来做基数统计的算法，其优点是在输入元素的数量或者体积非常大时，计算基数所需的空间总是固定的，并且是很小的。\n在Redis中，每个HyperLogLog键只需要花费12kb内存，就可以计算接近2^64个不同元素的基数。这和计算基数时，元素越多耗费内存越多的集合形成鲜明对比。\n但是，因为HyperLogLog只会根据输入元素来计算基数，不会存储输入元素本身，所以HyperLogLog不能像集合那样，返回输入的各个元素。\n基数统计：用于统计一个集合中不重复的元素个数，就是对集合去重复后剩余元素的计算\npfadd key element [element...] # 添加指定元素到HyperLogLog中pfcount key [key...] # 返回给定HyperLogLog的基数估算值pfmerge destkey sourcekey [sourcekey...] # 将多个HyperLogLog合并为一个HyperLogLog\n\n\n\n位图（bitmap）用String类型作为底层数据结构实现的一种统计二值状态（0和1）的数据类型，位图本质是数组，它是基于 String数据类型的按位的操作。该数据由多个二进制位组成，每个二进制位都对应一个偏移量（我们称之为一个索引）\nsetbit key offset val # 给指定key的第offset位赋值valgetbit key offset # 获取指定key的第offset位strlen key # 获取指定key占用的字节长度，不满8位按1字节补全bitcount key start end # 返回指定key中[start, end]中为1的数量bitop operation destkey key [key...] # 对不同的二进制存储数据进行位运算（AND、OR、NOT、XOR）\n\n\n\n位域（bitfield）Redis 位域允许您设置、递增和获取任意位长度的整数值。例如，您可以对从无符号 1 位整数到有符号 63 位整数的任何值进行操作。bitfield支持原子读取、写入和增量操作，使其成为管理计数器和类似数值的理想选择。\n总结：将一个Redis字符串看作是一个由二进制位组成的数组，并能对变长位宽和任意没有字节对齐的指定整型位进行寻址和修改\n\n\n流（Stream）Redis版的MQ消息中间件+阻塞队列\n\n\n持久化将内存中的数据写入磁盘\nRDB全称Redis Database，以指定的时间间隔执行数据集的时间点快照。\n把某一时刻的数据和状态以文件的形式写到磁盘上，也就是快照。这样依赖即使故障宕机，快照文件也不会丢失，数据的可靠性也就得到了保证。这个快照文件就称为RDB文件（dump.rdb）\n\n自动触发\n6.0.16以下版本配置：\n################## SNAPSHOTTING ################save 900 1 # 每隔15min，如果超过1个key发生变化，就写一份新的RDB文件save 300 10 # 每隔5min，如果超过10个key发生变化，就写一份新的RDB文件save 60 10000 # 每隔1min，如果超过10000个key发生变化，就写一份新的RDB文件\n\n公式save m n表示m秒内数据集存在n次修改时，自动触发保存\n7版本配置：\nsave 3600 1 300 100 60 10000\n\n手动触发\n可以使用SAVE或BGSAVE命令\nsave不会fork子进程，而是直接阻塞主线程来备份数据，直接持久化工作完成，执行期间Redis不能处理其他命令，线上禁止使用\nbgsave会fork一个子进程进行保存，这个操作是后台完成的，这就允许主进程还可以响应客户端请求\n\n\n\n\n优点：\n\nRDB适合大规模的数据恢复。\n可以按照业务定时备份。\nRDB文件在内存中的加载速度要比AOF快得多。\nRDB最大限度地提高了Redis性能，因为Redis父进程为了持久化而需要做的唯一工作就是派生一个将完成所有其余工作的子进程。父进程永远不会执行磁盘IO或类似操作。\n\n缺点：\n\n由于RDB保存有一定时间间隔，如果Redis由于任何原因在没有正确关闭的情况下停止工作，可能存在数据丢失。\n内存数据的全量同步，如果数据类太大会导致IO严重影响服务性能。\n\n\n\n触发RDBd的情况：\n\n配置中默认的快照配置（自动触发）\n手动save&#x2F;bgsave命令（手动触发）\n执行flushall&#x2F;flushdb命令（产生的是个空内容文件）\n执行shutdown且没有设置开启AOF持久化\n主从复制时，主节点自动触发\n\n\n\n检查RDB文件：\nredis-check-rdb xxx.rdb\n\n禁用快照：\nsava &quot;&quot; # 配置文件内填写空字符串\n\n配置文件中相关的配置信息：\nsave &lt;seconds&gt; &lt;changes&gt; # 自动触发配置dbfilename # RDB文件名dir # 存放路径stop-writes-on-bgsave-error yes # 默认yes，持久化保存出错时是否停止写请求rdbcompression yes # 默认yes，是否压缩存储。redis会采用LZF算法进行压缩，如果不想消耗CPU进行压缩的话，可以关闭此功能rdbchunsum yes # 默认yes，在存储快照后还可以让redis用CRC64算法来进行数据校验，但这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能rdb-del-syns-files no # 默认no，在没有持久化的情况下删除复制中使用的RDB文件\n\n\n\nAOF全称Append Only File，以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据。\n默认情况下Redis是没有开启AOF的，开启配置：\nappendonly yes\n\n\n写操作命令到达Redis Server后并不是直接写入AOF文件，会将这些命令先放入AOF缓存中进行保存。这里的AOF缓存区实际上是内存中的一片区域，存在的目的是当这些命令达到一定量以后再写入磁盘，避免频繁的磁盘IO操作\n\nAOF缓存会根据AOF缓存区同步文件的三种写回策略将命令写入磁盘的AOF文件\n写回策略：\n\nalways：每个写命令执行完立刻同步地将日志写回磁盘\neverysec（默认）：每秒写回，每个写命令执行完，把日志放入缓冲区，间隔1s写回磁盘\nno：操作系统控制的写回，每个写命令执行完，只是把日志放入缓冲区，由操作系统决定何时将缓冲区内容写回磁盘\n\n\n随着写入AOF内容的增加为避免文件膨胀，会根据规则进行命令的合并（又称AOF重写），从而起到AOF文件压缩的目的\n\n\n\n\n优点：\n\n更好保护数据不丢失、性能高、可做紧急恢复\n\n缺点：\n\nAOF文件通常比相同数据集的等效RDB文件大\nAOF运行效率要慢于RDB\n\n\n\nAOFRW\n\n自动触发\nauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb\n\n同时满足上面两个条件才会触发：\n\n根据上次重写后的AOF大小，判断当前AOF大小是否增长了1倍（百分百）\n重写时满足的文件大小（64MB）\n\n\n手动触发\nbgrewriteaof\n\n\nAOFRW流程以及MP-AOF的优化可参考：\nhttps://developer.aliyun.com/article/866957#\n\n\n\n相关配置：\nappendfsync everysec # 写回策略appenddirname &quot;appendonlydir&quot; # 日志存放路径appendfilename &quot;appendonly.aof&quot; # 日志文件名\n\nredis7.0后采取MP-AOF的方式存储文件，顾名思义，MP-AOF就是将原本的单个AOF文件拆分为多个AOF文件。在MP-AOF中，我们将AOF分为三类，分别是：\n\nBASE：表示基础AOF，一般由子进程通过重写产生，该文件最多只有一个\nINCR：表示增量AOF，一般会在AOFRW开始执行时被创建，该文件可能存在多个\nHISTORY：表示历史AOF，它是由BASE和INCR AOF变化而来，每次AOFRW成功完成时，本次AOFRW之前对应的BASE和INCR AOF都将变为HISTORY，HISTORY类型的AOF会被Redis自动删除\n\n为了管理这些文件，我们引入了一个manifest（清单）文件来跟踪、管理这些AOF。同时，为了便于AOF备份和拷贝，我们将所有的AOF文件和manifest文件放入一个单独的文件目录中，由appenddirname配置决定。\n\n\nRDB+AOF混合持久化\n默认情况下Redis仅开启了RDB，AOF未开启\n两者可以同时开启\n同时开启时，服务重启只会加载AOF，不会加载RDB文件\n\n这是一种推荐的持久化方式，因为：\n\n通常情况下AOF文件保存的数据集要比RDB文件保存的数据集完整（RDB间隔较长，服务宕机损失的数据较大）\nRDB适合用于备份数据库（AOF在不断变化不好备份）\n\n开启混合方式：\naof-use-rdb-preamble yes\n\nRDB镜像做全量持久化，AOF做增量持久化。\n先使用RDB进行快照存储，然后使用AOF持久化记录所有的写操作，当重写策略满足或手动触发重写的时候，将最新的数据存储为新的RDB记录。这样的话，重启服务会从RDB和AOF两部分恢复数据，既保证了数据完整性，又提高了恢复数据的性能。简单来说：混合持久化方式产生的文件一部分是RDB格式，一部分是AOF格式（AOF包括了RDB头部和AOF混写）\n\n\n事务可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序串行化执行而不会被其他命令插入。\n特点：\n\n单独的隔离操作\nRedis的事务仅仅保证事务里的操作会被连续独占的执行，Redis命令执行是单线程架构，在执行完事务内所有指令前是不可能再去同时执行其他客户端的请求的。\n\n没有隔离级别的概念\n因为事务提交前任何指令都不会被实际执行，也就不存在“事务内的查询要看事务内的更新，在事务外查询不能看到”这种问题了。\n\n不保证原子性\nRedis的事务不保证原子性，也就是不保证所有指令同时成功或同时失败，只有决定是否开始执行全部指令的能力，没有执行到一半回滚的能力。\n\n排他性\nRedis会保证一个事务内的命令依次执行，而不会被其他命令插入。\n\n\n\n\n使用方式# 开启事务MULTI...EXEC# 放弃事务MULTI...DISCARD\n\n两种错误情况：\n\n在EXEC之前，任何一个命令语法有错，Redis会直接返回错误，所有的命令都不会执行。\n在EXEC之后，当一个命令执行失败，不会影响到其他命令，其他正确的命令仍然会执行。\n\n\n\nwatch监控Redis使用Watch来提供乐观锁定\n\n悲观锁：每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁\n乐观锁：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据\n\n乐观锁策略：提交版本必须大于记录当前版本，才能执行更新\n客户端1：\nset balance 100set k1 v1WATCH balance # 1MULTIset balance 150 # 3set k1 xxxEXEC # nil\n\n客户端2：\nset balance 120 # 2\n\n客户端1被客户端2加塞，客户端1的整个事务都会中断\\\n可以使用unwatch取消监控\nWATCH balanceUNWATCH\n\n注意：\n\n一旦执行EXEC，之前加的监控锁都会被取消\n当客户端连接丢失的时候（断连），所有监控都会被取消\n\n\n\n管道问题由来：\n\n客户端向服务端发送命令（发送命令 -&gt; 命令排队 -&gt; 命令执行 -&gt; 命令返回），并监听Socket返回，通常以阻塞模式等待服务端响应\n服务端处理命令，并将结果返回客户端\n\n上述两步称为：Round Trip Time（简称RTT，数据包往返于两端的时间）\n\n如果同时执行大量的命令，那么就要等待上一条命令应答后再执行，这中间不仅多了RTT，而且还频繁调用系统IO，发送网络请求，同时需要Redis调用多次read()和write()系统方法，系统方法会将数据从用户态转移到内核态，这样就会对进程上下文有较大影响，性能不好。\n解决方案：\n管道可以一次性发送多条命令给服务端，服务端依次处理完毕后，通过一条响应一次性将结果返回，通过减少客户端与redis的通信次数来实现降低往返延时时间。pipeline实现的原理是队列，先进先出特性就保证数据的顺序性。\n\n\n\n管道和原生批量命令对比原生批量命令：mset等\n\n原生批量命令是原子性的，pipeline是非原子性的\n原生批量命令依次只能执行一种命令，pipeline支持批量执行不同命令\n原生批量命令是服务端实现，而pipeline需要服务端与客户端共同完成\n\n\n\n管道和事务对比\n事务具有原子性，管道不具有原子性\n\n执行事务时会阻塞其他命令的执行，而执行管道中的命令不会\n\n上面两点个人觉得表述有误，个人理解是事务保证了原子操作，不能加塞，而管道无法保证\n\n\n管道一次性将多条命令发送到服务器，事务是一条一条的发，事务只有在接收到EXEC命令后才会执行，管道不会\n\n\n\n\n注意事项\n管道缓冲的指令只是会依次执行，不保证原子性，如果执行中指令发生异常，将会继续执行后续的指令\n使用管道组装的命令不能太多，不然数据量过大客户端阻塞的时间可能过久，同时服务端此时也被迫回复一个队列答复，占用很多内存\n\n\n\n发布订阅\nhttps://blog.csdn.net/weixin_50012581/article/details/132348982\n\n\n\n主从复制\n读写分离\n容灾恢复\n数据备份\n水平扩容支撑高并发\n\n\n\n基本操作配从（库）不配主（库）\nreplicaof 主库IP 主库端口 # 配置文件中配置主数据库masterauth # 从机访问主机的通行密码，从机必须配置，主机不用\n\ninfo replication # 可以查看复制节点的主从关系和配置信息slaveof 主库IP 主库端口 # 命令配置主数据库。如果该数据库已经是某个主数据库的从数据库，那么会停止和原主数据库的同步关系，转而和新的主数据库同步slaveof no one # 使当前数据库停止与其他数据库的同步，转为主数据库\n\n\n\n注意事项\n从机不可以执行写命令\n\n从机意外宕机后，重启后仍有最新数据\n\n主机意外宕机后，从机不动，原地待命，等待主机重启。期间从机数据可以正常使用\n\n主机恢复后，主从关系不变，从机仍能正常复制\n\n从机变更主机，会清除之前数据，重新拷贝最新的主机数据\n\n从机变为主机，数据依旧存在，但不再同步\n\n上一个slave可以是下一个slave的master，slave同样可以接收其他slaves的连接和同步请求，那么该slave作为了链条中下一个的master，可以有效的分载master的同步压力。\n但是，中间环节的slave仍然不支持写操作。\n\n\n\n\n复制原理和工作流程\nslave启动，同步初请\nslave启动成功连接到master后会发送一个sync命令。\nslave首次全新连接master，一次完成同步（全量同步）将被自动执行，slave自身原有数据会被master数据清除覆盖。\n\n首次连接，全量复制\nmaster节点收到sync命令后开始在后台保存快照（即RDB持久化，主从复制会触发RDB），同时收集所有接收到的用于修改数据集命令缓存起来，master节点执行RDB持久化后，将RDB快照文件和所有缓存的命令发送到所有slave，以完成一次完全同步。\n而slave在接收到数据库文件数据后，将其存盘并加载到内存中，从而完成复制初始化。\n\n心跳持续，保持通信\nmaster会持续发送ping包，保持通信。\nrepl-ping-replica-period 10\n\n默认是10s\n\n进入平稳，增量复制\nmaster继续将新的所有收集到的修改命令自动依次传给slave，完成同步。\n\n从机下线，重连续传\nmaster会检查backlog里面的offset（master和slave都会保存一个复制的offset还有一个masterId，offset是保存在backlog中的），master只会把已经复制的offset后面的数据复制给slave，类似断点续传。\n\n\n\n\n缺点\n由于所有的写操作都是在master上操作，然后同步更新到slave上，所以从master同步到slave有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，slave机器数量的增加也会使这个问题更加严重。\n由于写操作只有在master机器上执行，如果master机器宕机，默认情况下，不会在slave节点中自动重选一个master，所有的写操作都没法完成。\n\n\n\n哨兵监控哨兵巡查监控后台master主机是否故障，如果故障了，根据投票数自动将某一个从库转换为新主库，继续对外服务。\n哨兵的作用：\n\n主从监控\n监控主从redis库运行是否正常\n\n消息通知\n哨兵可以将故障转移的结果发送给客户端\n\n故障转移\n如果master异常，则会进行主从切换，将其中一个slave作为新master\n\n配置中心\n客户端通过连接哨兵来获得当前redis服务的主节点地址\n\n\n\n\nsentinel.conf设置监控的master服务器\nsentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;sentinel auth-pass &lt;master-name&gt; &lt;password&gt;\n\n\nquorum表示最少有多少个哨兵认可客观下线，同意故障迁移的法定票数（确认客观下线的最少的哨兵数量）\n\n我们知道网络是不可靠的，有时候一个sentinel会因为网络堵塞而误以为一个master redis已经宕机了，在sentinel集群环境下需要多个sentinel互相沟通来确认某个master是否真的死了，quorum这个参数是进行客观下线的一个依据，意思是至少quorum个sentinel认为这个master有故障，才会对这个master进行下线以及故障转移。这就保证了公平性和高可用。\n\n\n\n其他配置\n# 指定多少毫秒后，主节点没有应答哨兵，此时哨兵主观认为主节点下线sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;# 表示允许并行同步的slave个数，当master挂了后，哨兵会选出新的master，此时剩余的slave会向新的master发起同步数据sentinel parallel-syncs &lt;master-name&gt; &lt;nums&gt;# 故障转移的超时时间，如果故障转移超过设置的毫秒，表示故障转移失败sentinel fallover-timeout &lt;master-name&gt; &lt;milliseconds&gt;# 配置当某一事件发生时所需要执行的脚本sentinel notification-script &lt;master-name&gt; &lt;script-path&gt;# 客户端重新配置主节点参数脚本sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;\n\n\nhttps://blog.csdn.net/m0_63947499/article/details/142059274\n\n\n\n注意事项\n主从关系发生变化后（主机宕机，从机上位），宕机的主机重连后不会变回主机，而是保持从机身份。\n主从关系发生变化后，sentinel.conf、redis.conf配置文件都会重写。\n\n\n\n运行流程和选举流程\n主观下线：SDOWN（主观不可用）是单个sentinel自己主观上检测到的关于master的状态，从sentinel的角度来看，如果发送了PING心跳后，在一定时间内没有收到合法回复，就打到了SDOWN的条件。\ndown-after-milliseconds配置可以设置主观下线的时间长度。\n\n客观下线：ODOWN（客观不可用）需要一定数量的sentinel，多个哨兵达成一致意见才能认为一个master客观上不可用。\n\n哨兵领导者选举：为了避免多个哨兵节点同时执行故障转移，造成混乱，哨兵集群需要从自己中选举一个哨兵领导者（leader），由它来负责故障转移（failover）的流程。哨兵领导者的选举是基于Raft算法或Paxos算法的。\n\n新主节点选举：当哨兵领导者选举出来后，它会从所有的从节点中选择一个最合适的从节点，作为新的主节点。新主节点的选举标准是：优先级最高，复制偏移量最大，运行ID最小。\n\n优先级是通过配置文件指定的，越小表示优先级越高；\n\n复制偏移量表示从节点复制主节点数据的字节数，越大表示数据越完整；\n\n运行ID是Redis每次启动时生成的随机字符串，用于标识不同的Redis实例，按字典序比较大小。\n\n\n\n重新配置从节点：当新主节点选举出来后，哨兵领导者会向所有的从节点发送命令，让它们与新主节点建立复制关系，更新自己的主节点信息。同时，哨兵领导者也会向所有的哨兵节点发送命令，让它们更新自己的主节点信息，并通知客户端使用新的主节点地址。\n\n\n\nhttps://blog.csdn.net/TaloyerG/article/details/134958242\n\n\n\n集群分片Redis 集群是一个可以在多个 Redis 节点之间进行数据共享的程序集。\n\nRedis集群支持多个Master，每个Master又可以挂载多个Slave\n读写分离\n数据高可用\n海量数据的读写存储操作\n\n\n由于Cluster自带Sentinel的故障转移机制，内置了高可用的支持，无需再去使用哨兵功能\n客户端与Redis的节点连接，不再需要连接集群中的所有节点，只需要任意连接集群中的一个可用节点即可\n槽位slot负责分配到各个物理服务节点，由对应的集群来负责维护节点、插槽和数据之间的关系\n\n\n\n概念\n槽位\nRedis 集群没有使用一致性hash，而是引入了哈希槽的概念。\nRedis 集群由16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽。集群的每个节点负责一部分哈希槽。\n\n分片\n使用Redis集群时我们会将 存储的数据分散到多台Redis机器上，这称为分片。简言之，集群中的每个Redis实例都被认为是整个数据的一个分片。\n\n\n优势：方便扩容&#x2F;缩容和数据分片查找\n\n\n映射算法\n哈希取余算法\n一致性哈希算法\n哈希槽分区算法\n\n\nhttps://www.bilibili.com/video/BV13R4y1v7sP?p=79\n\n\n\n为什么最大槽数是16384个？\nhttps://www.cnblogs.com/rjzheng/p/11430592.html\n\n\n","categories":["后端"],"tags":["Redis"]},{"title":"new","url":"/2022/03/09/new/","content":"以下方代码为例\nfunction Person(name)&#123;    this.name = name;&#125;let xiaoming = new Person(&#x27;xiaoming&#x27;);\n\n我们知道创建一个对象是通过new操作符，那么new操作符到底做了哪些事情呢？\n实际上它帮我们做了四件事情：\n\n创建一个空的对象\n\n将空对象原型__proto__指向函数的原型对象prototype\n\n函数的this指向这个空对象，并执行代码\n\n将这个对象返回\n构造函数返回值取决于函数的return：\n\n不写return -&gt; 返回默认创建的对象\nreturn this -&gt; 返回默认创建的对象\nreturn 基本数据类型 -&gt; 返回默认创建的对象\nreturn 对象 -&gt; 返回该对象而非创建的对象\n\n\n\n那么上面的代码，我们可以这样理解：\nlet xiaoming = new Person(&#x27;xiaoming&#x27;);// 上面这句代码可以看成这样let temp = &#123;&#125;;temp.__proto__ = Person.prototype;let res = Person.apply(temp, [&quot;xiaoming&quot;]);let xiaoming = typeof res === &#x27;object&#x27; ? res:temp;\n\n再扩展一下，我们可以自己封装一个new函数：\nfunction _new(context) &#123;    let temp = &#123;&#125;;    temp.__proto__ = context.prototype;    let res = context.apply(temp, [...arguments].slice(1));    return typeof res === &quot;object&quot; ? res : temp;&#125;function Person(name) &#123;    this.name = name;&#125;let xiaoming = _new(Person, &quot;xiaoming&quot;);    // 效果和 new Person(&quot;xiaoming&quot;) 一样\n\n\n在讲原型和原型链的时候我们说__proto__属性不能直接使用，这是由于在ES6之前没有标准的方法能够直接操作隐式原型，所以才有了__proto__属性，通过它我们可以访问到对象的原型，所以__proto__属性其实是可以使用的，但是并不建议，因为不是所有的浏览器都支持通过__proto__来访问。我们这里只是用来模拟new操作符的实现，必须要用到__proto__而已。\n\n","categories":["前端"],"tags":["JavaScript"]},{"title":"this","url":"/2022/03/11/this/","content":"1.this指向\n全局环境中的this -&gt; 指向window对象\n普通函数中的this -&gt; 严格模式下指向undefined，非严格模式下指向window对象\n构造函数中的this -&gt; 指向new出来的对象\ncall、apply、bind调用 -&gt; 指向这三个方法的第一个参数，如果参数为null或者undefined，在非严格模式下指向window对象\n箭头函数中的this -&gt; 取决于箭头函数外的this指向\n\n\n在非严格模式下，this指向不能是undefined或null，如果得出this将指向undefined或者null，那么this会指向window对象。\n在浏览器环境下是window对象，在Node环境下是global。\n\n简单一句话概括就是：谁调用，this就指向谁。\n\n\n2.优先级当有多种情况决定this指向时，优先级依次为：\n\n箭头函数\nnew\nbind\napply和call\n对象调用方法\n直接调用函数\n全局环境\n\n例如：\nlet func = () =&gt; &#123;  console.log(this);&#125;func.bind(&#123;&#125;)(); // 输出window，而不是空对象\n\n\n\n3.apply、call和bind这三个方法都会改变函数中的this指向，那他们有什么区别呢？以下方代码为例：\nfunction test(x, y)&#123;    console.log(this, x, y);&#125;test();    // window undefined undefined\n\n\n\n(1) callcall方法接收多个参数，第一个参数为要改变的this指向，后边参数为函数自身的参数。\nlet temp = &#123; name: &quot;小明&quot; &#125;;function test(x, y)&#123;    console.log(this, x, y);&#125;test.call(temp,1,2);    // temp对象 1 2\n\n接下来我们尝试自己去实现一下call方法。\n我们思考一下，怎么做才能让函数中的this指向一个对象？如果这个函数是对象体内的方法，那通过对象调用这个方法，函数中的this是不是就指向调用的对象。然后在调用完函数后，将这个方法删除掉，对象内容不变：\nlet temp = &#123; name: &quot;小明&quot; &#125;;function test(x, y)&#123;    console.log(this, x, y);&#125;temp.fn = test;temp.fn(1, 2);    // temp对象 1 2delete temp.fn;\n\n按照这个思路，我们试着自己去写一个call方法：\nFunction.prototype._call = function (context) &#123;    // 如果没有传入指定对象，默认为window    context = context || window;    // 将函数作为对象的方法，为了保证方法名唯一，使用Symbol    // this指向函数    const fn = Symbol();    context[fn] = this;    // 执行方法    const res = context[fn](...[...arguments].slice(1));    // 删除方法    delete context[fn];    // 返回结果    return res;&#125;;let temp = &#123; name: &quot;小明&quot; &#125;;function test(x, y)&#123;    console.log(this, x, y);&#125;test._call(temp, 1, 2);    // temp对象 1 2\n\n\n\n(2) applyapply方法接收两个参数，第一个参数为要改变的this指向，第二个参数为函数自身的参数，以数组的形式传入。apply与call方法不同的地方就是传参的形式。\nlet temp = &#123; name: &quot;小明&quot; &#125;;function test(x, y)&#123;    console.log(this, x, y);&#125;test.apply(temp,[1,2]);    // temp对象 1 2\n\n接下来我们尝试自己去实现一下apply方法。\napply方法和call方法一样，只不过是传入参数的方式不同而已：\nFunction.prototype._apply = function (context) &#123;    context = context || window;    const fn = Symbol();    context[fn] = this;    let res = null;    // 如果存在第二个参数    if (arguments[1]) &#123;        res = context[fn](...arguments[1]);    &#125; else &#123;        res = context[fn]();    &#125;    delete context[fn];    return res;&#125;;let temp = &#123; name: &quot;小明&quot; &#125;;function test(x, y)&#123;    console.log(this, x, y);&#125;test._apply(temp, [1, 2]);    // temp对象 1 2\n\n\n\n(3) bindbind方法接收多个参数，第一个参数是要改变的this指向，后边参数为函数自身的参数。它与上边两个方法不同的是，它不会立刻执行函数，而是返回一个新函数。\nlet temp = &#123; name: &quot;小明&quot; &#125;;function test(x, y)&#123;    console.log(this, x, y);&#125;// 下面这样是不会执行的// test.bind(temp, 1, 2);let fn = test.bind(temp, 1, 2);fn();  // temp对象 1 2// 或者test.bind(temp, 1, 2)();    // temp对象 1 2// 另外可以将函数的参数进行拆分test.bind(temp)(1, 2);    // temp对象 1 2test.bind(temp, 1)(2);    // temp对象 1 2\n\n接下来我们尝试自己去实现一下bind方法。\nbind返回的是一个新函数，所以实现起来和上面两个有所不同：\nFunction.prototype._bind = function (context) &#123;    const args = [...arguments].slice(1);    const fn = this;    return function() &#123;        return fn.apply(            context,            // 这个arguments是指返回的函数的参数            // 这部分涉及函数柯里化            args.concat(...arguments)        );    &#125;;&#125;;let temp = &#123; name: &quot;小明&quot; &#125;;function test(x, y) &#123;    console.log(this, x, y);&#125;test._bind(temp, 1, 2)(); // temp对象 1 2test._bind(temp, 1)(2); // temp对象 1 2\n\n但是这样还有个瑕疵，在MDN中有这么一句话：\n\nbind()中的第一个参数：调用绑定函数时作为this参数传递给目标函数的值。 如果使用new运算符构造绑定函数，则忽略该值。\n\n这句话中的绑定函数指bind返回的函数，那这句话是什么意思呢？由于bind方法返回的是一个函数，那么这个函数可以作为构造函数使用，当这个函数作为构造函数使用时，原来函数中的this指向的应该是这个构造函数创建的实例对象，而不是bind绑定的对象。\n我们还是看回这个例子：\nlet temp = &#123; name: &quot;小明&quot; &#125;;function test(x, y) &#123;    console.log(this, x, y);&#125;// 这里输出的不再是temp对象，而是新创建的obj对象let obj = new (test.bind(temp, 1, 2))();\n\n如果用我们上面自己的写的bind方法，当返回函数作为构造函数时，this指向还是temp对象，所以要进一步修改：\nFunction.prototype._bind = function (context) &#123;    const args = [...arguments].slice(1);    const fn = this;    return function Fn() &#123;        return fn.apply(            this instanceof Fn ? this : context,            args.concat(...arguments)        );    &#125;;&#125;;\n\n\n\n\n\n参考：\nhttps://juejin.cn/post/6844903746984476686\nhttps://juejin.cn/post/6946021671656488991\n\n","categories":["前端"],"tags":["JavaScript"]},{"title":"TypeScript","url":"/2024/10/16/TypeScript/","content":"快速入门\n手动编译\nnpm i typescript -g # 全局安装tstsc index.ts # 编译ts文件\n\n自动化编译\ntsc --init # 初始化配置tsc --watch # 监控目录下ts文件变更\n\n\n\n变量声明&#x2F;推断let a: string = &#x27;123&#x27;let b: number = 9let c: boolean = truefunction count(x:number, y:number):number&#123;    return x + y;&#125;// 字面量类型let d: &#x27;hello&#x27;d = &#x27;hello&#x27; // d只能赋值hello// TS会根据我们的代码，进行类型推断（但类型推断不是万能的，尽量还是写明类型）let e = -99 // TS会推断类型为数字\n\n\n\n类型总览js中的数据类型简单数据类型\n\nnumber\nstring\nboolean\nnull\nundefined\n\n复杂数据类型\n\nObject（包括Array、Function、Date等）\n\n\n\nts中的数据类型ts的数据类型包括上面js的类型，同时新增了几个类型：\n\nany\nunknown\nnever\nvoid\ntuple\nenum\n\n另外还有两个用于自定义类型的方式：\n\ntype\ninterface\n\n\n\n类型声明中的大小写问题let str1: string // Ts官方推荐的写法str1 = &#x27;hello&#x27;str1 = new String(&#x27;hello&#x27;) // 会报错，不能将String分配给string// string是基元，String是包装器对象，声明string类型的变量不能赋值一个包装器对象，推荐使用stringlet str2: String // 这种写法表示这个变量既支持基本类型，也支持包装器对象str2 = &#x27;hello&#x27;str2 = new String(&#x27;hello&#x27;)\n\n\n在JS中的这些内置构造函数：Number、String、Boolean，它们用于创建对应的包装对象，在日常开发时很少使用，在TS中也是同理，所以在TS中进行类型声明时，通常都是用小写的number、string、boolean\n\n\n额外补充：包装对象、自动装箱\n\n\n\n常用类型与语法anyany表任意类型，一旦将变量类型设置为any，那就意味着放弃了对该变量的类型检查。\nlet a: anya = 100a = &#x27;你好&#x27;a = false\n\n注意：any类型的变量，可以赋值给任意类型的变量\nlet c: anyc = 9let x: stringx = c // 无警告\n\n\n\nunknownunknown的含义是个未知类型\n\n它可以理解为一个类型安全的any，适用于：不确定数据的具体类型。\nlet a: unknown// 以下均正常a = 100a = falsea = &#x27;你好&#x27;let x: stringx = a // 警告：不能将类型“unknown”分配给类型“string”\n\n它会强制开发者在使用之前进行类型检查，从而提供更强的类型安全性。\n// 方式一if(typeof a === &#x27;string&#x27;)&#123;    x = a&#125;// 方式二（断言）x = a as stringx = &lt;string&gt;a\n\n读取any类型数据的任何属性都不会报错，而unknown正好与之相反。\nlet str1: stringstr1 = &#x27;hello&#x27;str1.toUpperCase() // 无警告let str2: anystr2 = &#x27;hello&#x27;str2.toUpperCase() // 无警告let str3: unknownstr3 = &#x27;hello&#x27;str3.toUpperCase() // 警告：”str3“类型为”unknown“\n\n\n\nnevernever的含义是任何值都不是，简言之就是不能有值，undefined、null、&#39;&#39;、0都不行。\n\n几乎不用never去直接限制变量，因为没有意义\nlet a: never// 下方都会有警告a = 1a = truea = undefineda = null\n\nnever一般是TS主动推断出来的\nlet a: stringa = &#x27;hello&#x27;if(typeof a === &#x27;string&#x27;)&#123;    console.log(a.toUpperCase())&#125;else&#123;    console.log(a) // TS会推断此处的a是never，因为没有任何一个值符合此处的逻辑&#125;\n\nnever也可用于限制函数的返回值\n// 限制throwError函数不需要有任何返回值，任何值都不行，包括undefined、nullfunction throwError(str: string): never &#123;    throw new Error(&#x27;异常退出：&#x27; + str)&#125;\n\n\n\nvoid\nvoid通常用于函数返回值声明，含义：函数不返回任何值，或者说函数返回空，调用者也不应该依赖其返回值进行任何操作。\nfunction logMessage(msg: string):void&#123;    console.log(msg)&#125;logMessage(&quot;你好&quot;)\n\n\n注意：虽然没有return显示指定返回值，但会有一个隐式返回值，就是undefined。所以，虽然函数返回类型为void，但也是可以接受undefined的。\n总结：undefined是void可以接受的一种“空”。\n\n\n以下写法均符合规范\nfunction logMessage(msg:string):void&#123;    console.log(msg)&#125;function logMessage(msg:string):void&#123;    console.log(msg)    return;&#125;function logMessage(msg:string):void&#123;    console.log(msg)    return undefined;&#125;\n\n理解void和undefined\nfunction logMessage(msg:string):void&#123;    console.log(msg)&#125;let result = logMessage(&quot;你好&quot;)if(result)&#123;&#125; // 警告function logMessage(msg:string):undefined&#123;    console.log(msg)&#125;let result = logMessage(&quot;你好&quot;)if(result)&#123;&#125; // 无警告\n\n\nvoid是一个广泛的概念，用来表示“空”，而undefined是这种“空”的具体实现之一\n因此可以说undefined是void可以接受“空”状态的一种具体形式。\n话句话说：void包含undefined，但void表达的语义超越了单纯的undefined，它是一种意图上的约定，而不仅仅是特定值的限制。\n\n总结：若函数返回类型为void，那么：\n\n从语法上讲，函数是可以返回undefined的，无论是显示返回还是隐式返回。\n从语义上讲，函数调用者不应该关心函数返回的值，也不应依赖返回值进行任何操作，即使返回了undefined值。\n\n\n\n\n\nobject\n关于object和Object，实际开发中用的相对较少，因为范围太大了。\n\n\nobject的含义是：所有非原始对象，可存储：对象、函数、数组等，由于限制的范围比较宽泛，在实际开发中使用的相对较少。\nlet a:object// 以下无警告a=&#123;&#125;a=&#123;name:&quot;张三&quot;&#125;a=[1,3,5,7,9]a=function()&#123;&#125;a=new String(&quot;123&quot;)class Person &#123;&#125;a = new Person()// 以下有警告a = 1a = truea = &#x27;你好&#x27;a = nulla = undefined\n\nObject的含义是：所有可以调用Object方法的类型。\n简单记忆：除了undefined和null的任何值。\n由于限制范围太大，所以实际开发中使用频率极低。\nlet a:Object// 以下无警告a=&#123;&#125;a=&#123;name:&quot;张三&quot;&#125;a=[1,3,5,7,9]a=function()&#123;&#125;a=new String(&quot;123&quot;)class Person &#123;&#125;a = new Person()a = 1a = truea = &#x27;你好&#x27;// 以下有警告a = nulla = undefined\n\n既然object和Object限制都太宽泛，那么该如何声明一个对象呢？\n声明对象类型\n实际开发中，限制一般对象，通常使用以下形式\n// 限制person对象必须有name属性，age为可选属性let person1: &#123;name: string, age?: number&#125;// 含义同上，也能用分号做分隔let person2: &#123;name: string; age?: number&#125;// 含义同上，也能用换行做分隔let person3: &#123;    name: string    age?: number&#125;person1 = &#123;name:&#x27;Tom&#x27;,age:18&#125;person2 = &#123;name:&#x27;Tom&#x27;&#125;\n\n索引签名\n允许定义对象可以具有任意数量的属性，这些属性的键和类型是可变的，常用于：描述类型不确定的属性（具有动态属性的对象）\nlet person: &#123;    name: string    age?: number    [key:string]:any // 索引签名，完全可以不用key这个单词，换成其他的也可以&#125;person = &#123;    name:&#x27;张三&#x27;,    age:18,    gender:&quot;男&quot;&#125;\n\n声明函数类型let count: (a: number, b: number) =&gt; numbercount = function (x, y) &#123; return x + y &#125;\n\n\nTypeScript 中的 =&gt; 在函数类型声明时表示函数类型，描述其参数类型和返回类型。\nJavaScript 中的 =&gt; 是⼀种定义函数的语法，是具体的函数实现。\n函数类型声明还可以使⽤：接⼝、⾃定义类型等⽅式，下⽂中会详细讲解。\n\n声明数组类型let arr1: string[] let arr2: Array&lt;string&gt;arr1 = [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;]arr2 = [&#x27;hello&#x27;,&#x27;world&#x27;]\n\n上述代码中的 Array 属于泛型，下⽂会详细讲解。\n\n\ntuple元组 (Tuple) 是⼀种特殊的数组类型，可以存储固定数量的元素，并且每个元素的类型是已知的且可以不同。元组⽤于精确描述⼀组值的类型， ?表示可选元素。\n// 第⼀个元素必须是 string 类型，第⼆个元素必须是 number 类型。let arr1: [string,number]// 第⼀个元素必须是 number 类型，第⼆个元素是可选的，如果存在，必须是 boolean 类型。let arr2: [number,boolean?]// 第⼀个元素必须是 number 类型，后⾯的元素可以是任意数量的 string 类型let arr3: [number,...string[]]// 可以赋值arr1 = [&#x27;hello&#x27;,123]arr2 = [100,false]arr2 = [200]arr3 = [100,&#x27;hello&#x27;,&#x27;world&#x27;]arr3 = [100]// 不可以赋值，arr1声明时是两个元素，赋值的是三个arr1 = [&#x27;hello&#x27;,123,false]\n\n\n\nenum枚举（enum）可以定义⼀组命名常量，它能增强代码的可读性，也让代码更好维护。\n如下代码的功能是：根据调⽤ walk 时传⼊的不同参数，执⾏不同的逻辑，存在的问题是调⽤ walk 时传参时没有任何提示，编码者很容易写错字符串内容；并且⽤于判断逻辑的up、down、left、right是连续且相关的⼀组值，那此时就特别适合使⽤ 枚举（enum）。\nfunction walk(str:string) &#123; if (str === &#x27;up&#x27;) &#123; console.log(&quot;向【上】⾛&quot;); &#125; else if (str === &#x27;down&#x27;) &#123; console.log(&quot;向【下】⾛&quot;); &#125; else if (str === &#x27;left&#x27;) &#123; console.log(&quot;向【左】⾛&quot;); &#125; else if (str === &#x27;right&#x27;) &#123; console.log(&quot;向【右】⾛&quot;); &#125; else &#123; console.log(&quot;未知⽅向&quot;); &#125;&#125;walk(&#x27;up&#x27;)walk(&#x27;down&#x27;)walk(&#x27;left&#x27;)walk(&#x27;right&#x27;)\n\n\n数组枚举\n数字枚举⼀种最常⻅的枚举类型，其成员的值会⾃动递增，且数字枚举还具备反向映射的特点，在下⾯代码的打印中，不难发现：可以通过值来获取对应的枚举成员名称 。\n// 定义⼀个描述【上下左右】⽅向的枚举Directionenum Direction &#123;    Up,    Down,    Left,    Right&#125;console.log(Direction) // 打印Direction会看到如下内容/*     &#123;        0:&#x27;Up&#x27;,         1:&#x27;Down&#x27;,         2:&#x27;Left&#x27;,         3:&#x27;Right&#x27;,         Up:0,         Down:1,         Left:2,        Right:3    &#125; */// 反向映射console.log(Direction.Up)console.log(Direction[0])// 此⾏代码报错，枚举中的属性是只读的Direction.Up = &#x27;shang&#x27;\n\n也可以指定枚举成员的初始值，其后的成员值会⾃动递增。\nenum Direction &#123;    Up = 6,    Down,    Left,    Right&#125;console.log(Direction.Up); // 输出: 6console.log(Direction.Down); // 输出: 7\n\n使⽤数字枚举完成刚才 walk 函数中的逻辑，此时我们发现： 代码更加直观易读，⽽且类 型安全，同时也更易于维护。\nenum Direction &#123;    Up,    Down,    Left,    Right,&#125;function walk(n: Direction) &#123;    if (n === Direction.Up) &#123;        console.log(&quot;向【上】⾛&quot;);    &#125; else if (n === Direction.Down) &#123;        console.log(&quot;向【下】⾛&quot;);    &#125; else if (n === Direction.Left) &#123;        console.log(&quot;向【左】⾛&quot;);    &#125; else if (n === Direction.Right) &#123;        console.log(&quot;向【右】⾛&quot;);    &#125; else &#123;        console.log(&quot;未知⽅向&quot;);    &#125;&#125;walk(Direction.Up)walk(Direction.Down)\n\n字符串枚举\n枚举成员的值是字符串\nenum Direction &#123;    Up = &quot;up&quot;,    Down = &quot;down&quot;,    Left = &quot;left&quot;,    Right = &quot;right&quot;&#125;let dir: Direction = Direction.Up;console.log(dir); // 输出: &quot;up&quot;\n\n注意：字符串枚举会丢失反向映射\n\n常量枚举\n\n官⽅描述：常量枚举是⼀种特殊枚举类型，它使⽤ const 关键字定义，在编译时会被内联，避免⽣成⼀些额外的代码。\n何为编译时内联？\n所谓“内联”其实就是 TypeScript 在编译时，会将枚举成员引⽤替换为它们的实际值，⽽不是⽣成额外的枚举对象。这可以减少⽣成的 JavaScript 代码量，并提⾼运⾏时性能。 \n\n使⽤普通枚举的 TypeScript 代码如下：\nenum Directions &#123; Up, Down, Left, Right&#125;let x = Directions.Up;\n\n编译后⽣成的 JavaScript 代码量较⼤ ：\n&quot;use strict&quot;;var Directions;(function (Directions) &#123; Directions[Directions[&quot;Up&quot;] = 0] = &quot;Up&quot;; Directions[Directions[&quot;Down&quot;] = 1] = &quot;Down&quot;; Directions[Directions[&quot;Left&quot;] = 2] = &quot;Left&quot;; Directions[Directions[&quot;Right&quot;] = 3] = &quot;Right&quot;;&#125;)(Directions || (Directions = &#123;&#125;));let x = Directions.Up;\n\n使⽤常量枚举的 TypeScript 代码如下：\nconst enum Directions &#123; Up, Down, Left, Right&#125;let x = Directions.Up;\n\n编译后⽣成的 JavaScript 代码量较⼩：\n&quot;use strict&quot;;let x = 0 /* Directions.Up */;\n\n\n\ntypetype可以为任意类型创建别名，让代码更简洁、可读性更强，同时能更⽅便地进⾏类型复⽤和扩展。\n基本用法类型别名使⽤ type 关键字定义， type 后跟类型名称，例如下⾯代码中 num 是类型别名。\ntype num = numberlet price: numprice = 100\n\n联合类型联合类型是⼀种⾼级类型，它表示⼀个值可以是⼏种不同类型之⼀。\ntype Status = number | stringtype Gender = &#x27;男&#x27; | &#x27;⼥&#x27;function printStatus(status: Status) &#123; console.log(status);&#125;function logGender(str:Gender)&#123; console.log(str)&#125;printStatus(404);printStatus(&#x27;200&#x27;);printStatus(&#x27;501&#x27;);logGender(&#x27;男&#x27;)logGender(&#x27;⼥&#x27;)\n\n交叉类型交叉类型（Intersection Types）允许将多个类型合并为⼀个类型。合并后的类型将拥有所有被合并类型的成员。交叉类型通常⽤于对象类型。\n// ⾯积type Area = &#123; height: number; // ⾼ width: number; // 宽&#125;;// 地址type Address = &#123; num: number; // 楼号 cell: number; // 单元号 room: string; // 房间号&#125;;// 定义类型House，且House是Area和Address组成的交叉类型type House = Area &amp; Address;const house: House = &#123; height: 180, width: 75, num: 6, cell: 3, room: &#x27;702&#x27;&#125;;\n\n\n\n特殊情况先观察下面两段代码：\n\n代码1（正常）\n在函数定义时，限制函数返回值为 void ，那么函数的返回值就必须是空。\nfunction demo():void&#123; // 返回undefined合法 return undefined // 以下返回均不合法 return 100 return false return null return []&#125;demo()\n\n代码2（特殊）\n使⽤类型声明限制函数返回值为 void 时， TypeScript 并不会严格要求函数返回空。\ntype LogFunc = () =&gt; voidconst f1: LogFunc = () =&gt; &#123; return 100; // 允许返回⾮空值&#125;;const f2: LogFunc = () =&gt; 200; // 允许返回⾮空值const f3: LogFunc = function () &#123; return 300; // 允许返回⾮空值&#125;;\n\n为什么会这样？\n是为了确保如下代码成⽴，我们知道Array.prototype.push的返回值是⼀个数字，⽽Array.prototype.forEach⽅法期望其回调的返回类型是 void 。\nconst src = [1, 2, 3];const dst = [0];src.forEach((el) =&gt; dst.push(el));\n\n\n官方说明：Assignability of Functions\n\n\n\n类class Person &#123;    // 属性声明    name: string    age: number    // 构造器    constructor(name: string, age: number) &#123;        this.name = name        this.age = age    &#125;    // ⽅法    speak() &#123;        console.log(`我叫：$&#123;this.name&#125;，今年$&#123;this.age&#125;岁`)    &#125;&#125;// Person实例const p1 = new Person(&#x27;周杰伦&#x27;, 38)\n\n继承\nclass Student extends Person &#123;    grade: string    // 构造器    constructor(name: string, age: number, grade: string) &#123;        super(name, age)        this.grade = grade    &#125;    // 备注：本例中若Student类不需要额外的属性，Student的构造器可以省略    // 重写从⽗类继承的⽅法    override speak() &#123;        console.log(`我是学⽣，我叫：$&#123;this.name&#125;，今年$&#123;this.age&#125;岁，在读$&#123;this.grade&#125;年级`)    &#125;    // ⼦类⾃⼰的⽅法    study() &#123;        console.log(`$&#123;this.name&#125;正在努⼒学习中......`)    &#125;&#125;\n\n\n\n属性修饰符\n\n\n修饰符\n含义\n具体规则\n\n\n\npublic\n公开的\n可以被：类内部、子类、类外部访问\n\n\nprotected\n受保护的\n可以被：类内部、子类访问\n\n\nprivate\n私有的\n可以被：类内部访问\n\n\nreadonly\n只读属性\n属性无法修改\n\n\npublic修饰符class Person &#123;    // name写了public修饰符，age没写修饰符，最终都是public修饰符    public name: string    age: number    constructor(name: string, age: number) &#123;        this.name = name        this.age = age    &#125;    // 方法没写修饰符，也是public    speak() &#123;        // 类的【内部】可以访问public修饰的name和age        console.log(`我叫：$&#123;this.name&#125;，今年$&#123;this.age&#125;岁`)    &#125;&#125;const p1 = new Person(&#x27;张三&#x27;, 18)// 类的【外部】可以访问public修饰的属性console.log(p1.name)\n\nclass Student extends Person &#123;    constructor(name: string, age: number) &#123;        super(name, age)    &#125;    study() &#123;        // 【⼦类中】可以访问⽗类中public修饰的：name属性、age属性        console.log(`$&#123;this.age&#125;岁的$&#123;this.name&#125;正在努⼒学习`)    &#125;&#125;\n\n属性的简写形式：\n// 完整写法class Person &#123;    public name: string;    public age: number;    constructor(name: string, age: number) &#123;        this.name = name;        this.age = age;    &#125;&#125;// 简写class Person &#123;    constructor(        public name: string,        public age: number    )&#123;&#125;&#125;\n\nprotected修饰符class Person &#123;    // name和age是受保护属性，不能在类外部访问，但可以在【类】与【⼦类】中访问    constructor(        protected name: string,        protected age: number    ) &#123;&#125;    // getDetails是受保护⽅法，不能在类外部访问，但可以在【类】与【⼦类】中访问    protected getDetails(): string &#123;        // 类中能访问受保护的name和age属性        return `我叫：$&#123;this.name&#125;，年龄是：$&#123;this.age&#125;`    &#125;    // introduce是公开⽅法，类、⼦类、类外部都能使⽤    introduce() &#123;        // 类中能访问受保护的getDetails⽅法        console.log(this.getDetails());    &#125;&#125;const p1 = new Person(&#x27;杨超越&#x27;,18)// 可以在类外部访问introducep1.introduce()// 以下代码均报错p1.getDetails()p1.namep1.age\n\nclass Student extends Person &#123;    constructor(name:string,age:number)&#123;        super(name,age)    &#125;    study()&#123;        // ⼦类中可以访问introduce        this.introduce()        // ⼦类中可以访问name        console.log(`$&#123;this.name&#125;正在努⼒学习`)    &#125;&#125;const s1 = new Student(&#x27;tom&#x27;,17)s1.introduce()\n\nprivate修饰符class Person &#123;    constructor(        public name: string,        public age: number,        // IDCard属性为私有的(private)属性，只能在【类内部】使⽤        private IDCard: string    ) &#123; &#125;    private getPrivateInfo()&#123;        // 类内部可以访问私有的(private)属性 —— IDCard        return `身份证号码为：$&#123;this.IDCard&#125;`    &#125;    getInfo() &#123;        // 类内部可以访问受保护的(protected)属性 —— name和age        return `我叫: $&#123;this.name&#125;, 今年刚满$&#123;this.age&#125;岁`;    &#125;    getFullInfo()&#123;        // 类内部可以访问公开的getInfo⽅法，也可以访问私有的getPrivateInfo⽅法        return this.getInfo() + &#x27;，&#x27; + this.getPrivateInfo()    &#125;&#125;const p1 = new Person(&#x27;张三&#x27;,18,&#x27;110114198702034432&#x27;)console.log(p1.getFullInfo())console.log(p1.getInfo())// 以下代码均报错// p1.name// p1.age// p1.IDCard// p1.getPrivateInfo()\n\nreadonly修饰符class Car &#123;    constructor(        public readonly vin: string, //⻋辆识别码，为只读属性        public readonly year: number,//出⼚年份，为只读属性        public color: string,        public sound: string    ) &#123; &#125;    // 打印⻋辆信息    displayInfo() &#123;        console.log(`            识别码：$&#123;this.vin&#125;,            出⼚年份：$&#123;this.year&#125;,            颜⾊：$&#123;this.color&#125;,            ⾳响：$&#123;this.sound&#125;        `);    &#125;&#125;const car = new Car(&#x27;1HGCM82633A123456&#x27;, 2018, &#x27;⿊⾊&#x27;, &#x27;Bose⾳响&#x27;);car.displayInfo()// 以下代码均错误：不能修改 readonly 属性// car.vin = &#x27;897WYE87HA8SGDD8SDGHF&#x27;;// car.year = 2020;\n\n\n\n抽象类概述：抽象类是⼀种⽆法被实例化的类，专⻔⽤来定义类的结构和⾏为，类中可以写抽象⽅法，也可以写具体实现。抽象类主要⽤来为其派⽣类提供⼀个基础结构，要求其派⽣类必须实现其中的抽象⽅法。\n简记：抽象类不能实例化，其意义是可以被继承，抽象类⾥可以有普通⽅法、也可以有抽象⽅法。\nabstract class Package &#123;    constructor(public weight: number) &#123; &#125;    // 抽象⽅法：⽤来计算运费，不同类型包裹有不同的计算⽅式    abstract calculate(): number    // 通⽤⽅法：打印包裹详情    printPackage() &#123;        console.log(`包裹重量为: $&#123;this.weight&#125;kg，运费为:$&#123;this.calculate()&#125;元`);    &#125;&#125;\n\n// 标准包裹class StandardPackage extends Package &#123;    constructor(        weight: number,        public unitPrice: number // 每公⽄的固定费率    ) &#123; super(weight) &#125;    // 实现抽象⽅法：计算运费    calculate(): number &#123;        return this.weight * this.unitPrice;    &#125;&#125;// 创建标准包裹实例const s1 = new StandardPackage(10,5)s1.printPackage()// 特快包裹class ExpressPackage extends Package &#123;    constructor(        weight: number,        private unitPrice: number, // 每公⽄的固定费率（快速包裹更⾼）        private additional: number // 超出10kg以后的附加费    ) &#123; super(weight) &#125;    // 实现抽象⽅法：计算运费    calculate(): number &#123;        if(this.weight &gt; 10)&#123;            // 超出10kg的部分，每公⽄多收additional对应的价格            return 10 * this.unitPrice + (this.weight - 10) * this.additional        &#125; else &#123;            return this.weight * this.unitPrice;        &#125;    &#125;&#125;// 创建特快包裹实例const e1 = new ExpressPackage(13,8,2)e1.printPackage()\n\n总结：何时使⽤抽象类？\n\n定义通用接口：为⼀组相关的类定义通⽤的⾏为（⽅法或属性）时。 \n\n提供基础实现：在抽象类中提供某些⽅法或为其提供基础实现，这样派⽣类就可以继承这 些实现。\n\n确保关键实现：强制派⽣类实现⼀些关键⾏为。\n\n共享代码和逻辑：当多个类需要共享部分代码时，抽象类可以避免代码重复。\n\n\n\n\ninterfaceinterface 是⼀种定义结构的⽅式，主要作⽤是为：类、对象、函数等规定⼀种契约，这样可以确保代码的⼀致性和类型安全，但要注意 interface 只能定义格式，不能包含任何实现 ！\n定义类结构// PersonInterface接⼝，⽤与限制Person类的格式interface PersonInterface &#123; name: string age: number speak(n: number): void&#125;// 定义⼀个类 Person，实现 PersonInterface 接⼝class Person implements PersonInterface &#123;    constructor(        public name: string,        public age: number    ) &#123; &#125;    // 实现接⼝中的 speak ⽅法    speak(n: number): void &#123;        for (let i = 0; i &lt; n; i++) &#123;            // 打印出包含名字和年龄的问候语句            console.log(`你好，我叫$&#123;this.name&#125;，我的年龄是$&#123;this.age&#125;`);        &#125;    &#125;&#125;// 创建⼀个 Person 类的实例 p1，传⼊名字 &#x27;tom&#x27; 和年龄 18const p1 = new Person(&#x27;tom&#x27;, 18);p1.speak(3)\n\n定义对象结构interface UserInterface &#123;    name: string    readonly gender: string // 只读属性    age?: number // 可选属性    run: (n: number) =&gt; void&#125;const user: UserInterface = &#123;    name: &quot;张三&quot;,    gender: &#x27;男&#x27;,    age: 18,    run(n) &#123;        console.log(`奔跑了$&#123;n&#125;⽶`)    &#125;&#125;;\n\n定义函数结构interface CountInterface &#123;    (a: number, b: number): number;&#125;const count: CountInterface = (x, y) =&gt; &#123;    return x + y&#125;\n\n接口继承⼀个 interface 继承另⼀个 interface ，从⽽实现代码的复⽤\ninterface PersonInterface &#123;    name: string // 姓名    age: number // 年龄&#125;interface StudentInterface extends PersonInterface &#123;    grade: string // 年级&#125;const stu: StudentInterface = &#123;    name: &quot;张三&quot;,    age: 25,    grade: &#x27;⾼三&#x27;,&#125;\n\n接口合并接口可重复定义，相同接口名会自动合并。\n// PersonInterface接⼝interface PersonInterface &#123;    // 属性声明    name: string    age: number&#125;// 给PersonInterface接⼝添加新属性interface PersonInterface &#123;    // ⽅法声明    speak(): void&#125;// Person类实现PersonInterfaceclass Person implements PersonInterface &#123;    name: string    age: number    // 构造器    constructor(name: string, age: number) &#123;        this.name = name        this.age = age    &#125;    // ⽅法    speak() &#123;        console.log(&#x27;你好！我是⽼师:&#x27;, this.name)    &#125;&#125;\n\n总结：何时使⽤接⼝？\n\n定义对象的格式：描述数据模型、API响应格式、配置对象……等等，是开发中⽤的最多的场景。\n\n类的契约：规定⼀个类需要实现哪些属性和⽅法。\n\n自动合并：⼀般⽤于扩展第三⽅库的类型， 这种特性在⼤型项⽬中可能会⽤到。\n\n\n\n\n一些相似概念的区别interface和type的区别相同点：\n\ninterface和type都可以⽤于定义对象（函数）结构，在定义对象结构时两者可以互换。\n\n不同点：\n\ninterface更关注定义对象和类的结构，支持继承、合并。\ntype可以定义类型别名、联合类型、交叉类型，但不⽀持继承和⾃动合并。\n\n// 使⽤ interface 定义 Person 对象interface PersonInterface &#123;    name: string;    age: number;    speak(): void;&#125;// 使⽤ type 定义 Person 对象type PersonType = &#123;    name: string;    age: number;    speak(): void;&#125;;// 使⽤PersonInterfacelet person: PersonInterface = &#123;    name:&#x27;张三&#x27;,    age:18,    speak()&#123;        console.log(`我叫：$&#123;this.name&#125;，年龄：$&#123;this.age&#125;`)    &#125;&#125;// 使⽤PersonTypelet person: PersonType = &#123;    name:&#x27;张三&#x27;,    age:18,    speak()&#123;        console.log(`我叫：$&#123;this.name&#125;，年龄：$&#123;this.age&#125;`)    &#125;&#125;\n\n// 接口可以继承、合并interface PersonInterface &#123;    name: string // 姓名    age: number // 年龄&#125;interface PersonInterface &#123;    speak: () =&gt; void&#125;interface StudentInterface extends PersonInterface &#123;    grade: string // 年级&#125;const student: StudentInterface = &#123;    name: &#x27;李四&#x27;,    age: 18,    grade: &#x27;⾼⼆&#x27;,    speak() &#123;        console.log(this.name,this.age,this.grade)    &#125;&#125;\n\n// 使⽤ type 定义 Person 类型，并通过交叉类型实现属性的合并type PersonType = &#123;    name: string; // 姓名    age: number; // 年龄&#125; &amp; &#123;    speak: () =&gt; void;&#125;;// 使⽤ type 定义 Student 类型，并通过交叉类型继承 PersonTypetype StudentType = PersonType &amp; &#123;    grade: string; // 年级&#125;;const student: StudentType = &#123;    name: &#x27;李四&#x27;,    age: 18,    grade: &#x27;⾼⼆&#x27;,    speak() &#123;        console.log(this.name, this.age, this.grade);    &#125;&#125;;\n\ninterface和抽象类的区别相同点：\n\n都可以定义一个类的格式（定义类应遵循的契约）\n\n不同点：\n\n接口只能描述结构，不能有任何实现代码，⼀个类可以实现多个接⼝。\n抽象类既可以包含抽象⽅法，也可以包含具体⽅法，⼀个类只能继承⼀个抽象类。\n\n// FlyInterface 接⼝interface FlyInterface &#123;    fly(): void;&#125;// 定义 SwimInterface 接⼝interface SwimInterface &#123;    swim(): void;&#125;// Duck 类实现了 FlyInterface 和 SwimInterface 两个接⼝class Duck implements FlyInterface, SwimInterface &#123;    fly(): void &#123;        console.log(&#x27;鸭⼦可以⻜&#x27;);    &#125;    swim(): void &#123;        console.log(&#x27;鸭⼦可以游泳&#x27;);    &#125;&#125;// 创建⼀个 Duck 实例const duck = new Duck();duck.fly(); // 输出: 鸭⼦可以⻜duck.swim(); // 输出: 鸭⼦可以游泳\n\n\n\n泛型泛型允许我们在定义函数、类或接⼝时，使⽤类型参数来表示未指定的类型，这些参数在具体使⽤时，才被指定具体的类型，泛型能让同⼀段代码适⽤于多种类型，同时仍然保持类型的安全性。\n// 泛型函数function logData&lt;T&gt;(data: T): T &#123;    console.log(data)    return data&#125;logData&lt;number&gt;(100)logData&lt;string&gt;(&#x27;hello&#x27;)\n\n// 泛型可以有多个function logData&lt;T, U&gt;(data1: T, data2: U): T | U &#123; console.log(data1,data2) return Date.now() % 2 ? data1 : data2&#125;logData&lt;number, string&gt;(100, &#x27;hello&#x27;)logData&lt;string, boolean&gt;(&#x27;ok&#x27;, false)\n\n// 泛型接口interface PersonInterface&lt;T&gt; &#123;    name: string,    age: number,    extraInfo: T&#125;let p1: PersonInterface&lt;string&gt;let p2: PersonInterface&lt;number&gt;p1 = &#123; name: &#x27;张三&#x27;, age: 18, extraInfo: &#x27;⼀个好⼈&#x27; &#125;p2 = &#123; name: &#x27;李四&#x27;, age: 18, extraInfo: 250 &#125;\n\n// 泛型类class Person&lt;T&gt; &#123;    constructor(        public name: string,        public age: number,        public extraInfo: T    ) &#123; &#125;    speak() &#123;        console.log(`我叫$&#123;this.name&#125;今年$&#123;this.age&#125;岁了`)        console.log(this.extraInfo)    &#125;&#125;// 测试代码1const p1 = new Person&lt;number&gt;(&quot;tom&quot;, 30, 250);// 测试代码2type JobInfo = &#123;    title: string;    company: string;&#125;const p2 = new Person&lt;JobInfo&gt;(&quot;tom&quot;, 30,    &#123;        title: &#x27;研发总监&#x27;,         company: &#x27;发发发科技公司&#x27;     &#125;);\n\n// 泛型约束interface LengthInterface &#123;    length: number&#125;// 约束规则是：传⼊的类型T必须具有 length 属性function logPerson&lt;T extends LengthInterface&gt;(data: T): void &#123;    console.log(data.length)&#125;logPerson&lt;string&gt;(&#x27;hello&#x27;)// 报错：因为number不具备length属性// logPerson&lt;number&gt;(100)\n\n\n\n类型声明文件类型声明⽂件是 TypeScript 中的⼀种特殊⽂件，通常以 .d.ts 作为扩展名。它的主要作⽤是为现有的 JavaScript 代码提供类型信息，使得 TypeScript 能够在使⽤这些 JavaScript 库或模块时进⾏类型检查和提示。\n// demo.jsexport function add(a, b) &#123; return a + b;&#125;export function mul(a, b) &#123; return a * b;&#125;\n\n// demo.d.tsdeclare function add(a: number, b: number): number;declare function mul(a: number, b: number): number;export &#123; add, mul &#125;;\n\n// example.tsimport &#123; add, mul &#125; from &quot;./demo.js&quot;;const x = add(2, 3); // x 类型为 numberconst y = mul(4, 5); // y 类型为 numberconsole.log(x,y)\n\n\n\n装饰器简介\n装饰器本质是一种特殊的函数，它可以对：类、属性、方法、参数进行扩展，同时能让代码更简洁。\n装饰器自2015年在ECMAScript-6中被提出到现在，已将近10年。\n截止目前，装饰器依然是实验性特性 ，需要开发者手动调整配置，来开启装饰器支持。\n装饰器有 5 种：\n类装饰器\n属性装饰器\n方式装饰器\n访问器装饰器\n参数装饰器\n\n\n\n\n备注：虽然TypeScript5.0中可以直接使用类装饰器，但为了确保其他装饰器可用，现阶段使用时，仍建议使用experimentalDecorators配置来开启装饰器支持，而且不排除在来的版本中，官方会进一步调整装饰器的相关语法！参考：《TypeScript 5.0发版公告》\n\n\n\n类装饰器类装饰器是一个应用在类声明上的函数，可以为类添加额外的功能，或添加额外的逻辑。\n/*   Demo函数会在Person类定义时执行  参数说明：    ○ target参数是被装饰的类，即：Person*/function Demo(target: Function) &#123;  console.log(target)&#125;// 使用装饰器@Democlass Person &#123;&#125;\n\n","categories":["前端"],"tags":["TypeScript"]},{"title":"windows安装wsl+conda环境配置+pycharm设置","url":"/2023/12/30/windows%E5%AE%89%E8%A3%85wsl-conda%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-pycharm%E8%AE%BE%E7%BD%AE/","content":"一. windows 安装 wsl\nhttps://learn.microsoft.com/zh-cn/windows/wsl/install\n\n\n以管理员身份运行 Windows PowerShell\n执行：\nwsl --install\n\n出现以下提示表示安装成功：\n\n\n重启电脑，自动弹出子系统启动界面\n默认为 ubuntu\n\n\n设置用户名密码\n\n完毕\n\n默认安装在 C 盘，如果想移动到其他盘，参考：\nhttps://blog.csdn.net/yihuajack/article/details/119915303\n\n\n\n\n\n二. conda 环境设置\napt-get 替换国内镜像源\n\nhttps://blog.csdn.net/qq_21095573/article/details/99736630\nhttps://developer.aliyun.com/mirror/ubuntu?spm=a2c6h.13651102.0.0.3e221b11fHrGAW\n\n进入目录/etc/apt/：\ncd /etc/apt/\n\n备份当前sources.list：\nsudo cp sources.list sources.list.copy\n\n按照国内镜像源配置说明更改sources.list内容：\n\n更换完后，执行：\nsudo apt-get update\n\n如果没有出现异常则表示更换完毕\n\n安装 gcc 环境\nsudo apt install gcc build-essential\n\n安装 conda\n\nhttps://blog.csdn.net/weixin_44159487/article/details/105620256\n\n推荐安装 miniconda\n# 返回用户目录cd ~# 安装miniconda包wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-latest-Linux-x86_64.sh# 执行sh文件bash Miniconda3-latest-Linux-x86_64.sh\n\n按照提示安装即可\n安装完毕后重启终端，如果能看到（base）\n\n表示安装成功\n\n更换 conda 的 pip 安装源\n\nhttps://www.cnblogs.com/137point5/p/15000954.html\n\n永久更换清华源\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n\n\n但是个人更喜欢配置多个源，根据上图可以看到 pip 的配置文件存放在/home/当前用户/.config/pip/pip.conf中\n修改该文件：\n[global]index-url=https://pypi.tuna.tsinghua.edu.cn/simple/extra-index-url=http://mirrors.aliyun.com/pypi/simple/[install]trusted-host=pypi.tuna.tsinghua.edu.cn\tmirrors.aliyun.com\n\n\n这里注意不要配置官方源，否则默认会从官方源下载，导致下载速度还是很慢\n\n\n测试一下\n创建虚拟环境\nconda create -n test python=3.10\n\n切换到test环境\nconda activate test\n\n尝试安装一些包\n\n完毕\n\n\n\n\n三. pycharm 设置前提！前提！前提！需要 pycharm 专业版！！！如果不是专业版无法连接到 wsl 中的 conda 环境\n\n解释器设置选择 WSL\n\n后续操作同主系统直接使用 conda\n\n","categories":["其他"]},{"title":"同时配置github和gitlab","url":"/2022/11/22/%E5%90%8C%E6%97%B6%E9%85%8D%E7%BD%AEgithub%E5%92%8Cgitlab/","content":"1. 前置条件\n安装git\n拥有github和gitlab账号\n\n\n\n2. 步骤整体思路：针对不同HOST，使用不同公钥\n2.1 生成不同秘钥git bash打开命令行窗口，执行以下命令\n# 生成github账号的秘钥$ ssh-keygen -t rsa -f ~/.ssh/id_rsa_github -C &quot;GithubAccount&quot;# 生产gitlab账号的秘钥$ ssh-keygen -t rsa -f ~/.ssh/id_rsa_gitlab -C &quot;GitlabAccount&quot;\n\n2.2 修改config配置文件2.2.1 切换至~&#x2F;.ssh目录$ cd ~/.ssh\n\n2.2.2 修改配置文件$ vim config\n\n# gitlab    # Host 与 HostName 需要相同    Host gitlab.com    HostName gitlab.com    # 指定rsa秘钥文件    IdentityFile ~/.ssh/id_rsa_gitlab# github    Host github.com    HostName github.com    IdentityFile ~/.ssh/id_rsa_github\n\n注意：Host取代码托管平台的地址，如果是局域网的gitlab地址，请使用局域网地址，下文中测试的指令也需要同步修改\n2.3 在github和gitlab上添加个人公钥以github为例\n2.3.1 登录github账号，并进入设置\n2.3.2 进入公钥配置\n2.3.3 添加公钥\n\n因为配置的是github账号，所以复制~/.ssh/id_rsa_github.pub中的内容到上图的Key中\n\n2.4 测试# github测试$ ssh -T git@github.comHi GithubAccount! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.# gitlab测试$ ssh -T git@gitlab.comHi GitlabAccount! \n\n","categories":["其他"]},{"title":"原型与原型链","url":"/2022/03/11/%E5%8E%9F%E5%9E%8B%E4%B8%8E%E5%8E%9F%E5%9E%8B%E9%93%BE/","content":"1.前置知识在聊原型和原型链之前，我们需要知道几个概念：构造函数和普通函数、函数对象和实例对象。\n\n\n(1) 构造函数和普通函数function Test(hi)&#123;    this.hi = hi    console.log(this.hi);&#125;function test()&#123;    console.log(&quot;这是普通函数&quot;);&#125;var t = new Test(&quot;这是构造函数&quot;);test();\n\n在函数声明的时候，无法判断一个函数是否为构造函数。只有使用new操作符创建对象时，调用的函数才叫做构造函数。\n两者区别：\n\n作用不同\n普通函数的作用自然是执行函数体内的代码以实现某种功能。构造函数的作用是用来创建对象。\n\n调用方式不同\n普通函数直接调用：函数名()\n构造函数是为了创建对象，所以需要使用new关键字来调用：new 函数名()\n\n书写习惯不同\n为了区别普通函数和构造函数，构造函数的函数名一般大写开头。\n\nthis指向不同\n普通函数中的this指向window对象，构造函数中的this则是指向它创建的对象。\n\n写法不同\n构造函数中一般不写return。\n\n\n所以上述代码中test为普通函数，Test为构造函数。\n\n\n(2) 函数对象和实例对象以下面的代码为例：\nfunction Student(name)&#123;    this.name = name;&#125;var st1 = new Student(&#x27;小明&#x27;);\n\n在JavaScript中，函数也是对象，所以从这个角度讲，上述代码中Student构造函数也称为函数对象，而通过new操作符创建的对象，称为实例对象，上述代码中st1就是通过Student构造函数创建的实例对象。\n\n不仅仅是构造函数，任何函数从对象的角度讲或者当做对象去使用时，都可以称为函数对象。\n这里所说的函数对象不是JS内置的Function对象。\n\n\n\n2.原型什么是原型？我们还是通过上面的代码来讲解：\nfunction Student(name)&#123;    this.name = name;&#125;var st1 = new Student(&#x27;小明&#x27;);\n\n假设现在我们需要给st1添加一个speak方法，可以这么做：\nfunction Student(name)&#123;    this.name = name;&#125;var st1 = new Student(&#x27;小明&#x27;);st1.speak = function()&#123;    console.log(&quot;my name is&quot;, this.name);&#125;st1.speak();    // my name is 小明\n\n但假如我要给每一个Student创建出来的实例对象都添加上这个speak方法，可以这么做：\nfunction Student(name)&#123;    this.name = name;    this.speak = function()&#123;        console.log(&quot;my name is&quot;, this.name);    &#125;&#125;var st1 = new Student(&#x27;小明&#x27;);var st2 = new Student(&#x27;小红&#x27;);st1.speak();    // my name is 小明st2.speak();    // my name is 小红\n\n这种方式每创建一个实例对象，就会创建一个新的speak方法，也就是说每个实例对象的speak方法都是唯一的。\n\n但这种方式有个问题：如果我们创建出来的实例对象越来越多，在内存中占用的空间是不是也越来越多。\n我们仔细想想，这个speak方法需要每个实例对象都唯一吗？能不能共用一个？答案是可以共用，因为每个实例对象的speak方法做的事情都是一样的。\n那么我们要怎么修改呢？可以这么做：\nfunction Student(name)&#123;    this.name = name;    this.speak = _speak;&#125;// 将方法提取到全局作用域下function _speak()&#123;    console.log(&quot;my name is&quot;, this.name);&#125;var st1 = new Student(&#x27;小明&#x27;);var st2 = new Student(&#x27;小红&#x27;);st1.speak();    // my name is 小明st2.speak();    // my name is 小红\n\n这时候的内存空间：\n\n这种方式看上去很不错，但是仍然会带来一些问题：\n\n_speak是在全局作用域下声明的，可能会污染全局作用域（变量冲突）。\n随着全局作用域下的函数声明越来越多，全局作用域会变得越来越臃肿。\n\n\n\n因此，JS就提出了原型的概念。每一个函数对象身上都有一个prototype属性，该属性指向一个对象。\nfunction Student(name)&#123;    this.name = name;&#125;console.log(Student.prototype);    // Object\n\n这个对象叫做原型对象，每个函数对象都有自己的原型对象。\n\n不管是构造函数还是普通函数，都有prototype属性，只不过在普通函数上这一个属性没有什么作用。所以在讲原型时，我们比较强调构造函数，下文中的函数对象也都指构造函数。\n\n另外，创建实例对象时，实例对象身上会有一个属性__proto__，它指向创建该实例对象的函数对象的原型对象。同一个函数对象创建的每一个实例对象，它们的__proto__属性都指向同一个原型对象。\nfunction Student(name)&#123;    this.name = name;&#125;var st1 = new Student(&quot;小明&quot;);console.log(Student.prototype === st1.__proto__);  // true\n\n\n这就意味着，如果我们在函数对象的原型对象中添加属性和方法，该函数对象创建的实例对象也可以访问到。JS就是这么做的，JS中对于对象属性和方法的访问顺序是从对象本身到对象的原型，如果对象本身中就有要找的属性或方法，直接使用对象本身中的属性或方法，否则从对象的原型中找。比如：\nfunction Student(name)&#123;    this.name = name;&#125;Student.prototype.school = &quot;xx大学&quot;;var st1 = new Student(&quot;小明&quot;);console.log(st1.school);    // xx大学st1.school = &quot;yy大学&quot;;console.log(st1.school);    // yy大学\n\n\n\n那么为了实现我们上面所说的对于speak方法的操作，可以这么做：\nfunction Student(name)&#123;    this.name = name;&#125;Student.prototype.speak = function()&#123;    console.log(&quot;my name is&quot;, this.name);&#125;var st1 = new Student(&#x27;小明&#x27;);var st2 = new Student(&#x27;小红&#x27;);st1.speak();    // my name is 小明st2.speak();    // my name is 小红\n\n\n再补充一点，原型对象在函数声明时一同创建，然后挂载到函数对象的prototype属性上，另外原型对象上有一个constructor属性，指向创建它的函数对象，这样两者的关系就紧密结合起来了。\n完整关系图：\n\n总结：\n\n函数对象上有一个prototype属性，该属性称为显示原型。它指向一个对象，该对象称为原型对象。\n函数对象创建的每个实例对象都有一个 __proto__属性 ，该属性称为隐式原型。它指向创建该实例对象的函数对象的原型对象。\n原型对象上有一个constructor属性，它指向创建该原型对象的函数对象。\n\n所以原型就是一个对象，它的作用是所有实例对象共享属性和方法。\n\n一般是共享方法，因为属性一般都是实例对象独有的，不同实例对象他们的属性不同，比如上面的st1和st2，他们的name属性各不相同，不应该把name放入Student原型对象中。\n\n\n有些人可能会问：为什么一定要通过函数对象的prototype往原型对象上添加方法和属性，能不能通过实例对象的__proto__去添加呢？答案是不行的，实例对象的__proto__属性的意义在于为对象的查找机制提供一个方向或者说一条线路，但它是一个非标准属性，因此实际开发中不可以使用这个属性，这也是为什么称它为隐式原型的原因。\n\n\n\n3.原型链理解了原型之后，原型链理解起来就比较容易。我们还是从上面的例子入手：\nfunction Student(name)&#123;    this.name = name;&#125;Student.prototype.speak = function()&#123;    console.log(&quot;my name is&quot;, this.name);&#125;var st1 = new Student(&#x27;小明&#x27;);st1.speak();    // my name is 小明console.log(st1.toString());    // [object Object]\n\n我们会发现上述第九行代码，会输出[object Object]，也就是说st1能够执行toString()方法。但是st1这个实例对象本身和它__proto__所指向的原型对象上都没有这个方法。那这个方法是哪来的呢？\n我们知道，Object对象是所有对象的“祖先”，既然原型对象也是一个对象，那它也不例外，所以其实原型对象是Object对象的实例对象。既然是实例对象，那它身上就会有一个__proto__属性，指向Object对象的原型对象。\n\n我们简化一下这张图：\n\n接着我们来看下Object对象的原型对象上有没有toString()方法：\n\n果然有，这说明了什么？说明JS对于对象属性和方法的查找规则是这样的：\n先从对象本身去找，如果找不到，就去该对象的原型对象上去找，如果还是没有找到，就去原型对象的原型对象上去找……但原型对象不可能永无止境，Object对象的原型对象__proto__属性值为null，也就是说查找到Object对象的原型对象就结束了，如果还是没有找到，则返回undefined。\n\n像图上这条被__proto__链接起来的链式关系，就叫原型链。它直接反应了JS对于对象属性和方法的查找顺序。\n\n\n4.补充理解完了原型和原型链，我们再想一想，所有的函数都可以通过new Function()的方式创建，那么也就是说所有的函数都是Function对象的实例对象。既然是实例对象，那它身上就会有一个__proto__属性，并且这一属性指向Function对象的原型对象。\n\n那么Function对象是谁的实例对象呢？\n我们刚说所有函数都是Function对象的实例对象，而Function对象也是构造函数，那么不就成了Function对象创建了Function对象？其实不必太过纠结这一点，因为Function对象是JS的内置对象，在脚本还没开始执行，就已经创建好了。所以Function.__proto__ === Function.prototype，记住这一个特殊情况就好了。\n\n\nObject对象和Function对象都是函数对象，也就是构造函数。只不过它们两个都是JS的内置对象，所以没有特别标注函数对象。\n\n这里有一张非常流行的关于原型的图，就是我们刚刚讲到的所有内容：\n\n5.继承继承是面向对象编程的一个概念。继承可以使子类具有父类的属性和方法，同时可以在子类中重新定义或追加属性和方法。继承是类与类之间的关系。\n但是JavaScript并没有类的概念，只有对象。那怎么会有继承呢？因为JavaScript是非常灵活的，我们可以通过构造函数和原型来模拟类的继承。\n\n如果熟悉面向对象编程的语言，我们会发现JS中的构造函数和类有点相似。在ES6中，JS也提出了类的概念，但ES6中的类其实是一个语法糖，它的本质还是构造函数，感兴趣的可以自行了解。\n\n\n\n(1) 通过构造函数继承属性假如我们现在有一个Father构造函数，并且希望有另一个构造函数继承Father构造函数，我们可以这么做：\n// 父构造函数function Father(name,age)&#123;    // this 指向父构造函数的实例对象    this.name = name;    this.age = age;&#125;// 子构造函数function Son(name,age)&#123;    // this 指向子构造函数的实例对象    // 要想继承父构造函数的属性，必须调用父构造函数，并且将父构造函数中的this改为当前构造函数中的this    Father.call(this, name, age);&#125;var son = new Son(&#x27;小明&#x27;, 18);\n\n但是这样还不够，因为这样Son构造函数只继承了Father构造函数的属性，没有继承Father构造函数的方法：\n// 父构造函数function Father(name,age)&#123;    this.name = name;    this.age = age;&#125;Father.prototype.money = function()&#123;    console.log(1000);&#125;// 子构造函数function Son(name,age)&#123;    Father.call(this, name, age);&#125;var son = new Son(&#x27;小明&#x27;, 18);son.money();    // 报错，son无法调用money方法，或者说根本找不到money方法\n\n\n接下去，我们就需要让Son构造函数继承Father构造函数的方法。\n\n\n(2) 通过原型对象继承方法由上面的图像结合原型链的知识，我们可以发现，如果让Son原型对象链接到Father原型对象，那我们Son构造函数创建的实例对象，是不是就可以使用Father原型对象上的方法了？\n\n原型对象的链接是依靠__proto__属性去操作的，所以最简单的方式：\nSon.prototype.__proto__ = Father.prototype;\n\n但是我们说过__proto__属性不能直接使用。那有没有什么办法同样能实现上述代码的效果？我们可以这么做：\n// 父构造函数function Father(name,age)&#123;    this.name = name;    this.age = age;&#125;Father.prototype.money = function()&#123;    console.log(1000);&#125;// 子构造函数function Son(name,age)&#123;    Father.call(this, name, age);&#125;// 将Son构造函数的prototype指向Father构造函数创建的实例对象// 由于Father构造函数创建的实例对象中有__proto__属性，并且指向Father构造函数的原型对象// 这样就达到了我们预先的目的Son.prototype = new Father();var son = new Son(&#x27;小明&#x27;, 18);son.money();    // 1000\n\n\n这样Father构造函数创建的实例对象就变成了Son构造函数的原型对象，Son构造函数new出来的实例对象，也指向这一个Father构造函数创建的实例对象。从而达到我们预先的目的。\n\n除此之外还差一步，我们原先说过原型对象中有一个constructor属性指向构造函数，我们修改了构造函数的原型对象，那就需要将新的原型对象中的constructor属性指向构造函数。\n// 父构造函数function Father(name,age)&#123;    this.name = name;    this.age = age;&#125;Father.prototype.money = function()&#123;    console.log(1000);&#125;// 子构造函数function Son(name,age)&#123;    Father.call(this, name, age);&#125;Son.prototype = new Father();// 修改constructorSon.prototype.constructor = Son;var son = new Son(&#x27;小明&#x27;, 18);son.money();    // 1000\n\n\n上述这种继承方式叫做组合继承。\n\n\n\n\n参考：\nhttps://juejin.cn/post/6996583771952644110\nhttps://www.bilibili.com/video/BV1Kt411w7MP\n\n","categories":["前端"],"tags":["JavaScript"]},{"title":"布隆过滤器","url":"/2024/10/09/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","content":"概念布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。\n布隆过滤器可以用于检索一个元素是否在一个集合中。\n它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。\n\n\n特点优点：\n\n时间复杂度低，增加和查询元素的时间复杂为O(N)（N为哈希函数的个数，通常情况比较小）\n保密性强，布隆过滤器不存储元素本身\n存储空间小，如果允许存在一定的误判，布隆过滤器是非常节省空间的（相比其他数据结构如Set集合）\n\n缺点：\n\n有一定的误判率，但是可以通过调整参数来降低\n无法获取元素本身\n很难删除元素（删除元素会导致误判率升高）\n\n特点：\n\n布隆过滤器判断存在，不一定存在；判断不存在，则一定不存在\n\n\n\n如何使用原理布隆过滤器时一种专门用来解决去重问题的高级数据结构。\n实质就是一个大型位数组和几个不同的无偏Hash函数（无偏表示分布均匀）。由一个初值都为0的bit数组和多个哈希函数构成，用来快速判断某个数据是否存在。但和HyperLogLog一样，它也存在一定的误判概率。\n\n\n添加&#x2F;查询key\n添加key\n使用多个hash函数对key进行hash运算得到一个整数索引值，对位数组长度进行取模运算得到一个位置，每个hash函数都会得到一个不同的位置，将这几个位置都置为1就完成了添加操作。\n\n查询key\n只要有其中一位是0就表示这个key不存在，如果都是1，则不一定存在对应的key。\n\n存在哈希冲突，位上的1不一定是由这个key产生的。\n\n\n\n正是基于布隆过滤器的快速检测特性，我们可以把数据写入数据库时，使用布隆过滤器做个标记。当缓存缺失后，应用查询数据库时，可以通过查询布隆过滤器快速判断数据是否存在。如果不存在，就不用再去数据库中查询了。这样一来，即使发生缓存穿透了，大量请求只会查询Redis和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。布隆过滤器可以使用Redis实现，本身就能承担较大的并发访问压力。\n\n\n使用场景\n解决缓存穿透问题，和Redis结合bitmap使用\n黑名单校验，识别垃圾邮件\n解决新闻推荐过的不再推荐\n…\n\n\n","categories":["后端"],"tags":["Redis"]},{"title":"服务端渲染","url":"/2024/11/12/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B8%B2%E6%9F%93/","content":"客户端渲染在了解服务端渲染之前，我们需要先了解客户端渲染。\n什么是客户端渲染（CSR）？客户端渲染是指在浏览器中使用JavaScript代码生成内容。浏览器首先加载一个包含HTML骨架的页面，并通过JavaScript获取数据（如JSON），然后在用户界面上填充内容。这一过程通常依赖于AJAX请求和框架（如React、Vue等）来实现动态更新。\nCSR的工作流程\n用户请求服务器上的页面\n服务器返回一个最基本的HTML文件（通常包含JavaScript文件的引用）\n浏览器解析页面，加载JavaScript代码\nJavaScript代码在浏览器上执行，向服务器请求数据并生成动态内容\n用户在页面上与内容交互时，JavaScript可以通过AJAX等方式加载新数据并更新DOM\n\n优势\n服务器负担轻：页面渲染和大部分逻辑工作都在客户端完成，减少了服务端压力\n高交互性：用户与页面的交互通常会更流畅，因为页面不需要完整刷新\n丰富的用户体验：使用JavaScript库和框架（如React、Vue）可以创建高度动态的单页应用（SPA）\n\n劣势\n首屏渲染慢：用户在请求页面时可能需要等待JavaScript加载，这可能导致较慢的首屏渲染时间\nSEO问题：由于页面内容是由JavaScript生成的，搜索引擎可能无法有效抓取页面内容，影响SEO\n对旧浏览器支持差：某些旧浏览器可能不支持现代JavaScript功能，从而影响应用的广泛可用性\n\n服务端渲染服务端渲染其实不是一个新技术，过去前后端未分离的时候，由服务端返回HTML字符串（如最早学习Web时使用PHP输出HTML字符串），这就是早期的服务端渲染。\n什么是服务端渲染（SSR）？服务端渲染是指在服务器端生成完整的HTML页面并发送到客户端（浏览器），浏览器随即渲染这些HTML内容。这意味着所有的动态内容在用户请求页面时就已经在服务器上处理完成，得到完整的HTML返回。\nSSR的工作流程\n用户请求一个页面（例如，输入URL或点击链接）\n服务器接收到请求并处理相关数据（如从数据库中提取数据）\n服务器将数据渲染成HTML，并将完整的HTML文档返回给客户端\n客户端接收到完整的HTML后进行渲染，用户可以立刻看到页面内容\n\n优势\n首屏渲染快速：用户可以更快地看到页面内容，因为在页面返回之前已经生成了HTML\nSEO友好：由于页面内容在服务器端生成，搜索引擎可以更容易地抓取和索引页面内容\n适合内容丰富的页面：对内容丰富的网页（如博客、新闻网站等）尤为有效，因为大部分内容是在页面加载时就呈现给用户\n\n劣势\n服务器负担更重：服务器需要将所有页面的内容动态生成，这对服务器性能要求较高\n流量和响应速度：对于用户的每个操作，可能需要更多地与服务器进行交互，增加了延迟\n交互性降低：在用户与页面的交互过程中，每次请求可能需要重新加载页面，造成不必要的延迟\n\n在选择使用服务器端渲染或客户端渲染时，要考虑应用的特性和需求。有时可以结合这两种渲染方式，例如使用SSR初始加载后，使用CSR进行后续交互，这种方式被称为“混合渲染”（Hybrid Rendering），能够充分发挥两者的优势。\n例子一个非常简单的页面，只有一个列表：\n\n\n但是通过打包后的文件：\n\n可以看到，这个列表并没有存在HTML文档中，而是引入了一个JS文件，在页面渲染时执行并更新页面。这就是客户端渲染。\n通过查看页面源代码我们也能看到它并不会显示列表内容：\n\n所以一般的爬虫只能抓取这一部分数据，不能获取具体的页面信息，不利于SEO。\n相反，如果通过服务端渲染：\n// 简易服务端，仅作演示const express = require(&#x27;express&#x27;);const React = require(&#x27;react&#x27;);const ReactDOMServer = require(&#x27;react-dom/server&#x27;);const App = () =&gt; &lt;div&gt;Hello, SSR!&lt;/div&gt;;const server = express();server.get(&#x27;/&#x27;, (req, res) =&gt; &#123;  const html = ReactDOMServer.renderToString(&lt;App /&gt;);  res.send(`&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;My React SSR App&lt;/title&gt;&lt;/head&gt;&lt;body&gt;$&#123;html&#125;&lt;/body&gt;&lt;/html&gt;`);&#125;);server.listen(3000, () =&gt; &#123;  console.log(&#x27;Server is running on http://localhost:3000&#x27;);&#125;);\n\n浏览器能够获取到完整的HTML文档：\n\n既减少了浏览器执行JS的开销，首屏渲染快速，也更利于SEO：\n\n所以简单理解：服务端渲染其实就是把JS的执行加载部分放在服务端上运行，输出完整的HTML文档返回给浏览器。\n\n那么这时候就引申出另一个问题，为什么不能在打包构建阶段（build）就创建出完整的HTML文档？\n最主要的原因是动态数据，以博客为例，通过服务端渲染获取最新的博客信息，并携带这些信息返回完整HTML文档，更利于SEO（如果是客户端通过接口请求获取数据并更新页面，这就又回到了客户端渲染）。\n实际上，现在很多框架是支持在打包构建阶段（build）生成部分HTML文档的，但仅适用于静态数据。这种模式称之为预渲染。\n\n","categories":["前端"]},{"title":"执行上下文、作用域、作用域链和闭包","url":"/2022/02/20/%E6%89%A7%E8%A1%8C%E4%B8%8A%E4%B8%8B%E6%96%87%E3%80%81%E4%BD%9C%E7%94%A8%E5%9F%9F%E3%80%81%E4%BD%9C%E7%94%A8%E5%9F%9F%E9%93%BE%E5%92%8C%E9%97%AD%E5%8C%85/","content":"执行上下文、作用域、作用域链、闭包这四个概念联系非常紧密，所以放到同一篇博客中记录。现在网上的很多文章和视频都很难把这几个概念讲清楚，我看了之后，结合自己的理解记录这篇博客。如有错误，欢迎指正。\n\n\n一.执行上下文1.概念执行上下文（execution context）：当前 JavaScript 代码被解析和执行时存在的环境。它是为了方便理解提出来的一种抽象概念，并非真实存在。\n\n\n2.类型在 ES6 版本下，有四种情况会创建执行上下文：\n\n进入全局代码（全局执行上下文）\n进入 function 函数体代码（函数执行上下文）\n进入 eval 函数参数指定的代码（eval 执行上下文）\n进入 module 代码（module 执行上下文）\n\n我们重点关注前两种执行上下文：全局执行上下文和函数执行上下文\n\n\n3.执行上下文栈全局执行上下文只会存在一个，而函数执行上下文可以存在无数个。每当函数被调用，就会创建一个新的函数执行上下文。即使是同一个函数被多次调用，也会创建多个执行上下文。\n那么该如何管理这些上下文呢？这就有了执行上下文栈的概念，也叫执行栈或调用栈（如果了解 js 的事件循环机制，那对于调用栈并不陌生，我个人理解调用栈和执行上下文栈本质是同一个东西，只不过在事件循环机制中，我们更关注于代码的执行，也就是下文将提到的创建执行上下文的执行阶段）。\n执行栈具有LIFO（Last In First Out）的特点。当 JS 代码首次运行，都会创建一个全局执行上下文压入执行栈，之后每当有函数被调用，都将创建一个新的函数执行上下文压入栈中，当最顶层函数执行完毕，一步步出栈。\nfunction f1() &#123;  f2();  console.log(1);&#125;function f2() &#123;  f3();  console.log(2);&#125;function f3() &#123;  console.log(3);&#125;f1(); //3 2 1\n\n那么执行上下文究竟做了哪些事情呢？接下来我们重点讲一下。\n\n\n4.执行上下文的生命周期执行上下文的生命周期分为三个阶段：创建阶段、执行阶段、销毁阶段。\n由于标准的不断更新，对于执行上下文的内容也有了很大出入，首先将以 ES3 标准介绍执行上下文，比较容易理解，之后再讲解 ES5 标准。\n\n\n(1) 创建阶段执行上下文的创建阶段被称为预处理或预编译，指在代码运行前js 引擎所作的处理，ES3 标准中执行上下文的创建阶段主要有三个部分：\n\n创建变量对象&#x2F;活动对象\n创建作用域链\nthis 绑定\n\n1）创建变量对象每个执行上下文都有一个表示变量的对象——变量对象(variable object，简称VO)，刚刚说了，执行上下文又分为全局执行上下文和函数执行上下文，它们的变量对象是有区别的。\n全局执行上下文的变量对象叫做全局对象(global object，简称GO)，在浏览器环境 JS 引擎会整合&lt;script&gt;标签中的内容，产生window对象，这个 window 对象就是全局对象。在&lt;script&gt;标签中声明的变量称为全局变量，全局变量会作为 window 对象的属性存在。\n&lt;script&gt;  var a = 100;  console.log(a); // 100  console.log(window.a); // 100  console.log(window);&lt;/script&gt;&lt;script&gt;  console.log(a); // 100  console.log(window.a); // 100&lt;/script&gt;\n\n在&lt;script&gt;标签中的声明的函数为全局函数，全局函数会作为 window 对象的方法存在。\n&lt;script&gt;  function a() &#123;    console.log(1);  &#125;  console.log(window);&lt;/script&gt;\n\n当函数被调用时，会创建函数执行上下文，函数执行上下文的变量对象叫做活动对象(activation object，简称AO)。在函数内部声明的变量称为局部变量，局部变量会作为 AO 的属性存在。在函数内部声明的函数叫局部函数，局部函数会作为 AO 的方法存在。\n// 通过控制台断点查看function a() &#123;  var i = 0;  function b() &#123;    console.log(1);  &#125;  b();&#125;a();\n\n\n其实，变量对象、全局对象、活动对象是一个东西，只不过是不同状态和阶段而已。全局执行上下文中的变量对象叫全局对象，函数执行上下文中的变量对象叫活动对象。\n\n接下来，我们来看一段经典的代码：\nconsole.log(a); // undefinedvar a;\n\n为什么输出打印的结果是 undefined，接下去我们就来详细讲讲。\n首先，在全局执行上下文的创建阶段中（严格来讲，是创建阶段的变量对象部分），JS 引擎会做这些事情：\n\n生成 window 对象，也就是 GO 对象\n查找（全局）变量声明，作为 GO 对象的属性名，值为 undefined\n查找（全局）函数声明，作为 GO 对象的方法名，值为 function\n\n变量声明：通过var关键字声明变量\nvar a; // 变量声明var a = 100; // 变量声明+变量赋值\n\n函数声明：通过function关键字声明函数\nfunction a() &#123;&#125; // 函数声明var a = function () &#123;&#125;; // 注意：这种情况并不是函数声明，而是函数表达式。相当于变量声明，只不过这个变量在执行代码时被赋予一个函数\n\n注意：\n\n当查找函数声明并初始化时，创建了一个与之对应的函数对象，并被它引用\n如果变量和函数同名，函数声明会覆盖掉变量声明，也就是说结果为 function\n\n\n对于注意点 2，有些人的说法是 var 的优先级高，因为 JS 引擎会优先找 var 声明，另一些人的说法是 function 优先级高，因为如果出现同名，JS 引擎会选择 function。其实这两种说法只是理解角度不同而已，最终结果都是 function。下方的示例 2 就是演示这一点。\n\n示例 1：\nvar a = 100;function b() &#123;  console.log(1);&#125;/*\t1.产生window对象\t2.查找变量声明：a，作为GO的属性名，初始化为undefined\t3.查找函数声明：b，作为GO的方法名，初始化为function(实际上是创建了一个函数对象，并让b引用)\tGO：&#123;\t\ta:undefined,\t\tb:function\t&#125;*/\n\n用图像来表示：\n\n\n黄色虚线表示逻辑关系，红色实线表示真实的内存地址引用，下文同\n\n实例 2：\nconsole.log(a); // functionvar a = 1;function a() &#123;  console.log(1);&#125;\n\n到此为止，全局执行上下文的创建阶段结束。\n\n严格来讲，是全局执行上下文创建阶段中的变量对象部分结束，但是在这一章节的学习中，我们会发现创建阶段的变量对象这一部分对我们理解来说是最重要的，所以这一章节中，变量对象初始化完毕后，我们就认为创建阶段结束，作用域链和 this 绑定我们暂不讨论。\n\n接着讲解下函数执行上下文的创建阶段（严格来讲，是创建阶段的变量对象部分），JS 引擎会做这些事情：\n\n在函数被调用时，为当前函数产生 AO 对象\n查找（局部）变量声明和形参，作为 AO 对象的属性名，值为 undefined\n使用实参的值改变形参的值\n查找（局部）函数声明，作为 AO 对象的方法名，值为 function\n\n示例：\nfunction a(x) &#123;  var i = 0;  function b() &#123;    console.log(1);  &#125;  b();&#125;a(1);/*\t创建全局执行上下文，并压入栈\t1.产生window对象\t2.查找变量声明：无\t3.查找函数声明:a，作为GO的方法名，初始化为function\tGO：&#123;\t\ta:function\t&#125;\t到此为止全局执行上下文的创建阶段结束\t\t开始执行代码(这部分是执行上下文的执行阶段，但由于函数执行上下文只有在被调用时才会创建，所以需要执行，我们将在下文再接着讲执行阶段)\t运行到a(1)\t\t创建函数执行上下文，并压入栈\t1.产生函数AO对象\t2.查找函数内变量声明和形参：x、i，作为AO的属性名，初始化为undefined\t3.将实参1赋值给形参x，x:1\t4.查找函数内函数声明：b，作为AO的方法名，初始化为function\tAO:&#123;\t\tx:1,\t\ti:undefined,\t\tb:function\t&#125;*/\n\n同样用图像来表示：\n\n通过浏览器的调试工具查看：\n\n到此为止，函数执行上下文的创建阶段结束。\n了解完这部分后，我们会发现之前所谓的变量提升和函数提升就是指查找变量声明和函数声明。\n\n2）创建作用域链作用域和作用域链我将在下一章节重点讲，这里就先略过。\n\n3）绑定 this如果是全局执行上下文，this 其实就是全局对象，即 window 对象，如果是函数执行上下文，那就要确认当前可执行代码块的调用者， 并将调用者信息this value存入当前执行上下文，否则默认为全局对象调用。有关 this 的问题，可另行查看，本文不过多介绍，并且不再提及。\n\n综上，在执行上下文的创建阶段，变量对象是最主要的内容。\n\n\n(2) 执行阶段所谓执行阶段，反而比创建阶段更好理解，就是运行 JS 代码。\n在执行阶段中，JS 代码会被逐条执行，如果有赋值语句，就对应地去赋值……\n示例：\nfunction a(x) &#123;  console.log(i); // undefined  var i = 0;  console.log(i); // 0  function b() &#123;    console.log(1);  &#125;  b();&#125;a(1);/*\t创建全局执行上下文，并压入栈\t1.产生window对象\t2.查找变量声明：无\t3.查找函数声明：a，初始化为function\tGO:&#123;\t\ta:function\t&#125;\t全局执行上下文创建阶段结束，开始执行代码\t执行到a(1)\t\t创建a函数执行上下文，并压入栈\t1.产生AO对象\t2.查找形参和变量声明：x、i，并初始化为undefined\t3.将实参1赋值给形参x，x:1\t4.查找函数声明：b，并初始化为function\tAO:&#123;\t\tx:1,\t\ti:undefined,\t\tb:function\t&#125;\t函数执行上下文创建阶段结束，开始执行代码\tconsole.log(i)\t此时还没有执行赋值语句，所以i还是undefined\t继续执行 var i = 0\t此时AO:&#123; x:1, i:0, b:function &#125;\t再继续执行 console.log(i)\t输出的自然是0\t跳过函数声明，继续执行b()\t\t创建b函数执行上下文，并压入栈\t1.产生新的AO对象\t2.查找形参和变量声明：无\t3.查找函数声明：无\tAO:&#123;&#125;\t函数执行上下文创建阶段结束，开始执行代码\tconsole.log(1)\t输出打印1\tb函数执行完毕，接着就是执行上下文的销毁阶段\tb函数执行上下文将从执行栈中弹出并销毁，对应的AO对象也被释放\t然后继续执行a函数代码，a函数执行完毕，a函数执行上下文将从执行栈中弹出并销毁，对应的AO对象被释放\t继续执行全局代码\t注意：即使代码全部执行完毕，全局执行上下文也不会从执行栈中弹出，直到关闭该页面*/\n\n以上代码请结合画图理解\n\n\n(3) 销毁阶段当函数代码执行完后，当前执行上下文（局部环境）会被弹出执行上下文栈并销毁，对应的变量对象也被释放，控制权被重新交给执行栈上一层的执行上下文。\n\n这是一般情况，但如果产生了闭包，会有所不同。闭包将在下面的篇章中介绍。\n\n\n\n5.总结至此，执行上下文的所有内容都介绍完毕\n\n练习：\n// 第一题var foo = function () &#123;  console.log(&quot;foo1&quot;);&#125;;foo();var foo = function () &#123;  console.log(&quot;foo2&quot;);&#125;;foo();// 第二题foo();var foo = function foo() &#123;  console.log(&quot;foo1&quot;);&#125;;function foo() &#123;  console.log(&quot;foo2&quot;);&#125;foo();\n\n接下去我们讲解一下作用域与作用域链。\n\n\n二.作用域与作用域链1.作用域域，顾名思义就是区域、范围的意思。那么作用域，就是指当前代码对变量的访问区域，或者说可访问变量的集合。\n作用域分为三类：\n\n全局作用域\n局部作用域（函数作用域）\n块级作用域\n\n早期 ES 标准中并没有块级作用域的概念，我将在下文 ES5 标准中介绍块级作用域，这里我们只考虑全局作用域和局部作用域。从代码编写的角度可以这样理解：\n\n上面红色框表示的就是局部作用域，黄色框表示全局作用域。结合我们上面执行上下文中所学的内容，JS引擎对变量的访问实际上就是从GO或者AO对象上查找属性，那么也就是说：\n\n全局作用域本质上就是 GO 对象\n局部作用域本质上就是 AO 对象\n\n\n\n2.作用域链那么什么是作用域链呢？以下面的代码为例：\nvar i = 0;function a() &#123;  i++;  console.log(i);&#125;a();/*\t我们还是按照执行上下文来分析这段代码\t首先创建全局执行上下文，并压入执行栈\t1.产生window对象\t2.查找变量声明：i，并初始化为undefined\t3.查找函数声明：a，并初始化为function\tGO:&#123;\t\ti:undefined,\t\ta:function\t&#125;\t全局执行上下文创建完毕，开始执行代码\tvar i = 0\t将O赋值给GO对象中的i，此时的GO:&#123; i:0, a:function &#125;\t继续执行 a()\t\t创建a函数执行上下文，并压入执行栈\t1.产生AO对象\t2.查找形参和变量声明：无\t3.查找函数声明：无\tAO:&#123;&#125;\t函数执行上下文创建完毕，开始执行代码\ti++\t这个时候，JS引擎会先从函数作用域(也就是AO对象)中上查找i，发现函数作用域中并没有，于是就向上级作用域查找，这里代码的上级作用域就是全局作用域(GO对象)，发现i为0，那么执行i++。此时GO:&#123; i:1, a:function &#125;\t继续执行 console.log(i)\t查找过程同上，输出i为1。函数执行完毕\t...(销毁阶段省略)*/\n\n这样一个查找过程形成的链式结构，就叫作用域链。\n那么问题来了，函数 a 在执行中怎么确定上级作用域是谁呢？\n其实，在函数声明的时候，创建的函数对象中包含了一个隐藏属性[[scope]]，这个属性记录了当前的执行环境。上面的代码用图像表示：\n\n首先创建全局执行上下文并压入栈；产生 GO 对象；查找变量声明：i，初始化 undefined；查找函数声明：a，初始化 function，即创建一个函数对象，并被 a 引用。这个时候函数对象中的[[scope]]属性就记录了当前的执行环境，它是一个数组，而当前正处于全局执行上下文，那么这个数组的第 1 位就是 GO 对象：a.[[scope]] &#x3D; [GO]\n\n\n图上这么画其实不准确，数组也是一个对象，所以[[scope]]属性应该要引用这个对象的地址，而这个对象要引用 GO 对象，但为了避免线条过多造成的视觉影响，所以采用图上的画法。\n另外提醒一点，[[scope]]属性只有 JS 引擎能够访问，下文所有与[[scope]]相关的代码都是伪代码，比如：a.[[scope]]其实是不能运行的。\n\n\n全局执行上下文的创建结束，开始执行代码 var a &#x3D; 0\n\n\n继续执行 a()，此时函数被调用，创建函数执行上下文，并压入执行栈；产生 a 函数的 AO 对象；没有形参、变量声明和函数声明，AO 对象为空对象\n\n\n还记得执行上下文创建阶段中有一个创建作用域链吗？当函数执行上下文创建时，除了创建变量对象，JS 引擎还会根据函数的[[scope]]属性去创建作用域链，将当前产生的AO对象添加到作用域链的最前端，也就是说当前执行上下文的作用域链为[aAO,GO]，即 JS 引擎访问变量的顺序就是aAO-&gt;GO\n注意：\n\n作用域链也是个数组，但它和[[scope]]是不同的，后者是函数对象中的属性，表示函数创建时的执行环境；前者是执行上下文的一部分，表示当前执行上下文中 JS 引擎访问变量的查找过程。\n作用域链 &#x3D; AO + [[scope]]，AO 会添加在作用域链的最前面：作用域链 &#x3D; [AO].concat([[scope]])\n全局执行上下文的作用域链就是[GO]\n\n\n\n此时函数执行上下文创建完毕，开始执行代码 i++，顺着作用域链查找并执行赋值语句。然后继续执行 console.log(i)，输出打印 1\n\n\n函数执行完毕，a 函数执行上下文弹出并销毁，aAO 被释放\n\n\n继续执行全局代码，直至页面关闭，全局执行上下文弹出并销毁。\n\n\n我们可以通过下面这个例子加深理解：\nvar i = 0;function a() &#123;  function b() &#123;    function c() &#123;      console.log(i);    &#125;    c();  &#125;  b();&#125;a();\n\n当 c 函数执行上下文创建时的图应该是这个样子：\n\n\nb 函数是在 a 函数中声明的，b 函数创建时[[scope]]属性的赋值，其实和 a 函数执行上下文创建作用域链的步骤是一样的，都是复制 a 函数的[[scope]]属性中的对象，将 a 函数执行上下文产生的 AO 对象添加到数组的第一位，也就是说 b 函数的[[scope]]属性和 a 函数执行上下文的作用域链内容是一样的，但是表示的含义不同。\n[[scope]]所谓的保存当前执行环境，其实就是保存了变量对象到其中。\n\n再一次强调：函数创建时，就会保存当前的执行环境。所以有一句话叫：函数的作用域在函数创建的时候决定而不是在调用的时候决定。\n\n我个人认为，这句话的准确说法应该是：函数执行上下文的 作用域链，在函数创建的时候决定而不是调用的时候决定。（AO+[[scope]]）\n因为现在一直在讲作用域链，突然提及函数的作用域，感觉有点奇怪。我们刚刚说了函数的作用域本质上是 AO 对象，那这句话里的函数的作用域要是按照 AO 对象去理解的话显然说不通，它指的应该是函数的[[scope]]属性。\n无论你怎么理解，总归都是一句话：当函数创建时，它体内就保存了当时的执行环境。\n\n我们再用一个例子强化这个理解：\nfunction foo() &#123;  console.log(a);&#125;function bar() &#123;  var a = 3;  foo();&#125;var a = 2;bar();/*\t结果：console.log打印输出2，而不是3\t过程：\t创建全局执行上下文，并压入栈\t1.产生window对象\t2.查找变量声明：a，初始化为undefined\t3.查找函数声明:foo、bar，初始化为function\tGO:&#123;\t\ta:undefined,\t\tfoo:function\t\tbar:function\t&#125;\t同时\tfoo.[[scope]] = [GO]\tbar.[[scope]] = [GO]\t创建作用域链:因为是全局执行上下文，所以就是[GO]\t\t全局执行上下文创建完毕，开始执行代码\tvar a = 2\t此时GO:&#123; a:2, foo:function, bar:function &#125;\t继续执行bar()\t\t创建bar函数执行上下文，并压入栈\t1.产生AO对象(简称bAO)\t2.查找形参、变量声明：a，初始化为undefined\t3.没有形参，所以不用将实参赋值给形参\t4.查找函数声明：无\tbAO：&#123;\t\ta:undefined\t&#125;\t创建作用域链:[bAO,GO]\t\tbar函数执行上下文创建完毕，开始执行代码\tvar a = 3\t此时bAO:&#123; a:3 &#125;\t继续执行foo()\t这里要注意，foo并不是在bar函数中声明的，bAO中没有foo属性，那么JS引擎就会顺着作用域链去GO中查找，找到foo并执行\t\t创建foo函数执行上下文，并压入栈\t1.产生AO对象(简称fAO)\t2.查找形参、变量声明：无\t3.查找函数声明：无\tfAO:&#123;&#125;\t创建作用域链:[fAO,GO]\t\tfoo函数执行上下文创建完毕，开始执行代码\tconsole.log(a)\t由于fAO中并没有a属性，所以沿着作用域链查找GO，发现GO中的a为2，所以输出打印2而不是3\t...(销毁阶段省略)*/\n\n如果用图像表示：\n\n创建全局执行上下文并压入栈；产生 GO 对象；查找变量声明：a，并初始化为 undefined；查找函数声明：foo、bar，并初始化为 function。foo、bar 函数的[[scope]]值为[GO]，另外全局执行上下文的作用域链就是[GO]\n\n\n全局执行上下文创建完毕，开始执行代码 var a &#x3D; 2\n\n\n继续执行 bar()\n\n函数被调用，创建 bar 函数执行上下文；产生 AO 对象（图中的 bAO）；有一个变量声明 a，初始化为 undefined，没有形参，也没有函数声明\n\n\n接着创建 bar 函数执行上下文的作用域链，bar 函数的[[scope]]为[GO]，所以 bar 函数执行上下文的作用域链为[bAO, GO]\n\n\nbar 函数执行上下文创建完毕，开始执行代码 var a &#x3D; 3\n\n\n继续执行 foo()。因为 bAO 中并没有 foo 属性，JS 引擎将顺着作用域链查找，在 GO 中查找到 foo 并调用\n\n创建 foo 函数执行上下文；产生 AO 对象（图中的 fAO）；没有形参、变量声明、函数声明\n\n\n接着创建 foo 函数执行上下文的作用域链，foo 函数的[[scope]]为[GO]，所以 foo 函数执行上下文的作用域链为[fAO, GO]\n\n\nfoo 函数执行上下文创建完毕，开始执行代码 console.log(a)。由于 fAO 中并没有 a 属性，所以沿着作用域链查找，找到 GO 中有 a 属性，输出打印 2\n\n…（销毁阶段省略）\n\n\n从上面的图可以看出来，JS 引擎并非按照执行上下文的调用顺序形成作用域链（如果是按照调用顺序决定作用域链，那 foo 函数执行上下文的作用域链应该是 fAO-&gt;bAO-&gt;GO，显然并不是），而是根据函数创建时的执行环境形成作用域链。最直观的，我们可以直接通过函数的书写位置来判断作用域链。因此 JS 的作用域被称为词法作用域。\n\n\n\n3.总结作用域和作用域链的部分讲完了。这部分比较难理解，概念比较多，需要花时间消化。\n另外，不同人对于相同的词可能有不同的理解，这就导致很多博客和教学视频对于执行上下文、作用域和作用域链等概念解释得并不相同。上文仅代表我个人理解，对你或许会有帮助。\n练习：\n// 第一题var foo = 1;function bar() &#123;  console.log(foo);  var foo = 10;  console.log(foo);&#125;bar();// 第二题var foo = 1;function bar() &#123;  console.log(foo);  foo = 2;&#125;bar();console.log(foo);// 第三题var foo = 1;function bar(foo) &#123;  console.log(foo);  foo = 234;&#125;bar(123);console.log(foo);\n\n\n\n三.闭包1.概念这部分应该是 JS 当中最难理解的一部分，但有了之前学到的基础，这部分理解起来就会容易一些。\n还是通过一个例子引出：\nfunction test() &#123;  var i = 0;  console.log(i);&#125;test();\n\n如果用图像来表示：\n\n…（全局执行上下文的创建阶段和执行阶段省略）\n\n…（test 函数执行上下文的创建阶段和执行阶段省略）\n\n\n当函数执行完时，test 函数执行上下文从栈中弹出并销毁，对应的 AO 对象会被释放（图中蓝色框部分），那么我们将不再能够访问到变量 i\n\n\n\n那么我们想一想，有没有办法将这个 AO 对象保存下来呢？\n答案肯定是有的。如果我们在函数内部再去声明一个函数，那么这个函数对象的[[scope]]是不是就保留了当前的执行环境，也就是说它的体内存在对当前 AO 对象的引用。\nfunction test() &#123;  var i = 0;  function inner() &#123;    console.log(i);  &#125;&#125;test();\n\n\n但是这样还不够，当 test 函数执行上下文弹出并销毁时，图中的蓝色框部分一样会被释放掉，因为没有存在外部引用，这一部分不可被访问到。\n\n\n关于垃圾回收机制，可以参考这篇博客：\nhttps://segmentfault.com/a/1190000018605776\n\n解决办法就是在全局环境下声明一个变量，并将 test 函数内的 inner 函数返回给它，那么就可以通过全局变量去访问内部函数，进而可以访问到 AO 对象。这种情况下，AO 对象不会被释放。以下面的代码为例：\nfunction test() &#123;  var i = 0;  function inner() &#123;    console.log(i);  &#125;  return inner;&#125;var a = test();a(); // 输出打印0\n\n\n创建全局执行上下文，并压入栈；产生 GO 对象；查找变量声明：a，初始化为 undefined；查找函数声明：test，初始化为 funticon，test.[[scope]] &#x3D; [GO]；创建作用域链：[GO]\n\n\n全局执行上下文创建完毕，开始执行代码 var a &#x3D; test()\n\ntest 函数被调用，创建 test 函数执行上下文，并压入栈；产生 AO 对象：tAO；查找形参：无；查找变量声明：i，初始化为 undefined；查找函数声明：inner，初始化为 function，inner.[[scope]] &#x3D; [tAO，GO]；创建作用域链：[tAO，GO]\n\n\ntest 函数执行上下文创建完毕，开始执行代码 var i &#x3D; 0，return inner\n\n\ntest 函数执行完毕，函数上下文从执行栈中弹出并销毁，注意全局执行上下文中 var a &#x3D; test()还未执行完，需要将 test 函数的返回值赋值给变量 a，a 保存对 inner 函数对象的引用\n\n这时候由于 tAO 仍能被访问，所以它不会被释放\n\n继续执行全局代码 a()，也就是调用 inner 函数\n\n创建 inner 函数执行上下文，并压入栈；产生 AO 对象：iAO；查找形参：无；查找变量声明：无；查找函数声明：无；创建作用域链：因为 inner 函数[[scope]]为[tAO，GO]，所以作用域链为[iAO，tAO，GO]\n\n\ninner 函数执行上下文创建完毕，开始执行代码 console.log(i)。JS 引擎会顺着作用域链查找变量，在 tAO 中找到，输出打印 0\n\ninner 函数执行完毕，从执行栈中弹出并销毁，对应的 iAO 被释放\n\n\n\n这就是闭包。百度百科上的解释是：闭包就是能够读取其他函数内部变量的函数。按照这样的解释，我们上面代码中的 inner 函数就是闭包。由于在 javascript 中，只有函数内部的子函数才能读取局部变量，所以说，闭包可以简单理解成“定义在一个函数内部的函数”。所以在本质上，闭包是将函数内部和函数外部连接起来的桥梁。\n\n\n2.作用闭包最大的作用有两个：\n\n可以让外部环境读取到函数内部的变量\n刚刚的例子中，我们在全局执行上下文中，可以读取到 test 函数内的变量 i。\n\n可以让这些变量的值始终保存在内存中，延长它们的生命周期\n刚刚的例子中，变量 i 始终没有被释放。\n\n\n\n\n3.问题凡事都有两面性，闭包带来好处的同时，必然会带来一些问题。其实我们刚刚讲到的闭包作用之一：延迟局部变量的生命周期。这就容易导致内存泄漏，将不必要的局部变量保存在内存当中。\n解决方案：在不使用局部变量后将其释放。如果是刚刚的例子，可以在代码最后加上a = null释放掉。\n\n\n4.总结在这一章节中，我们介绍了闭包的概念、作用和带来的问题。我们总结一下闭包形成的条件：\n\n函数嵌套\n上面的例子中，test 函数嵌套了 inner 函数，test 函数称为外部函数，inner 函数称为内部函数。为什么需要返回一个函数？因为函数是个对象，如果返回的仅仅是原始数据类型，变量 a 只会简单复制返回的值，而不是对一个对象的引用。\n\n内部函数使用了外部函数的变量\n闭包的目的就是为了让外部环境读取到函数内部的变量，如果内部函数不使用外部函数的变量，那返回内部函数也没有意义。\n\n内部函数需要被外部环境引用\n如果不被引用，内部函数将在外部函数运行完被释放。\n\n\n练习：\n// 第一题var a = 1;function foo() &#123;  var a = 2;  return function () &#123;    console.log(a);  &#125;;&#125;var bar = foo();bar();// 第二题function foo() &#123;  var a = 0;  return function () &#123;    console.log(a++);  &#125;;&#125;var bar = foo();bar();bar();bar();// 第三题function a() &#123;  function b() &#123;    var i = 0;    return function () &#123;      console.log(i++);    &#125;;  &#125;  var c = b();  c();&#125;a();\n\n\n\n四.ES5 标准下的执行上下文从 ES5 标准开始，执行上下文与 ES3 有了很大的变化，最大的改变就是去除了变量对象的概念，以词法环境组件和变量环境组件替代。\n在 ES5 中执行上下文创建阶段主要做三件事：\n\n创建词法环境组件\n创建变量环境组件\n绑定 this\n\n接下来我们聊一聊这些新名词。\n\n\n1.词法环境&#x2F;变量环境(1) 词法环境词法环境（Lexical Environment），是一种持有标志符—变量的映射的结构（标志符就是指变量&#x2F;函数名，变量是对实际对象或原始数据的引用）。看不懂没关系，我们先继续。\n词法环境的内部有两个组件：\n\n环境记录器（Environment Record）：是存储变量和函数声明的实际位置\n外部环境的引用（outer）：意味着它可以访问其父级词法环境\n\n如果用伪代码看起来是这样的：\nLexicalEnvironment: &#123;       // 词法环境    EnvironmentRecord: &#123;&#125;,  // 环境记录器    outer: &lt;null&gt;,          // 外部环境的引用&#125;\n\n这么一看，词法环境中的环境记录器像不像我们 ES3 中的变量对象，因为它们的作用是一样的。如果用图像表示，大概就像这样：\n\n另外，我们会发现在 ES5 规范的执行上下文的创建阶段，没有了 ES3 时候的创建作用域链，这其实是将作用域链的概念转移到了 outer 中。\n\n\n(2) 变量环境变量环境（Variable Environment），它也是一个词法环境，所以它有着词法环境的所有特性，包括环境记录器和对外部环境的引用。\nVariableEnvironment: &#123;      // 变量环境    EnvironmentRecord: &#123;&#125;,  // 环境记录器    outer: &lt;null&gt;,          // 外部环境的引用&#125;\n\n既然它就是一个词法环境，为什么要单独提出一个变量环境的概念呢？之所以在 ES5 的规范里要单独分出一个变量环境的概念是为 ES6 服务的：在 ES6 中词法环境用来存储let、const 变量声明，而变量环境用来存储var 变量声明和函数声明。如果用图像表示，大概这样：\n\n在 ES5 中，还没有 let、const 声明，以及待会要讲到的块级作用域，在 ES6 中它们才出现。但是这些概念已经提出来了，ES5 中执行上下文的很多内容其实是在为 ES6 服务。\n\n\n\n\n(3) 环境记录器环境记录器（Environment Record），它是存储变量和函数声明的实际位置。\n在全局环境和函数环境中，环境记录器又有所区别，它有两种类型：\n\n对象环境记录器（在全局环境中）\n声明式环境记录器（在函数环境中）\n\n声明式环境记录器相比对象环境记录器，还包含一个传递给函数的arguments对象和传递给函数的参数的length。\n\n\n(4) 外部环境的引用外部环境的引用（outer），它的作用是访问父级词法环境。\n\n在全局执行上下文中，该值为 null\n在函数执行上下文中，该值为全局对象，或者为父级词法环境（作用域）\n\n\n\n2.执行上下文的生命周期ES5 标准中执行上下文的执行阶段和销毁阶段与 ES3 基本无异，故重点还是关注创建阶段。\n\n全局执行上下文的创建阶段，JS 引擎会做这些事情：\n\n\n创建词法环境，对外部环境的引用为null\n查找顶级let、const 变量声明，存入词法环境的环境记录器，但不初始化\n\n\n创建变量环境，对外部环境的引用为null\n查找非函数内的 var 声明，存入变量环境的环境记录器，初始化为 undefined\n查找顶级函数声明，存入变量环境的环境记录器，初始化为 function\n查找代码块中的与上述几条非重名的函数声明，存入变量环境的环境记录器，初始化为 undefined\n\n\n绑定 this（这点在本文中不介绍）\n\n\n函数执行上下文的创建阶段，JS 引擎会做这些事情：\n\n\n创建词法环境，对外部环境的引用为父级词法环境\n查找函数内非块中的 let、const 变量声明，存入词法环境的环境记录器，但不初始化\n\n\n创建变量环境，对外部环境的引用为父级词法环境\n查找函数内的 var 声明，存入变量环境的环境记录器，初始化为 undefined\n查找形参，存入变量环境的环境记录器，并将实参赋值给形参\n查找函数内非块中的函数声明，存入变量环境的环境记录器，初始化为 function\n查找代码块中的与上述几条非重名的函数声明，存入变量环境的环境记录器，初始化为 undefined\n\n\n绑定 this（这点在本文中不介绍）\n\n注意：\n\n函数执行上下文和全局执行上下文的最主要区别就是对形参的处理，其他都是一致的。\n\nlet、const 声明的变量，是不初始化的。所以下面的代码会报错。之所以说 let、const 声明的变量没有变量提升，就是这个原因。\nconsole.log(a);let a;\n\n但是，如果两行代码如果换一下位置，是不会报错的。这是因为在执行上下文的执行阶段，当 JS 引擎运行到let a这行代码，发现 a 未初始化，就会初始化为 undefined。\nlet a;console.log(a); // undefined\n\n不允许同一作用域下出现和 let、const 声明的变量同名的变量或函数，否则会报错。\n\n在执行上下文的创建阶段过程中，我非常强调顶级、非函数内、代码块、函数内非块中等词语，这是因为 let、const 声明的变量存在块级作用域的概念，而 var 声明的变量并没有，而对代码块中的函数声明和非代码块中的函数声明，JS 引擎又有不同的处理方式。这些内容我将在下一小节中讲解。\n\n\n\n\n3.块级作用域(1) 概念从 ES6 开始，加入了块级作用域。从代码编写的角度来看，块级作用域可以这么理解：\n\n蓝色框表示的就是块级作用域。用&#123;&#125;包裹起来的代码称之为代码块，每个代码块都有一个块级作用域。\n\n\n(2) let、const 变量我们知道 var 声明的变量是没有块级作用域的概念的，而 let、const 声明的变量存在块级作用域。为了更好理解 let 和 var 的不同，我们可以看下面这个例子：\nvar a = &quot;global a&quot;;let b = &quot;global b&quot;;&#123;  let b = &quot;block b&quot;;  var c = &quot;block c&quot;;  let d = &quot;block d&quot;;  console.log(a);  console.log(b);&#125;console.log(b);console.log(c);console.log(d);\n\n为了方便理解和观看，我将不再细分环境记录器和外部环境的引用，直接将词法环境当做整体来使用。\n\n同样用画图来表示上面的代码：\n\n创建全局执行上下文，并压入栈。\n\n创建词法环境，查找顶级const、let 变量声明。\n所谓顶级的 const、let 变量声明，指的是不在代码块中且不在函数中的 const、let 变量声明。\n找到变量 b，加入词法环境，但不初始化。\n\n\n创建变量环境，查找非函数内的 var 变量声明。\n因为 var 变量没有块级作用域的概念，所以无论是否在代码块中声明，都需要找出来。\n找到变量 a、c，加入变量环境，初始化为 undefined。\n\n\n没有函数声明。全局执行上下文创建完毕，开始执行代码。\n\n执行var a = &quot;global a&quot;和let b = &quot;global b&quot;。\n\n\n继续执行代码，这时遇到了代码块。\n注意：\n\n执行代码块是不创建执行上下文的！\nJS 引擎会将代码块中声明的 let、const 变量和函数存储在一个单独的区域。这块特殊区域就可以理解成块级作用域。\n当代码块中的代码执行完，如果不存在外部引用，这块区域将被释放。\n块级作用域也是一个词法环境。\n\n\n\n查找代码块中的 let、const 变量声明。\n找到变量 b、d，加入到块级作用域，但不初始化。\n\n\n没有函数声明。继续执行代码。\n\n执行完let b = &quot;block b&quot;，执行var c = &quot;block c&quot;。\n注意：\n\n在一个执行上下文中，JS 引擎的访问顺序是从词法环境到变量环境。\n当执行到代码块中的语句时，则从块级作用域到词法环境再到变量环境。\n如果存在代码块嵌套，则从最内部代码块生成的块级作用域到上一层代码块生成的块级作用域，一直到变量环境。\n当代码块执行完毕，当前执行上下文将不再访问该块级作用域。\n\n在变量环境中找到变量 c 并赋值。\n\n\n继续执行let d = &quot;block d&quot;。\n\n\n然后开始输出打印，按照上面所说的访问顺序查找变量 a、b，输出打印global a和block b。\n\n代码块执行完毕，由于不存在外部引用，块级作用域被释放。\n\n\n继续执行console.log(b)，输出打印global b。执行console.log(c)，输出打印block c。执行console.log(d)，由于找不到 d，所以这一步会报错。最终结果：\n\n\n\n\n\n(3) 块级作用域中的函数声明JS 引擎在创建执行上下文时，对于代码块中的函数声明和非代码块中的函数声明有不同的处理方式：\n\n非代码块中的函数声明：\n将函数名添加到变量环境，并初始化为 function。\n\n代码块中的函数声明：\n如果当前执行上下文中的词法环境和变量环境中存在同名变量或函数，则不进行任何操作。否则，将函数名添加到变量环境，并初始化为undefined。\n\n\n我们用几个例子演示一下：\n// 示例1console.log(test); // 输出的是undefinedvar test = 0;if (true) &#123;  function test() &#123;    console.log(1);  &#125;&#125;// 示例2console.log(test); // 报错，test未初始化let test = 0;if (true) &#123;  function test() &#123;    console.log(1);  &#125;&#125;// 示例3console.log(test); // 输出的是代码块外面的函数function test() &#123;  console.log(2);&#125;if (true) &#123;  function test() &#123;    console.log(1);  &#125;&#125;// 示例4console.log(test); // 输出的是undefinedif (true) &#123;  function test() &#123;    console.log(1);  &#125;&#125;\n\n接着在执行上下文的执行阶段，当执行到代码块时，查找代码块中的函数声明，添加到块级作用域，并初始化为 function。当代码块执行完，查找变量环境中是否存在同名变量，如果存在，让它引用该函数对象。\n用画图的方式解释一下：\nif (true) &#123;  let i = 0;  function test() &#123;    console.log(i);  &#125;&#125;test();\n\n\n创建全局执行上下文并压入栈。\n\n创建词法环境，查找顶级 let、const 声明的变量：无。\n\n创建变量环境，查找非函数体内 var 声明的变量：无。查找函数声明：找到块中的 test 函数，由于处于代码块当中，所以将函数名添加到变量环境中，并初始化为 undefined。\n\n\n全局执行上下文创建完毕，开始执行代码。\n\n执行到代码块，生成块作用域。查找代码块中的 let、const 声明：i，但不初始化；查找函数声明，找到 test 函数，初始化为 function。\n\n\n继续执行代码let i = 0。\n\n\n代码块执行完毕，查找变量环境中是否存在 test 变量，存在则让其引用 test 函数对象。\n注意：由于函数创建时会保存当时的执行环境，所以 test 函数体内存在对 if 块作用域的引用，而变量环境中的 test 又引用了 test 函数对象，所以即使这个代码块执行完，if 块作用域也不会被释放。这就和我们上面讲闭包时一样。\n\n\n继续执行代码，调用 test 函数。\n注意：代码块执行完后，全局上下文就不能访问块级作用域了，所以这个 test 函数是变量环境中的 test 函数，而不是 if 块作用域中的 test 函数。\n\n创建 test 函数执行上下文，并压入栈。\n\n…（test 函数执行上下文创建过程省略）\n\n\n开始执行代码console.log(i)，在 if 块作用域中找到变量 i，输出打印0。\n\n…（test 函数执行上下文销毁阶段省略）\n\n\n有兴趣的可以同样用画图的方式，理解一下以下代码：\n// 示例1console.log(test); // 输出的是undefinedvar test = 0;if (true) &#123;  function test() &#123;    console.log(1);  &#125;&#125;console.log(test); // 输出的是function// 示例2let test = 0;if (true) &#123;  function test() &#123;    console.log(1);  &#125;&#125;console.log(test); // 输出的是0// 示例3console.log(test); // 输出的是代码块外面的函数function test() &#123;  console.log(2);&#125;if (true) &#123;  function test() &#123;    console.log(1);  &#125;&#125;console.log(test); // 输出的是代码块内部的函数\n\n\n\n4.总结我们会发现，ES5 标准的执行上下文与 ES3 标准并无太多区别，只是用词法环境&#x2F;变量环境去替代了变量对象，多了一个针对 let、const 声明的变量的处理，以及块级作用域的处理。在 ES5 标准中，可以将作用域理解成词法环境。\n随着 ES 标准的不断更新，执行上下文的内容也在发生变化，比如：在最新的 ES6 标准中，词法环境用于存储函数声明和 const、let 声明的变量，而变量环境只存储 var 声明的变量；而 ES9 中的执行上下文又与上文有所区别。感兴趣的可以自行了解。以上内容仅供理解，如有错误，欢迎指正。\n\n\n五.Q&amp;A\n作用域和执行上下文有什么区别？\n答：我个人认为这两个是包含关系，执行上下文中包含了作用域，同时还有其他像 this 绑定等内容。\n\n什么是作用域？\n答：根据不同的标准，对作用域的理解是不同的，ES3 的标准中，作用域可以理解为变量对象；而在 ES5 标准中，作用域可以理解为词法环境。\n\n函数的作用域链是什么时候建立的？\n答：我认为，函数没有作用域链的概念，作用域链是执行上下文中的内容。而函数只有一个[[scope]]属性，它在函数创建的时候就保存了当时的执行环境。当函数被调用时，函数执行上下文会根据[[scope]]创建作用域链。这个问题中的作用域链，应该指的是函数[[scope]]属性，它是在函数创建的时候建立的。\n\n\n\n\n\n参考视频：\nES3 标准：https://www.bilibili.com/video/BV1C54y1r7VS\nES5 标准：https://www.bilibili.com/video/BV1wD4y1D7Pp\n参考文章：\nhttps://www.cnblogs.com/echolun/p/11438363.html\nhttps://juejin.cn/post/7043408377661095967\nhttps://blog.csdn.net/feral_coder/article/details/106447013\nhttps://www.zhihu.com/question/36751764\nhttp://www.ruanyifeng.com/blog/2009/08/learning_javascript_closures.html\nhttps://segmentfault.com/a/1190000018605776\n\n","categories":["前端"],"tags":["JavaScript"]},{"title":"一些常见函数","url":"/2022/03/11/%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/","content":"1.快速排序标准版本：\nfunction quickSort(list, start, end) &#123;    if (end &lt;= start) &#123;        return;    &#125;    let left = start;    let right = end;    while (left &lt; right) &#123;        while (list[right] &gt; list[start]) &#123;            right--;        &#125;        while (list[left] &lt;= list[start]) &#123;            left++;        &#125;        if (left &lt; right) &#123;            let temp = list[left];            list[left] = list[right];            list[right] = temp;        &#125;    &#125;    let temp = list[right];    list[right] = list[start];    list[start] = temp;    quickSort(list, start, right - 1);    quickSort(list, right + 1, end);&#125;\n\n另一种实现方式：\nfunction quickSort(list) &#123;    if (list.length &lt;= 1) &#123;        return list;    &#125;    let left = [];    let right = [];    for (let i = 1; i &lt; list.length; ++i) &#123;        if (list[i] &lt;= list[0]) &#123;            left.push(list[i]);        &#125; else &#123;            right.push(list[i]);        &#125;    &#125;    return quickSort(left).concat(list[0], quickSort(right));&#125;// 也可以用ES6数组的filter方法缩写上述代码function quickSort(list) &#123;    if (list.length &lt;= 1) &#123;        return list;    &#125;    let left = list.filter((x, i) =&gt; x &lt;= list[0] &amp;&amp; i != 0);    let right = list.filter((x) =&gt; x &gt; list[0]);    return quickSort(left).concat(list[0], quickSort(right));&#125;\n\n\n\n2.防抖在规定时间后执行函数，如果函数在规定时间内再次被触发，将重新计时。\nfunction debounce(func, gapTime = 1500) &#123;    let timer = null;    return function() &#123;        if (timer !== null) &#123;            clearTimeout(timer);        &#125;        timer = setTimeout(() =&gt; &#123;            func.apply(this, arguments);        &#125;, gapTime)    &#125;&#125;\n\n\n\n3.节流规定时间内只执行一次函数。\nfunction throttle(func, gapTime = 1500) &#123;    let lastTime = null    return function() &#123;        let nowTime = Date.now()        if (nowTime - lastTime &gt; gapTime || !lastTime) &#123;            func.apply(this, arguments)            lastTime = nowTime        &#125;    &#125;&#125;","categories":["前端"],"tags":["JavaScript"]},{"title":"深拷贝","url":"/2022/03/11/%E6%B7%B1%E6%8B%B7%E8%B4%9D/","content":"1.JSON转换这是最简单的一种方式：\nJSON.parse(JSON.stringify(对象));\n\n但这种方式有很大缺陷，由于它是依赖于JSON，因此它不支持JSON不支持的其他格式，通过JSON的官网可知，JSON只支持Object、Array、String、Number、Boolean、Null这几种数据类型，其他的比如Function、Undefined、Date、RegExp等数据类型都不支持。对于它不支持的数据都会直接忽略该属性。\n另外，如果对象存在循环引用的情况，会导致栈溢出。\n\n\n2.递归函数通过JSON转换有那么多问题，那我们就需要自己手写一个深拷贝方法，最常用的就是通过递归实现。\n(1) 基础版本function clone(target) &#123;    if (target instanceof Object) &#123;        let cloneTarget = &#123;&#125;;        for (const key in target) &#123;            cloneTarget[key] = clone(target[key]);        &#125;        return cloneTarget;    &#125; else &#123;        return target;    &#125;&#125;;\n\n这种方式只能拷贝最简单的对象，还没有考虑其他引用类型：如数组、函数等。\n(2) 拷贝数组function clone(target) &#123;    if (target instanceof Object) &#123;        let cloneTarget = null;        if (target instanceof Array) &#123;            // 如果是数组            cloneTarget = [];        &#125; else &#123;            cloneTarget = &#123;&#125;;        &#125;        for (const key in target) &#123;            cloneTarget[key] = clone(target[key]);        &#125;        return cloneTarget;    &#125; else &#123;        return target;    &#125;&#125;\n\n(3) 拷贝函数对于函数的拷贝其实是有争议的，我认为函数不应该有深拷贝，因为对于函数，绝大多数情况都是用来调用执行，很少用来操作函数对象，所以对于函数的拷贝，我认为只需要拷贝引用即可。\nfunction clone(target) &#123;    if (target instanceof Object) &#123;        let cloneTarget = null;        if (target instanceof Array) &#123;            cloneTarget = [];        &#125; else if (target instanceof Function) &#123;            // 如果是函数            cloneTarget = target;        &#125; else &#123;            cloneTarget = &#123;&#125;;        &#125;        for (const key in target) &#123;            cloneTarget[key] = clone(target[key]);        &#125;        return cloneTarget;    &#125; else &#123;        return target;    &#125;&#125;\n\n(4) 拷贝正则表达式const re = /test/g;\n\n一个正则表达式由模式和修饰符组成，/test/为正则模式，g为修饰符。拷贝一个正则表达式，只需获取这两部分即可。通过正则对象的source属性可以获取正则规则，flags属性可以获取修饰符。\nfunction clone(target) &#123;    if (target instanceof Object) &#123;        let cloneTarget = null;        if (target instanceof Array) &#123;            cloneTarget = [];        &#125; else if (target instanceof Function) &#123;            cloneTarget = target;        &#125; else if (target instanceof RegExp)&#123;            // 如果是正则表达式            cloneTarget = new RegExp(target.source, target.flags);        &#125; else &#123;            cloneTarget = &#123;&#125;;        &#125;        for (const key in target) &#123;            cloneTarget[key] = clone(target[key]);        &#125;        return cloneTarget;    &#125; else &#123;        return target;    &#125;&#125;\n\n(5) 拷贝日期function clone(target) &#123;    if (target instanceof Object) &#123;        let cloneTarget = null;        if (target instanceof Array) &#123;            cloneTarget = [];        &#125; else if (target instanceof Function) &#123;            cloneTarget = target;        &#125; else if (target instanceof RegExp) &#123;            cloneTarget = new RegExp(target.source, target.flags);        &#125; else if (target instanceof Date) &#123;            // 如果是日期            cloneTarget = new Date(target);        &#125; else &#123;            cloneTarget = &#123;&#125;;        &#125;        for (const key in target) &#123;            cloneTarget[key] = clone(target[key]);        &#125;        return cloneTarget;    &#125; else &#123;        return target;    &#125;&#125;\n\n\n到目前为止，我们已经写出了一个可以使用的深拷贝函数，但是这个函数仍存在很多可以优化的地方。\n\n\n3.进一步优化(1) 忽略原型上的属性我们在遍历对象属性的时候，使用的是for in，for in会遍历包括原型上的所有可迭代属性，但是事实上我们不应该这么做。所以我们需要通过hasOwnProperty筛选出自身的属性。\nfunction clone(target) &#123;    if (target instanceof Object) &#123;        let cloneTarget = null;        if (target instanceof Array) &#123;            cloneTarget = [];        &#125; else if (target instanceof Function) &#123;            cloneTarget = target;        &#125; else if (target instanceof RegExp) &#123;            cloneTarget = new RegExp(target.source, target.flags);        &#125; else if (target instanceof Date) &#123;            cloneTarget = new Date(target);        &#125; else &#123;            cloneTarget = &#123;&#125;;        &#125;        for (const key in target) &#123;            // 筛选自身属性            if (target.hasOwnProperty(key)) &#123;                cloneTarget[key] = clone(target[key]);            &#125;        &#125;        return cloneTarget;    &#125; else &#123;        return target;    &#125;&#125;\n\n\n\n(2) 循环引用问题解决循环引用问题的关键点在于判断一个对象是否已经被拷贝过，如果拷贝过直接返回拷贝后的对象。所以我们需要一个东西帮我们记录，最好的方式就是map。\nlet cache = new Map();function clone(target) &#123;    // 如果已经拷贝过，直接返回拷贝后的对象    if (cache.get(target)) &#123;        return cache.get(target);    &#125;    if (target instanceof Object) &#123;        let cloneTarget = null;        if (target instanceof Array) &#123;            cloneTarget = [];        &#125; else if (target instanceof Function) &#123;            cloneTarget = target;        &#125; else if (target instanceof RegExp) &#123;            cloneTarget = new RegExp(target.source, target.flags);        &#125; else if (target instanceof Date) &#123;            cloneTarget = new Date(target);        &#125; else &#123;            cloneTarget = &#123;&#125;;        &#125;        // 记录拷贝对象        cache.set(target, cloneTarget);        for (const key in target) &#123;            if (target.hasOwnProperty(key)) &#123;                cloneTarget[key] = clone(target[key]);            &#125;        &#125;        return cloneTarget;    &#125; else &#123;        return target;    &#125;&#125;\n\n\n\n\n\n参考：\nhttps://juejin.cn/post/6844903929705136141\nhttps://juejin.cn/post/6889327058158092302\n\n","categories":["前端"],"tags":["JavaScript"]},{"title":"用户态和内核态","url":"/2024/10/09/%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81/","content":"概念\n也叫用户空间、内核空间\n\n用户态指非特权的执行状态，不能执行越权的操作，一般我们编写的程序、APP、客户端软件等都运行在用户态\n\n内核态指特权的执行状态，可以操作硬件，一般是指操作系统\n\n这是为了系统的安全和稳定\n\n当需要操作系统帮助完成一些用户态自己没有特权的操作时就会切换到内核态，如read()、write()等，这种切换最常见的形式就是系统调用\n\n\n\n\n系统调用系统调用是操作系统的最小功能单位。根据不同的应用场景，不同的Linux发行版本提供的系统调用数量也不尽相同，大致在240-350之间。这些系统调用组成了用户态跟内核态交互的基本接口。\n例如：用户态想要申请一块20K大小的动态内存，就需要系统调用，将数据段指针向下偏移，如果用户态多处申请20K动态内存，同时又释放呢？这个内存的管理就变得非常的复杂。\n\n\n库函数库函数就是屏蔽这些复杂的底层实现细节，减轻程序员的负担，从而更加关注上层的逻辑实现。它对系统调用进行封装，提供简单的基本接口给用户，这样增强了程序的灵活性，当然对于简单的接口，也可以直接使用系统调用访问资源，例如：open，write，read等等。\n库函数根据不同的标准也有不同的版本，例如：glibc库，posix库等。\n\n\nshellshell顾名思义，就是外壳的意思。就好像把内核包裹起来的外壳。它是一种特殊的应用程序，俗称命令行。为了方便用户和系统交互，一般一个shell对应一个终端，呈现给用户交互窗口。\n当然shell也是编程的，它有标准的shell语法，符合其语法的文本叫shell脚本。\n很多人都会用shell脚本实现一些常用的功能，可以提高工作效率。\n\n\n\nhttps://zhuanlan.zhihu.com/p/69554144\n\n","categories":["其他"]},{"title":"浏览器工作原理","url":"/2022/02/21/%E6%B5%8F%E8%A7%88%E5%99%A8%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/","content":"前置知识(1) 浏览器的组成结构浏览器一般由七个模块组成：\n\n用户界面（ User Interface ）\n包括地址栏、后退&#x2F;前进按钮、书签目录等，也就是除了标签页窗口之外的其他部分。\n\n浏览器引擎（ Browser Engine ）\n可以在用户界面和渲染引擎之间传送指令或在客户端本地缓存中读写数据等，是浏览器中各个部分之间相互通信的核心。\n\n渲染引擎（ Rendering Engine ）\n渲染引擎负责渲染用户请求的页面内容。在渲染引擎下还有很多小的功能模块，比如网络模块、JS 解释器等。\n\n网络（ Networking ）\n用来完成网络调用或资源下载的模块。\n\nJS 解释器（ JavaScript Interpreter ）\n用来解释执行 JS 脚本的模块。\n\nUI 后端（ UI Backend ）\n用来绘制基本的浏览器窗口内控件，如输入框、按钮、单选按钮等，根据浏览器不同绘制的视觉效果也不同，但功能都是一样的。\n\n数据持久化存储（ Date Persistence ）\n浏览器在硬盘中保存 cookie、localStorage 等各种数据，可通过浏览器引擎提供的 API 进行调用。\n\n\n\n从浏览器的组成结构来讲，我们常说的浏览器内核，指的就是渲染引擎。\n\n\n(2) 浏览器的多进程结构1) 进程&#x2F;线程进程是资源分配的最小单位，线程是 CPU 调度的最小单位。\n早期浏览器是单进程的，单进程导致了许多问题：\n\n不稳定\n一个页面卡死会导致整个浏览器不能正常使用\n\n不安全\n浏览器之间共享数据\n\n不流畅\n一个进程负责太多的事情，效率低\n\n\n故现在的浏览器采用了多进程结构\n\n\n2) 浏览器的进程浏览器的主要进程有：（以谷歌浏览器为例）\n\n浏览器进程（ Browser process ）\n控制浏览器除标签页外的用户界面，包括地址栏、书签、后退和前进按钮，以及负责和浏览器的其他进程协调工作。\n\n插件进程（ Plugin process ）\n控制网站所使用的所有插件，如 Flash。\n\n渲染进程（ Renderer process ）\n控制显示 tab 标签页内的所有内容，主要作用为页面渲染，脚本执行，事件处理等。浏览器在默认情况下会为每个标签页创建一个进程（这取决于浏览器选择的进程模型）\n渲染进程是多线程的：\n\nJS 引擎线程\n负责处理 Javascript 脚本程序。\n\nGUI 渲染线程\n负责渲染标签页内容，解析 HTML、CSS，构建 DOM 树，布局和绘制等。\n\n事件触发线程\n主要负责将准备好的事件交给 JS 引擎线程执行，比如 setTimeout 定时器计数结束，ajax 等异步请求成功并触发回调函数，或者用户触发点击事件时，该线程会将整装待发的事件依次加入到任务队列的尾部，等待 JS 引擎线程的执行。\n\n定时触发器线程\n负责执行异步定时器一类的函数的线程，如 setInterval，setTimeout 等。\n\n异步 http 请求线程\n负责异步请求一类的函数的线程，如 Promise，axios，ajax 等。\n\n…\n\n\n\nGPU 进程（ GPU process ）\n负责整个浏览器界面的渲染。\n\n其实，Chrome 刚开始发布的时候是没有 GPU 进程的。而 GPU 的使用初衷是为了实现 3D CSS 的效果，只是随后网页、Chrome 的 UI 界面都选择采用 GPU 来绘制，这使得 GPU 成为浏览器普遍的需求。最后，Chrome 在其多进程架构上也引入了 GPU 进程。\n\n\n…\n\n\n\n从浏览器的进程角度来讲，浏览器内核指的是渲染进程。\n\n\n\n从浏览器输入 URL 开始，到页面渲染完成，浏览器做了哪些事情？\n这是一个经典问题，也是作为前端程序员必须要掌握和理解的知识点。\n整个过程可以分为以下几步：\n\nDNS 域名解析\n建立 TCP 连接\n发送 HTTP 请求\n服务器处理请求并返回响应\n浏览器解析并渲染页面\n断开 TCP 连接\n\n接下来我们展开说说，以谷歌浏览器为例。\n\n\n1.DNS 域名解析浏览器进程的UI 线程会捕捉输入框输入的内容，如果是网址，则 UI 线程会启动一个网络线程请求 DNS 进行域名解析；如果输入的不是网址而是关键字，就会使用默认配置的搜索引擎来查询。\n我们重点关注 DNS 域名解析。\n\n\n(1) 域名结构以www.bilibili.com为例，我们通常认为它就是一个域名，但从严格意义上来讲，bilibili.com才是域名，www是服务器名，它表示在bilibili.com域名下，有一台叫做www的服务器。服务器名.域名称为完全限定域名，或者叫主机名。一个域名下可以有多个服务器，比如除了www外，bilibili.com域名下还有mail、space等服务器。\n域名是由.进行划分的，bilibili.com中bilibili为二级域名，它又受com域名管理。com域名又叫做顶级域名，常见的顶级域名还有cn、edu等。那这些顶级域名又受谁管理呢？其实www.bilibili.com的完整写法应该是www.bilibili.com.root，或者简写成www.bilibili.com.，我们把最后这个.称为根域名，只不过一般我们会把这个.省略。\n所以一个主机名的完整结构是：\n服务器名.二级域名.顶级域名.根域名\n\n\n有些人会把主机名也当做是域名，把服务器名也当做是一级域。所以会产生 www.baidu.com 究竟是二级域名还是三级域名的讨论。这就看个人理解了。如果你认为 baidu.com 才是域名，www 是服务器名，那它就是二级域名；如果认为 www.baidu.com 是域名，那它就是三级域名。\n\n\n\n(2) DNSDNS（Domain Name System） ：域名系统。我们知道每一台主机都有一个 IP 地址，浏览器要想向输入的 URL 的主机名所对应的服务器发送请求，那就需要知道服务器的 IP 地址。DNS 的作用就是将主机名转换成 IP 地址。\nDNS 是一个由分层的 DNS 服务器实现的分布式数据库，整个系统由分散在世界各地的许多台 DNS 服务器组成，每台 DNS 服务器上都保存了一些数据，这些数据能够让我们最终查询到主机名对应的 IP。\n所以，DNS 域名解析，本质上就是去向 DNS 服务器查询 IP 地址。\n\n\n(3) DNS 服务器DNS 服务器，也叫做域名服务器。\n它有 3 种类型：\n\n根域名服务器\n它的作用就是管理下一级，也就是顶级域名服务器。通过查询根域名服务器，我们可以知道一个主机名所对应的顶级域名服务器 IP 是多少，再继续向顶级域名服务器发起查询请求。\n\n顶级域名服务器\n_Top Level Domain（TLD）_：顶级域名服务器。除了刚刚提到的com外，常见的顶级域名还有cn、org、edu等。顶级域名服务器提供了下一级权威域名服务器的 IP 地址。\n\n权威域名服务器\n权威域名服务器管理自己域名下主机（服务器）的 IP 地址，最终可以返回主机名 - IP的映射。\n\n\n层次结构图：\n\n除了上述讲到的三种类型的 DNS 服务器，还有一个本地域名服务器，但是严格来讲，本地域名服务器并不属于 DNS 服务器的层次结构，但是它对 DNS 有着重要作用。当主机发起 DNS 请求时，该请求会被发送到本地域名服务器，本地域名服务器起着代理的作用，负责将该请求转发到 DNS 服务器的层次结构中。\n下面我们还是用一个例子展示 DNS 的查询过程。\n\n\n(4) 查询过程假设想要获取www.bilibili.com的 IP 地址。\n\n首先主机会向本地域名服务器发送一个 DNS 查询报文，其中包含了需要被转换的主机名www.bilibili.com。\n\n本地域名服务器将该报文转发到根域名服务器。\n注意：根域名服务器不止一台，全球共有 13 台根域名服务器，本地域名服务器会找最近的根域名服务器。\n\n根域名服务器注意到该主机名的com前缀，就会向本地域名服务器返回com所对应的顶级域名服务器的 IP 地址列表。\n意思就是，我并不知道www.bilibili.com的 IP，不过这些顶级域名服务器可能知道，你去问下他们吧。\n\n本地域名服务器就向那些顶级域名服务器发送查询报文。\n\n顶级域名服务器注意到了bilibili.com的前缀，就会向本地域名服务器返回对应的权威域名服务器的 IP 地址列表。\n意思就是，我并不知道www.bilibili.com的 IP，不过这些权威域名服务器可能知道，你去问下他们吧。\n\n本地域名服务器就向那些权威域名服务器发送查询报文。\n\n最终在某一权威服务器中找到并返回www.bilibili.com的 IP 地址。\n注意：如果域名被注册，必然能在域名服务器中找到对应的 IP 地址。\n\n\n\n如图所示，本地域名服务器向其他域名服务器发送查询请求的方式，就是迭代查询，所有请求都是由本地域名服务器发出，并且所有的响应都是直接返回给本地域名服务器。\n还有另外一种查询方式叫做递归查询，如图：\n\n响应结果并不直接返回给本地域名服务器，而是由当前域名服务器向下一级域名服务器继续查找，直到找到目标 IP 地址，再逐级返回。\n\n\n(5) DNS 缓存为了更快地获得 IP，DNS 广泛使用了缓存技术。\n\n在本地 DNS 服务器向根 DNS 服务器查询请求前，它会先去浏览器自身的 DNS 缓存中查找，如果存在，则解析结束。\n如果浏览器自身的 DNS 缓存中没有，那么会尝试去读取操作系统中的 hosts 文件，看看是否有对应的映射关系，如果存在，则解析结束。\n如果本地 hosts 文件中没有，则去查找本地 DNS 服务器（ISP 服务器，或者自己手动设置的 DNS 服务器）中的 DNS 缓存，如果存在，则解析结束。\n如果上述三步中都不存在相应缓存，就开始进行查询请求。\n\n\n\n\n2.建立 TCP 连接通过 DNS 域名解析，获取到目标 IP 地址后，需要和其建立 TCP 连接，也就是我们常说的三次握手。\n\n\n(1) 格式TCP 头部格式：\n\n其中有 6 个标志位：\n\nSYN（synchronous 建立联机）\nACK（acknowledgement 确认）\nPSH（push 传送）\nFIN（finish 结束）\nRST（reset 重置）\nURG（urgent 紧急）\n\n\n\n(2) 三次握手\n\nSYN 连接请求(客户端)\n主机 A 发送seq=x，SYN=1的数据包给主机 B，其中seq=x表示这条数据包的序号。\n这就是第一次握手，由客户端发出，服务端接收。\n\nSYN、ACK 确认(服务端)\n主机 B 接收到后根据SYN=1知道了 A 要求建立连接。向 A 发送seq=y，ack=x+1，SYN=1，ACK=1的数据包，其中seq=y表示这条数据包的序号，ack=x+1表示这条数据包是对主机 A 之前发送的seq=x的数据包的确认，只有标志位ACK=1时，这个确认序列号，也就是ack才是有效的。\n相当于告诉主机 A 我已经准备好了。这就是第二次握手，由服务端发出，客户端接收。\n\nACK 确认(客户端)\n主机 A 收到后，检查ACK是否为 1，如果是，继续检查ack是否正确，即第一次发送数据包的seq+1，同时检查SYN是否为 1，如果都满足，则再次发送一条seq=x+1，ack=y+1，ACK=1的数据包，其中seq=x+1表示这条数据包的序号，ack=y+1表示这条数据包是对主机 B 返回的seq=y的数据包的确认。主机 B 收到后，检查ACK、ack是否正确，如果正确则连接建立成功。\n这就是第三次握手，由客户端发出，服务端接收。\n\n\n\n为什么要三次握手？\n其实这是由 TCP 自身可靠传输的特点决定的。客户端和服务端要进行可靠传输，那么就需要确认双方的接收和发送能力。第一次握手可以确认客户端的发送能力，第二次握手，确认了服务端的发送能力和接收能力，所以第三次握手才可以确认客户端的接收能力。不然容易出现丢包的现象。\n\n\n\n3.发送 HTTP 请求在成功和服务端建立连接之后，就可以发送 http 请求了。\n\n\n(1) 格式请求报文：\n行:GET url HTTP/1.1头:Content-Type:application/x-www-form-urlencoded空行体:...\n\n响应报文：\n行:HTTP/1.1 200 OK头:Content-Type: text/plain; charset=UTF-8空行体:...\n\n\n\n(2) 状态码\n\n\n状态码\n含义\n\n\n\n1xx\n服务器收到请求\n\n\n2xx\n请求成功\n\n\n3xx\n重定向\n\n\n4xx\n客户端错误\n\n\n5xx\n服务端错误\n\n\n\n\n(3) HTTP 缓存什么是 HTTP 缓存？当客户端向服务端请求资源时，会先去缓存中找，如果缓存中存在该资源的副本，则直接从缓存中提取而不是去向服务端请求。\n为什么需要 HTTP 缓存？因为网络请求相比较于 CPU 的计算和页面渲染是非常慢的。使用缓存可以加快页面加载速度，同时减少服务器的负担。\n哪些资源可以被缓存？静态资源，比如 js、css、图片等。\n\nHTTP 缓存和 DNS 缓存是不一样的，DNS 缓存记录的是主机名到 IP 的映射关系，HTTP 缓存的是静态资源。除此之外，还有一个浏览器缓存，即 Cookie、SessionStorage、LocalStorage 等，不过这不是本文重点，感兴趣的可以另行查看。\n\nHTTP 缓存又两种类型：\n\n强缓存\n协商缓存\n\n下面我们依次介绍\n\n\n1) 强缓存强缓存就是向浏览器 HTTP 缓存查找该请求结果，并根据该结果的缓存规则来决定是否使用该结果的过程。\n简单来讲，就是去设置资源的有效时间，当再次请求相同资源时，如果缓存仍然有效，直接从缓存中读取资源。\n强缓存分了两种方式：Expires和Cache-Control\n\nExpries\n版本：HTTP&#x2F;1.0\n来源：存在于服务端返回的响应头中\n语法：Expires: Wed, 22 Nov 2019 08:41:00 GMT\n缺点：服务器的时间和浏览器的时间可能并不一致导致失效\n\n\nCache-Control\n版本：HTTP&#x2F;1.1\n来源：响应头和请求头\n语法：Cache-Control:max-age&#x3D;3600\n\n\n\n当前 HTTP 版本为 1.1，所以强缓存更多的是采用 _Cache-Control_，我们重点来聊 _Cache-Control_。它的具体表现就是在请求头和响应头中添加了 Cache-Control 字段，用来判断该资源的缓存规则。\n该字段常见的值如下：\n\n\n\n值\n说明\n\n\n\nmax-age&#x3D;delta-seconds\n缓存最大过期时间为 delta-seconds 秒\n\n\nno-cache\n客户端可以存储资源，但是每次都要去和服务端做新鲜度校验，来决定是重新获取还是直接使用缓存\n\n\nno-store\n永远不在客户端存储资源，永远都是去原始服务器去获取资源\n\n\n\n\n注意：虽然请求头和响应头中都能设置 Cache-Control 字段，但一般是响应头发挥作用，比如请求头设置 max-age 为 60s，响应头设置为 30s，最后结果是 30s 缓存就失效了，也就是说服务端的设置决定了缓存的有效时间，另外，只有服务端有能力开启缓存，如果请求头设置 _Cache-Control_，而服务端不设置，缓存是不生效的。那么请求头中的 Cache-Control 有什么用呢？只有请求头中设置了 Cache-Control 值为 no-store 或者 no-cache 或者 max-age&#x3D;0，也就是客户端不想要走强缓存，那这个 Cache-Control 才是有用的。\n\n\n\n2) 协商缓存协商缓存就是在强制缓存失效后，浏览器携带缓存标识向服务器发起请求，由服务器根据缓存标识是否决定使用缓存的过程。\n简单来讲，就是当强缓存失效时，我们需要去判断缓存中的资源是否仍然有效，如果仍然有效，依旧从缓存中读取资源。\n协商缓存也有两种：\n\nLast-Modified &#x2F; if-Modified-Since\n\n意义：资源最后修改时间\n来源：Last-Modified 在响应头中，if-Modified-Since 在请求头中\n判断：如果这两个值相同，表示资源并没有更新过，返回 304；不一致则表示资源更新过，就返回 200 和新的资源以及新的 Last-Modified\n\n\n\n\nEtag &#x2F; if-None-Match\n\n意义：资源的唯一标识（一个字符串，类似于人类的指纹）\n来源：Etag 在响应头中，if-None-Match 在请求头中\n判断： 如果这两个值相同，表示资源并没有更新过，返回 304；不一致则表示资源更新过，就返回 200 和新的资源以及新的 Etag\n\n\n\n\n那么这两种方式有什么区别呢？其实 Etag 和 Last-Modified 判断资源的方式是一样，只不过后者是一个时间，前者是对资源按照一定方式计算出来的唯一标识，如果资源发生了更新，这个唯一标识必然会有变化。\n两者比较：\n\n优先使用 Etag\nLast-Modified 只能精确到秒\n如果资源重复生成，但内容不变，使用 Etag 更精确\n\n\n\n3) 综合流程\n4) 页面刷新对 HTTP 缓存的影响有三中刷新类型：\n\n正常操作：浏览器输入 url、连接跳转、前进后退\n强制缓存和协商缓存都有效\n\n手动刷新：f5、点击刷新按钮、右键菜单刷新\n强制缓存失效，协商缓存有效\n\n强制刷新：ctrl + f5、shift + command + r\n强制缓存和协商缓存都失效\n\n\n\n\n4.服务器处理请求并返回响应每台服务器上都会安装处理请求的应用—— Web Server 。常见的 Web Server 产品有 apache、nginx、IIS 或 Lighttpd 等。\nHTTP 请求一般可以分为两类，静态资源和动态资源。\n请求访问静态资源，这个就直接根据 url 地址去服务器里找就好了。\n请求动态资源的话，就需要 web server 把不同请求，委托给服务器上处理相应请求的程序进行处理，然后返回后台程序处理产生的结果作为响应，发送到客户端。\n\n\n5.浏览器解析并渲染页面当网络线程获取到数据后，终于要开始渲染页面了。\n（如果是谷歌浏览器，当网络线程获取到数据后，需要通过SafeBrowsing检查站点是否是恶意站点，SafeBrowsing 是谷歌内部的一套站点安全系统，通过检测该站点的数据来判断是否安全，通过安全校验后，才进入渲染流程）\n\n\n(1) 渲染流程\n浏览器进程会启动一个渲染进程，并将数据（也就是 html）通过IPC 管道传递给渲染进程，正式开始渲染流程。\n\n渲染进程的核心任务就是把 html、css、js、图片等资源渲染成用户能交互的 web 页面。\n\n\n渲染进程的主线程会将 html 进行解析，构造DOM 数据结构，html 首先通过Tokeniser 标记化，通过语法分析将 html 内容解析成多个标记，根据识别后的标记进行DOM 树构造，DOM 树构造过程中会创建document 对象，然后以 document 对象为根节点的 DOM 树不断进行修改，向其中添加各种元素。\n\nhtml 中引入的其他资源，如图片、css、js 等，图片和 CSS 等需要通过http 请求下载或者从http 缓存中直接加载，这些资源不会阻塞 html 的解析，因为它们不会影响 DOM 的生成，但如果解析过程中遇到 script 标签，就会暂停解析，先去加载解析并执行 js 脚本，因为 js 中可能会改变当前页面 html 结构。或者使用 async 或者 defer 属性来异步加载执行 js。\n主线程就是指 JS 引擎线程和 GUI 渲染线程，这两个线程是互斥的，JS 引擎线程执行时，GUI 渲染线程不执行，反之亦然。\n\n\n\nDOM 树构建完毕后，主线程需要解析 CSS 并确定每个 DOM 节点的计算样式。\n\n即使你没有自定义样式，浏览器也会有自己的默认样式表。\n\n\n\n在知道 DOM 结构和每个节点的样式后，我们接下来需要知道每个节点放在页面上的哪个位置，也就是节点的坐标以及该节点需要占用多大的区域，这一阶段叫做Layout 布局。主线程通过遍历 DOM 树和计算好的样式来生成Layout 树，Layout 树上的每个节点都记录了 x，y 坐标和边框尺寸。\n\nDOM 树和 Layout 树并不是一一对应的，如设置了 display:none 的元素不会出现在 Layout 树中，而在 before 伪元素中添加了 content 值的元素，content 中的内容会出现在 Layout 树中，不会出现在 DOM 树中。这是因为 DOM 树是根据解析 html 所得，并不关心样式；而 Layout 树是根据 DOM 节点和计算好的样式来生成，和最终展示在页面上的节点是对应的。\n\n\n\nLayout 树创建完毕后，我们还需要知道这些元素要以什么样的顺序进行绘制（比如 z-index 就会影响绘制顺序），主线程遍历 Layout 树，创建一个绘制记录表，该表记录了绘制的顺序，这个阶段称为**绘制(Paint)**。\n\n\n现在知道了元素的绘制顺序，就到了需要把这些信息真正转化成像素点，显示到屏幕上的时候了，这个阶段称为**栅格化(光栅化)**。\n\n主线程遍历 Layout 树，生成Layer(图层)树，将这些信息传递给合成器线程，合成器线程将每个图层栅格化，生成合成器帧。\n\n早期的 Chrome 栅格化方案：只栅格化页面显示的内容，当页面滚动时，再栅格化更多的内容来填充缺失的部分，这种方式会导致展示延迟。\n现在的 Chrome 采用更为复杂的栅格化方案，称为合成：将页面内的各个部分分成多个图层，分别对其进行栅格化，并在合成器线程中单独合成页面。上述操作即采用该方案。\n\n\n\n\n合成器帧通过 IPC 传送给浏览器进程，接着浏览器进程将合成器帧传送到GPU，最终渲染展示到屏幕上。当页面发生变化，如滚动了页面，合成器线程则会生成一个新的合成器帧，再重复上述操作。\n\n\n\n综述：\n\n\n\n\n(2) 重排&#x2F;重绘\n重排\n当改变一个元素的尺寸位置属性时，会重新进行样式计算、布局(Layout)、绘制(Paint)以及后面的所有流程，这个行为称为重排，也叫作回流(reflow)\n\n重绘\n当改变某个元素的颜色属性时，不会重新触发布局(Layout)，但还是会触发样式计算和绘制(Paint)，这个行为称为重绘(repaint)\n\n\n\n重排一定会引起重绘，而重绘不一定会引起重排。\n\n由于重排重绘会占用主线程、同时 JS 也会抢占主线程，这就会导致页面出现卡顿情况。同时，大量的重排重绘会造成额外的计算消耗。所以要尽量减少重排重绘。那么该如何减少重排重绘呢？\n\n最少化重排重绘，比如样式集中改变，使用添加新样式类名.class或cssText。\n使用 absolute 或 fixed使元素脱离文档流，这在制作复杂的动画时对性能的影响比较明显。\n开启 GPU 加速，利用 css 属性 transform 、will-change 等，因为它们不会触发重排重绘。\n\n\n\n6.断开 TCP 连接当所有操作完，关闭页面，就会断开 TCP 连接。也就是我们常说的四次挥手。\n\nhttp1.1 是默认不断开 TCP 连接的，因为连接建立需要耗费资源，多个 HTTP 请求会复用 TCP 通道。所以当页面关闭时，TCP 连接才断开。\n\n\n\n(1) 四次挥手\n首先要明确一点，客户端和服务端都可以发起关闭连接请求。我们假设是客户端发起关闭请求。\n\nFIN 请求（客户端）\n主机 A 发送一条seq=x，FIN=1的数据包给主机 B，其中seq=x表示这条数据包的序号。\n这就是第一次挥手。\n\nACK 确认（服务端）\n主机 B 接收到后根据FIN=1知道要断开连接。向 A 发送一条seq=y，ack=x+1，ACK=1的数据包，其中seq=y表示这条数据包的序号，ack=x+1表示这条数据包是对主机 Aseq=x的数据包的确认。\n这就是第二次挥手。告诉对方我已经知道了。但是这时候还没有立刻关闭，而是处于一个关闭等待的状态。因为这时候服务端可能还在发送数据，只有数据发送完了才能发送 FIN 数据包。\n\nFIN、ACK 确认（服务端）\n当数据发送完毕，主机 B 发送一条seq=z，ack=x+1，ACK=1，FIN=1的数据包给主机 A，其中seq=z表示这条数据包的序号，ack=x+1表示这条数据包是对主机 Aseq=x的数据包的确认。\n这就是第三次挥手。\n\nACK 确认（客户端）\n主机 A 接收到后，检查ACK是否为 1，ack是否为第一次发送数据包的seq+1，检查FIN是否为 1，如果都正确，主机 A 向主机 B 发送一条seq=x+1，ack=z+1，ACK=1的数据包。主机 B 收到后，检查ack、ACK是否正确，正确则关闭连接。\n这就是第四次挥手。\n\n客户端在发送 ACK 数据包后，不是立刻就关闭连接，而是需要等待一段时间，因为虽然理论上四个数据包发送完毕就可以直接关闭连接了，但是网络是不可靠的，可能存在最后这个 ACK 数据包没有被服务端接收到的情况，服务端在长时间没有收到 ACK 数据包后，会重新发送一次 FIN 数据包。如果客户端在发送 ACK 数据包后立刻关闭连接，就无法收到这条重发的 FIN 数据包，导致服务端关闭连接失败，造成资源的浪费。所以客户端在发送 ACK 数据包后，需要等待一段时间，等待时间长度为 2MSL，MSL（ Maximum Segment Life ）是 TCP 对数据包生存时间的限制，发送后超过这个时间还未被接收到，就认为这个数据包丢失，2MSL 能确保客户端收到重发的 FIN 数据包。\n\n\n\n\n\n\n参考：\nhttps://blog.csdn.net/BonJean/article/details/78453547\nhttps://zhuanlan.zhihu.com/p/102149546\nhttps://juejin.cn/post/6935232082482298911\nhttps://juejin.cn/post/6990344840181940261\nhttps://juejin.cn/post/6998389354271866910\nhttps://www.bilibili.com/video/BV1x54y1B7RE\nhttps://www.imooc.com/wenda/detail/499811\n\n","categories":["前端"]},{"title":"缓存双写一致性","url":"/2024/10/09/%E7%BC%93%E5%AD%98%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/","content":"查询流程\n\n\n双写一致性概念当修改了数据库的数据也要同时更新缓存的数据，缓存和数据库的数据要保持一致。\n\n如果Redis中有数据，需要和数据库中的值相同\n\n如果Redis中无数据，数据库中的值要是最新值，且回写Redis\n\n\n缓存按照操作来分，可以分为两种：\n\n只读缓存\n\n读写缓存\n大部分都是读写缓存，其有两种回写同步策略：\n\n同步直写策略\n写数据库后也同步写Redis缓存，缓存和数据库中的数据一致；\n对于读写缓存来说，要想保证缓存和数据库中的数据一致，就要采用同步回写策略。\n\n异步缓写策略\n正常业务运行中，数据库变动了，但是可以在业务上容许出现一定时间后才作用于Redis；\n当出现异常情况，不得不将失败的动作重新修补，可能需要借助消息中间件实现重试重写。\n\n\n\n\n\n\n双检加锁策略当高并发查询时，如果Redis没有数据，大量请求会落入数据库中，同时大量的回写操作造成数据覆盖，会耗费不必要的资源。\n解决方案：采用双检加锁策略\n多个线程同时去查询数据库的这条数据，我们可以在第一个查询数据的请求上使用一个互斥锁。其他线程等第一个线程查询完回写缓存释放锁后，直接加载缓存数据。\n\n\n更新策略目的：保证最终一致性\n原则：以MySQL的数据为准\n下述共4种更新策略，四种策略无最优解，不保证适配所有情况，视实际情况选择。\n\n如果是停机更新，下面方法都可以使用，如果是无感更新，不同策略可能存在一些问题\n\n\n\n先更新数据库，再更新缓存问题：\n\n如果更新数据库成功，但Redis更新失败了，两边数据不一致，读到Redis脏数据。\n\n多线程环境下，线程有快有慢，可能存在如下情况：\n线程A、B同时更新\n# 正常情况A update mysql 100A update redis 100B update mysql 80B update redis 80# 异常情况A update mysql 100B update mysql 80B update redis 80A update redis 100\n\n导致数据库和Redis数据不一致\n\n\n\n\n先更新缓存，再更新数据库问题：\n\n这种方式并不推荐，因为业务上一般把MySQL作为底单数据库，保证最后解释。\n\n同第一种更新策略，多线程环境下，线程有快有慢，可能存在如下情况：\n线程A、B同时更新\n# 正常情况A update redis 100A update mysql 100B update redis 80B update mysql 80# 异常情况A update redis 100B update redis 80B update mysql 80A update mysql 100\n\n导致数据库和Redis数据不一致\n\n\n\n\n先删除缓存，再更新数据库问题：\n\n缓存删除成功，但数据库更新失败，导致读取到旧值。\n\n线程A已经删除缓存，数据库更新还在执行中（可能网络延迟，并没有真正到MySQL的update操作），另一个线程B此时进行查询操作。\n此处就会有两个问题：\n\n线程B从MySQL中获得了旧值\n线程B将旧值回写给Redis\n\n导致数据库和Redis数据不一致\n\n\n解决方法：延时双删策略。在更新数据库前后都删除一次缓存。更新数据库后的删除需要一段延迟时间，这段时间是为了让线程B能够先从数据库读取数据，再把缺失的数据写入缓存，所以这个时间需要大于线程B读取数据再写入缓存的时间。\n\n\n先更新数据库，再删除缓存较为推荐的做法。但也有一些问题：\n\n缓存删除失败或者来不及，会导致请求再次访问Redis时缓存命中，读取到的是缓存旧值。\n\n\n\n强一致性解决方案借助消息中间件\n\n\n可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列\n当程序没有成功删除缓存或者更新数据库时，可以从消息队列中重新读取这些值，再次尝试\n如果成功删除或更新，这些值就要从消息队列中去除，避免重复操作。此时，就可以保证数据库和缓存的数据一致性。否则还需要继续重试\n如果超过一定次数还未成功，需要业务层发送错误信息，通知运维人员。\n\n\n\nCanalcancal主要用途是用于MySQL数据库增量日志数据的订阅、消费和解析，是阿里巴巴开发并开源的，采用Java语言开发。\n\nhttps://github.com/alibaba/canal\n\n","categories":["后端"],"tags":["Redis"]},{"title":"缓存预热、雪崩、击穿、穿透","url":"/2024/10/09/%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD%E3%80%81%E9%9B%AA%E5%B4%A9%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F/","content":"缓存预热概念缓存预热是一种在程序启动或缓存失效之后，主动将热点数据加载到缓存中的策略。这样，在实际请求到达程序时，热点数据已经存在于缓存中，从而减少了缓存穿透和缓存击穿的情况，也缓解了SQL服务器的压力。\n\n\n缓存雪崩概念当某一个时刻出现大规模的缓存失效的情况，那么就会导致大量的请求直接打在数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。\n出现大规模缓存失效的情况：\n\nRedis服务器宕机（硬件运维）\n大量key同时过期（软件开发）\n\n\n\n解决方案\nRedis集群，避免单机宕机导致缓存失效\n在原有的失效时间上加上一个随机值，比如1-5分钟随机。这样就避免了因为采用相同的过期时间导致的缓存雪崩\n多缓存结合（本地缓存）\n服务降级，业务上兜底\n云数据库\n\n\n\n缓存击穿概念其实跟缓存雪崩有点类似，缓存雪崩是大规模的key失效，而缓存击穿是一个热点的key，有大并发集中对其进行访问，突然间这个key失效了，导致大并发全部打在数据库上，导致数据库压力剧增。这种现象就叫做缓存击穿。\n\n\n解决方案\n差异失效时间：\n在业务允许的情况下，对于热点的key可以设置永不过期\n\n互斥更新：\n采用双检加锁策略\n\n\n\n\n缓存穿透概念一般情况下，先查询缓存Redis是否有该条数据，缓存中没有时，再查询数据库。当数据库也不存在该条数据时，每次查询都要访问数据库，这就是缓存穿透。\n缓存穿透带来的问题是，当有大量请求查询数据库不存在的数据时，就会给数据库带来压力，甚至会拖垮数据库。\n\n\n解决方案\n空对象缓存：\n增强回写，如果数据库查询不到数据，业务上规定某一特殊值回写进Redis。\n该方法有个缺陷是Redis中无关紧要的key会不断增多（一定要设置过期时间）\n\n布隆过滤器：\n把已存在数据的key存在布隆过滤器中，当有新请求时，先到布隆过滤器中查询是否存在：\n\n如果布隆过滤器中不存在该条数据，直接返回\n\n如果布隆过滤器中存在该条数据，再去查询缓存Redis，如果缓存中没有再去查询MySQL数据库\n\n\n\n\n\n","categories":["后端"],"tags":["Redis"]}]